1) Summary
   - This paper studies when and why partial parameter transfer (inheriting a fraction α of weights from an upstream model) helps a downstream task. In a two-layer ReLU CNN trained by gradient descent on a synthetic “two-patch” data model, the authors analyze training dynamics via a signal/noise decomposition of filters and prove phase transitions in generalization with and without parameter transfer. The main result (Theorem 4.2, Section 4) gives conditions on dimension d, sample sizes N1/N2, noise levels σp,1/σp,2, and universal signal strength ∥u∥2 under which test error approaches Bayes-optimal or remains bounded away. They also characterize regimes of positive and negative transfer (Proposition 4.4, Section 4). Synthetic experiments (Figures 1–2, Section 5) and real-data experiments on CIFAR-10/100 with ResNet/VGG/ViT (Table 1; Figures 3–4, Sections 6 and Appendix F) qualitatively support the theory.2) Strengths
   - Bold, dynamics-based theory for parameter transfer
     • Theorem 4.2 (Section 4, Blocks #12–#13) establishes a phase transition of test error with parameter transfer, explicitly depending on α, N1, ∥u∥2, σp,1 and target quantities; this is impactful because most prior theory focuses on static bounds rather than training dynamics (Section 1, Block #2).  
     • Direct comparison with the non-transfer baseline via Theorem 4.3 (Section 4, Block #14) allows attributing gains to transfer, supporting technical soundness and interpretability.  
     • Proposition 4.4 (Section 4, Blocks #15 & #17) provides conditions under which transfer helps (large Γ) or hurts (weak shared signal), clarifying applicability; this is notable novelty for theory of negative transfer within a dynamic framework.- Clear formalization of the setup and algorithm
     • Data models (Definitions 3.1–3.2, Section 3, Blocks #7 & #10) precisely separate universal feature u, task-specific features v1/v2, and Gaussian noise, enabling tractable analysis; this clarity is foundational for rigorous proofs.  
     • The CNN model and training objective (Section 3, Block #10) are explicitly defined, including the ReLU two-patch architecture and cross-entropy loss, ensuring reproducibility of the theoretical analysis.  
     • Algorithms 1–2 (Section 3/4, Blocks #8–#9) formalize partial parameter transfer (α-fraction inheritance) versus from-scratch training, mapping the theoretical conditions to concrete procedures.- Nontrivial proof techniques and training-dynamics analysis
     • Weight decomposition into signal (u, v1, v2) and per-sample noise components (Definition B.1; Lemma B.2; Appendix B, Blocks #45–#48) enables tracking signal learning (γ-coefficients) vs. noise memorization (ρ-coefficients), demonstrating technical depth and novelty within the feature-learning line.  
     • Balanced loss across samples and continuous-time approximations (Lemma A.1; Lemma D.4; Lemma C.4; Appendix A/D/C, Blocks #41–#42, #64–#68, #54) are carefully established to control dynamics, supporting soundness.  
     • Phase transition derivations rely on precise scaling (e.g., κA, κD, Conditions 4.1, Appendix D/E, Blocks #60–#63, #85–#88), indicating careful technical control of constants and regimes.- Insight into positive and negative transfer
     • Proposition 4.4 (Section 4, Blocks #15 & #17) formalizes when transfer outperforms or underperforms training from scratch, reflecting empirical observations and giving design guidance; this addresses a well-known open question (Introduction, Block #2).  
     • The introduction (Blocks #3–#4) provides an intuitive mechanism—strong shared features and favorable upstream noise/sample size benefit transfer, whereas weak shared signal can cause inherited norms to amplify task-specific noise—helpful for practical selection of source tasks.  
     • Synthetic experiment Figure 1(c) (Section 5, Blocks #16 & #19) demonstrates degradation when ∥u∥2 = 0, empirically confirming negative-transfer behavior predicted by theory.- Empirical validation spanning synthetic and real data
     • Synthetic experiments systematically vary N1, σp,1, ∥u∥2, and d (Figures 1(a–c) and 2(a–c), Section 5, Blocks #16, #19–#22), and match theoretical trends (e.g., increasing N1 helps: Figure 1(a); decreasing σp,1 helps: Figure 1(b); increasing ∥u∥2 helps, and ∥u∥2 = 0 hurts: Figure 1(c)).  
     • Real-data experiments on CIFAR-10/100 with ResNet/VGG show larger gains as source data increases (Table 1, Section 6, Blocks #23 & #27), aligning with the role of N1 in Theorem 4.2 and Proposition 4.4.  
     • Noise-robustness tests on target (Figure 3(a–b), Section 6, Blocks #28 & #31; images #35–#34) show w/ PT consistently outperforming scratch as σp,2 increases, echoing the model’s prediction that inherited universal knowledge mitigates noise memorization (Section 1, Block #3; Theorem 4.2).- Assumptions and regimes are explicitly stated
     • Condition 4.1 (Section 4, Block #12) makes small init, learning rate bounds, and overparameterization explicit, clarifying scope and distinguishing from the NTK/lazy regime (Related Work, Blocks #5–#6).  
     • The authors discuss the orthogonality and its extendability (Section 3, Block #10), enhancing clarity of modeling choices.  
     • The proof sketch (Appendix A, Blocks #40–#44) concisely summarizes the logic, aiding readability.- Breadth of architectures in real experiments
     • Results with ResNet/VGG (Table 1, Section 6, Blocks #23 & #27) and DeiT-B/ViT (Appendix F, Figure 4; Blocks #112–#116) indicate that the qualitative claims generalize beyond the toy CNN, raising the potential impact despite the theoretical model being shallow.3) Weaknesses
   - Restrictive data/model assumptions limit external validity
     • Orthogonality between universal and task-specific signals and the noise subspace is assumed for simplicity (Section 3, Block #10), which eases analysis but may not hold in practice; this narrows applicability.  
     • The two-patch input and two-layer ReLU CNN (Section 3, Block #10) are stylized; modern transfer learning often operates in deep architectures with complex augmentations and correlated features, so the leap from theory to practice remains large (impact/generalizability).  
     • Universal knowledge is represented by a single shared vector u (Definitions 3.1–3.2, Block #7), which is a very specific structure; real tasks may share multiple intertwined factors (novelty/realism).- Notational inconsistencies and referencing issues that affect clarity
     • Theorem 4.3 cites “Condition 3.1” (Section 4, Block #14), but only “Condition 4.1” is defined; this is likely a typo and can confuse readers (clarity).  
     • Theorem 4.2 states “training loss L_S(W^(t)) ≤ ε” (Section 4, Block #13) although Section 3 defines L_Task2; L_S is not defined (clarity/precision).  
     • The exposition after Condition 4.1 says “assumption on the width d” (Section 4, Block #11), while width was denoted m in Section 3; conflating d and m impairs readability (clarity).  
     • Theorem E.12 cites “equation F.2/F.3” (Appendix E, Blocks #108–#109), but Section F is “Other Experiments” (Appendix F, Blocks #112–#116), and no equations F.2/F.3 are defined; this undermines traceability of the proof (technical clarity).- Real-data experimental details are insufficient for reproducibility
     • Varying N1 in CIFAR experiments (Section 6, Block #23) lacks training hyperparameters (optimizer, schedule, augmentation, epochs), preventing replication (experimental rigor).  
     • It is unclear how parameters are transferred across different architectures (ResNet-101 to ResNet-34/50; Table 1, Block #27): which layers/α, and how shapes are matched (clarity/validity).  
     • For ViT (Appendix F; Section 6, Block #29), layer inheritance is described (layers 9–11) but training details (optimization, learning rate schedules, data augmentations) are missing; Figure 4 (Blocks #112, #115–#116) shows curves without setup specifics (reproducibility).  
     • The noise-injection protocol in “Varying σp,2” (Section 6, Blocks #28 & #31) is described, but not the baseline training setup; ensuring fair comparisons requires full training details (rigor).- Limited experimental exploration of α and inheritance strategy versus theory
     • Theory emphasizes α (Theorem 4.2; Proposition 4.4, Blocks #13, #15–#17), but synthetic experiments vary α only once (α = 0.5 in the heatmap setting; Section 5, Block #22) and do not analyze its effect systematically (experimental completeness).  
     • The method uses random weight sampling for inheritance (Section 4, Block #11), whereas practical systems often select “strong shared features”; real experiments sometimes pick specific layers (DeiT, Section 6, Block #29), leading to a mismatch between the theoretical assumption (random α) and practice (selection heuristics), obscuring interpretation (validity).  
     • No ablations compare random, gradient-based, and structural layer transfer to isolate the role of selection strategy versus α (experimental rigor/impact).- Limited empirical evidence for negative transfer on real data and incomplete mechanistic quantification
     • Negative transfer is shown in synthetic data when ∥u∥2 = 0 (Figure 1(c), Section 5, Blocks #16 & #19), but real data experiments (Section 6, Table 1; Figures 3–4, Blocks #27–#31, #112–#116) report only improvements; no adverse cases or ablations demonstrate the predicted degradation in practice (completeness).  
     • The introduction attributes negative transfer to large inherited weight norms amplifying task-specific noise (Section 1, Block #4), but an explicit bound relating inherited norm magnitude to downstream noise amplification is not directly stated as a lemma/theorem; linkage remains qualitative (technical completeness).  
     • Proposition 4.4 item 2 (Section 4, Block #17) gives a condition for negative transfer, but the comparison to the non-transfer test error is summarized rather than quantified across realistic baselines; a more explicit theorem contrasting error curves would strengthen the claim (rigor).- Bayes-optimal reference is not explicitly defined within the presented data model
     • Theorems assert “near Bayes-optimal” (Theorem 4.3, Section 4, Block #14) or “Bayesian optimal” (Theorem 4.2, Section 4, Block #13), but the Bayes classifier for the two-patch model is not formally defined in Section 3; readers cannot compute or verify the Bayes error directly (clarity/rigor).  
     • While the distribution is specified (Definitions 3.1–3.2, Section 3, Block #7), the exact Bayes decision rule under the patch-selection randomness and orthogonal noise is not spelled out (clarity).  
     • No explicit lemma gives the Bayes error rate under σp,2 and ∥u + v2∥2, which would contextualize the exponential bounds in Theorems 4.2–4.3 (technical completeness).- Minor presentation issues in figures and text
     • Figure 2 is introduced with a Markdown-like table and placeholders (Section 5, Block #22), which is confusing; the figure panels’ axes and color scales are described, but the formatting obfuscates interpretation (clarity).  
     • Several LaTeX/math artifacts and typos appear (e.g., mismatched indices, “Condition 3.1” vs “4.1”, “width d” vs “width m”) across Sections 4 and Appendix E (Blocks #11, #14, #108–#109), which could hinder careful reading (clarity).  
     • Occasional symbol inconsistencies (e.g., L_S vs L_Task2 in Theorem 4.2, Block #13) reduce precision.4) Suggestions for Improvement
   - Broaden and stress-test the theoretical assumptions
     • Relax the orthogonality between signal and noise by analyzing a correlated model; at minimum, add a formal statement quantifying how small correlations affect constants in Theorem 4.2 (Section 3, Block #10).  
     • Discuss multi-dimensional shared subspaces (e.g., k-dimensional u) and how results (Theorem 4.2/Proposition 4.4) scale; include a remark or corollary extending Definitions 3.1–3.2 (Section 3, Block #7).  
     • Add empirical stress tests on synthetic data with controlled signal–noise correlations to show robustness of the phase transition (Figures 1–2, Section 5).- Resolve notational and referencing inconsistencies
     • Correct Theorem 4.3 to reference Condition 4.1 (Section 4, Blocks #11–#14), and replace L_S with the properly defined L_Task2 in Theorem 4.2 (Block #13).  
     • Clarify “width” usage after Condition 4.1 to consistently denote width by m, and dimension by d (Section 4, Block #11).  
     • In Appendix E, replace “equation F.2/F.3” (Blocks #108–#109) with correct internal equation labels and ensure all cross-references exist; add a short list of symbols for κA, κD, x_t^A/x_t^D, etc., to improve traceability.- Improve real-data reproducibility
     • Provide full training details for CIFAR and ViT experiments: optimizer, LR schedule, weight decay, data augmentation, epochs, batch sizes, hardware, seeds, and early stopping criteria (Section 6, Blocks #23, #28–#31; Appendix F, Blocks #112–#116).  
     • Describe precisely how parameters are transferred across architectures (ResNet-101 → ResNet-34/50): which layers/blocks, mapping rules, α, and any re-initialized modules (Table 1, Block #27).  
     • Release code/configs or include a detailed appendix protocol to reproduce Table 1 and Figures 3–4; specify the scratch baseline’s exact settings to ensure fairness.- Systematically study α and the inheritance strategy
     • Add synthetic ablations varying α across a grid (e.g., α ∈ {0.1,…,1.0}) and report the resulting accuracy curves, relating them to Theorem 4.2 (Section 5, Block #22).  
     • Compare random inheritance (Algorithm 1; Section 4, Block #11) to heuristic selection (e.g., top-activating filters, gradient-based) on synthetic and CIFAR; quantify gaps to assess whether the random α assumption is conservative.  
     • Report real-data results where α or layer-selection varies (e.g., different layer groups in ResNet/ViT), to align empirical methodology with the theoretical knob α.- Strengthen negative transfer evidence and mechanistic quantification
     • Include real-data scenarios with weak task relatedness (e.g., disjoint class subsets or mismatched domains) to demonstrate performance degradation w/ PT relative to scratch, mirroring Figure 1(c) (Section 6, Table 1; Figures 3–4).  
     • Add an explicit lemma bounding the inherited norm and showing how it propagates to downstream noise amplification (e.g., via ∑i ρ-terms), directly supporting the intuition stated in the Introduction (Block #4).  
     • Provide a theorem or corollary that contrasts test-error bounds with and without transfer under Proposition 4.4’s negative-transfer condition, making the degradation quantitatively explicit beyond the summary statement (Section 4, Blocks #15 & #17).- Define and contextualize the Bayes-optimal benchmark
     • Formally define the Bayes classifier and Bayes error for the two-patch model under Definitions 3.1–3.2 (Section 3, Block #7) and reference it when claiming “near Bayes-optimal” (Theorems 4.2–4.3, Blocks #13–#14).  
     • Provide a short lemma computing Bayes error as a function of σp,2 and ∥u + v2∥2, and explain the “near Bayes-optimal” terminology in Theorem 4.3 (clarify constants within the exponent).  
     • Add a brief discussion on whether the phase transition thresholds relate to the Bayes error scaling, improving interpretability of the exponential rates.- Polish figures and text to improve readability
     • Reformat Figure 2 (Section 5, Block #22) to standard subplots with clear legends and consistent color scales; avoid Markdown table placeholders.  
     • Audit the manuscript for typos/LaTeX artifacts (e.g., “Condition 3.1”, “width d”, L_S vs L_Task2, Appendix E references) and fix them for clarity (Sections 4–5; Appendix E/F).  
     • Ensure symbol consistency (e.g., consistently use x̄ vs x for trajectories; T*, T** definitions in Section 3 vs usage in Theorem 4.2 and Appendix A/E) to streamline the reading.5) Score
   - Overall (10): 7 — Substantive dynamics-based theory with phase transition and negative-transfer regimes (Theorem 4.2; Proposition 4.4, Section 4) and supportive experiments (Figures 1–3; Table 1), but clarity/reproducibility issues (Condition 3.1 typo; Appendix E references; incomplete real-data details).
   - Novelty (10): 8 — First-principles training-dynamics analysis for partial parameter transfer with explicit positive/negative regimes (Section 1, Block #2; Theorem 4.2; Proposition 4.4) beyond static bounds.
   - Technical Quality (10): 7 — Rigorous decomposition and lemmas (Appendix B–E) with clear conditions (Condition 4.1), but some referencing/definition gaps (Theorem 4.3 “Condition 3.1”; Appendix E’s F.2/F.3; Bayes-optimal definition not explicit).
   - Clarity (10): 6 — Generally well-structured with algorithms and proofs (Sections 3–4; Appendix A), yet marred by notational inconsistencies and missing references (Section 4, Blocks #11, #14; Appendix E, Blocks #108–#109; Figure 2 formatting, Block #22).
   - Confidence (5): 4 — High confidence in reading/assessment of theory and experiments given detailed appendices and multiple figures/tables, with some uncertainty due to referencing typos and limited real-data protocol details.