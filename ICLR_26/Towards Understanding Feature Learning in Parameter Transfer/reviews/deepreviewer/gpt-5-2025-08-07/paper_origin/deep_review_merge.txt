Summary
The paper develops a dynamic theoretical framework for parameter transfer in transfer learning, focusing on two-layer ReLU CNNs where an α fraction of filters from an upstream model are inherited by a downstream model. The data model contains two patches per input, a universal shared signal u, task-specific signals v1 and v2, and Gaussian noise. Under an explicit over-parameterization and training regime (Condition 4.1), the authors analyze gradient descent via a coefficient decomposition of convolutional weights aligned with u, v1, v2, and per-sample noise. They prove a phase transition in downstream generalization (Theorem 4.2): when the dimension d lies below a threshold determined by α, upstream and downstream sample sizes (N1, N2), signal strengths, and noise levels, test error approaches Bayes optimal; otherwise, it is bounded away from optimal. They compare to training from scratch (Theorem 4.3, building on Kou et al., 2023), derive a sufficiency criterion for successful transfer (Proposition 4.4), and characterize negative transfer when universal knowledge is weak. Extensive appendices provide explicit update rules (Lemma B.2), concentration bounds (Lemma C.1), initialization controls (Lemma C.2), and ODE-style approximations for signal learning and noise memorization. Synthetic experiments and real-image experiments on CIFAR-10/100 with ResNet, VGG, and ViT empirically corroborate the main trends, including the roles of α, N1, noise level, and ‖u‖, and demonstrate noise robustness for transfer.

Strengths
- Novel dynamic theory for partial parameter transfer: The paper moves beyond static generalization bounds to analyze training trajectories and explicitly quantify when transfer helps or hurts, including a sharp phase transition in generalization (Theorem 4.2) and comparison to scratch training (Theorem 4.3).
- Rigorous coefficient-level analysis: The decomposition into universal and task-specific components and per-sample noise (Definition B.1), explicit gradient update rules (Lemma B.2), concentration and initialization lemmas (C.1/C.2), and ODE-style approximations underpin a careful and transparent derivation.
- Clear identification of governing factors: The analysis quantifies how α (fraction of inherited filters), N1/N2 (sample sizes), noise levels (σp,1/σp,2), and universal signal strength ‖u‖ drive positive and negative transfer, with a sufficiency criterion for success and conditions for negative transfer (Proposition 4.4).
- Empirical alignment across settings: Synthetic experiments illustrate phase boundaries and the impact of N1, σp,1, and ‖u‖; real-data experiments across CNNs and ViTs show trends consistent with theory, including improved robustness under noise and benefits from larger upstream datasets.
- Comprehensive and organized presentation: The paper is well-structured, with algorithms for random inheritance and training, main statements in the body, and appendices that enable self-verification of key steps.

Weaknesses
- Stylized assumptions limit generality: The data model relies on orthogonality between universal and task-specific signals and between noise and signals, patch-based structure, and a shallow two-layer CNN, which constrain applicability to real-world scenarios and deeper architectures.
- Stringent scaling and training regime: The over-parameterization and small initialization/learning rate requirements in Condition 4.1 are strong and may require very large dimensions, making the proven regime demanding in practice. Claims of “tightness” could be better substantiated with necessity arguments or matching lower bounds.
- Random inheritance versus practical selection: The analysis assumes randomly selected filters are transferred (Algorithm 1), whereas practice often uses learned or heuristic feature selection. This gap may attenuate the negative transfer mechanism or alter phase boundaries under more informed inheritance schemes.
- Presentation and consistency issues: There are notable editorial inconsistencies that hamper verifiability, including a condition reference mismatch (Theorem 4.3 citing Condition 3.1 when Condition 4.1 is defined) and σp misindexing in a training-loss bound (Theorem E.12). The notation is heavy, with occasional mismatched indices and mixed symbols, which reduces clarity.
- Incomplete experimental details: Real-data experiments lack precise reporting on α values, layer-selection strategies across architectures, handling of shape mismatches and batch normalization, training hyperparameters, and variability across random seeds. Negative transfer is convincingly demonstrated in synthetic settings but is not explicitly shown on real datasets.
- Potential sensitivity of conclusions: While the negative transfer explanation is internally consistent under the stylized model, its strength may be reduced when inheritance uses feature-selection heuristics, or when orthogonality assumptions are relaxed—directions that are only briefly acknowledged.
