Summary
The paper proposes a training-free, graph signal processing (GSP) framework to analyze how transformers perform syntactic computations, focusing on voice alternation (active→passive) across 20 languages and three model families (Phi-3-Mini, Qwen2.5-7B, LLaMA-3.2-1B). Attention matrices are treated as dynamic token graphs, hidden states as graph signals, and spectral diagnostics—particularly the Fiedler value λ2—track algebraic connectivity per layer. A prespecified early window (layers 2–5) aggregates Δλ2 = λ2(passive) − λ2(active) to yield “computational fingerprints.” Key findings include an English-specific early-layer disruption in Phi‑3 (Δλ2[2,5] ≈ −0.446), smaller, distributed effects in Qwen, and muted, systematic patterns in LLaMA. The paper reports robustness checks (normalizations, head aggregation, directed variants), links spectral signatures to behavioral performance (NLL; r down to −0.976 for Phi-3), and provides causal evidence via targeted early attention head ablations. It also tentatively generalizes the framework to reasoning strategies via a composite Reconfiguration Change Index (RCI).

Soundness
The methodological core—transforming attention into undirected or Hermitian operators (Sec. 3.1), computing λ2, and comparing passive/active contrasts—is conceptually sound and grounded in spectral graph theory (Appendix A). The prespecified early window (Sec. 3.2) plus bootstrap CIs and permutation tests (Sec. 6.1; App. E) are appropriate for matched contrasts. Robustness to normalization (Lrw vs Lsym), directionality (directed/magnetic Laplacians), and head aggregation (App. B) is a strength. The causal head ablations (Sec. 6.4; Table 4) support mechanistic relevance. However, there are notable issues: (i) the attention-mass head weighting may collapse to uniform if A is strictly row-stochastic (Sec. 3.1), undermining the claimed default aggregation unless masking changes row sums; (ii) sample-size descriptions are inconsistent (10 paraphrases in Sec. 4 vs “three paraphrases” in App. E.1/§77, later “n=50” expansions in App. C), complicating power claims; (iii) very large correlations (e.g., r = −0.976 in Sec. 6.3) with n=20 and potential covariates (tokenization differences, morphology; Sec. 5) warrant stronger preregistered controls or multivariate modeling; (iv) some reported signs for Qwen show slight inconsistencies between narrative and figures (cf. Sec. 6.1 vs Fig. 3).

Presentation
The manuscript is generally clear and well-organized: motivation (Sec. 1), related work (Sec. 2), formal framework (Sec. 3), multilingual design (Sec. 4), tokenizer stress (Sec. 5), results and validation (Sec. 6), generalization (Sec. 7), and limitations (Sec. 8). Equations and operator definitions are explicit (Sec. 3.1; App. B). Figures and tables anchor claims (e.g., Fig. 2–4; Table 2–4), though some figures are low resolution and occasionally crowded, which makes small-magnitude effects hard to read. The appendices provide welcome detail (normalization, directionality, head aggregation, power analysis), but cross-referencing sample sizes and effect conventions could be tightened to avoid confusion.

Contribution
The paper offers a compact, spectral diagnostic for tracking syntactic computation in transformers without training, revealing family-specific fingerprints that correlate with behavior and respond to targeted interventions. Using Δλ2 in a prespecified early window to detect architectural biases is novel in interpretability for LLMs, especially the cross-lingual emphasis and tokenizer-stress covariates. The causal ablation analysis strengthens the claim that early attention structure shapes spectral connectivity, and the preliminary extension to reasoning strategies broadens the framework’s scope. This is a meaningful addition to the toolbox between probing and circuit analysis.

Strengths
- Clear, theoretically grounded use of the Fiedler value as an interpretable connectivity measure (App. A.1–A.2; Sec. 3.2).
- Preregistered early-layer endpoint and matched contrasts with uncertainty quantification (Sec. 3.2; Sec. 6.1; App. E).
- Robustness to operator and aggregation choices, including directed/magnetic Laplacians (App. B.1–B.3).
- Causal validation via attention head ablation profiles that differ by family (Sec. 6.4; Table 4).
- Multilingual scope and tokenizer-stress covariates that disentangle subword fragmentation from syntactic sensitivity (Sec. 5; Table 2).
- Practical framing as training-free diagnostics with preliminary generalization to reasoning modes (Sec. 7.1; App. F).

Weaknesses
- Potential flaw in “mass-weighted” head aggregation: with post-softmax, row-stochastic A, s_h = Σ_i Σ_j A_ij equals N per head, which implies α_h = 1/H (Sec. 3.1) unless masking or padding changes row sums; this needs explicit clarification and perhaps redefinition (e.g., using pre-softmax magnitude or variance).
- Inconsistent sample-size reporting: “at least 10 paraphrases” (Sec. 4), “three paraphrases” (App. §77), and expanded n=50 (App. C) muddy power claims and comparability across figures.
- Very strong spectral–behavioral correlations (Sec. 6.3; r = −0.976 for Phi‑3, n=20) risk overinterpretation without multivariate controls (tokenization drift, morphology, length; Sec. 5, App. E.3).
- Narrative vs. figure alignment issues: Qwen described as uniformly negative early shifts (Sec. 6.1) while Fig. 3 shows several groups close to zero or slightly positive; also, small magnitudes near zero may be within CI overlap.
- Limited detail on ablation implementation (zeroing vs reweighting, per-head hooks, effect on residual streams), statistical significance of Table 4 entries, and whether language/length were held fixed.
- Some aspects of the reasoning generalization (Sec. 7.1) rely on a different model (phi-3.5-mini) and small task sets; methodological details for RCI are brief (App. F) and performance claims are preliminary.

Questions
1. Head aggregation: Given A^(ℓ,h) is row-stochastic post-softmax (Sec. 3.1), does s_h = Σ_ij A_ij equal N for all heads? If so, how does mass-weighted aggregation differ from uniform; are masks/padding altering row sums? Would pre-softmax or variance-based weights be more informative?
2. Sample sizes: Please reconcile “at least 10 paraphrases per voice” (Sec. 4) with “three paraphrases” (App. §77) and the expanded n=50 subsets (App. C). Which figures use which n, and how do CIs/permutation p-values change?
3. Spectral–behavioral correlations: Did you control for tokenization drift (Sec. 5, App. E.3) and language-type in the correlation model (Sec. 6.3)? Could partial correlations or mixed-effects improve robustness?
4. Qwen sign consistency: In Sec. 6.1 you describe uniformly negative early shifts; however, Fig. 3 shows small magnitudes with some near zero. Can you quantify the proportion of languages with CI excluding zero and provide FDR-adjusted q-values per group?
5. Ablations: How were heads ablated (zeroed attention logits/values, gated outputs)? Were ablations repeated across seeds/languages, and are the Table 4 changes statistically significant with CIs?
6. Directed Laplacians: For L→ (App. B.2), you evaluate Hermitian symmetrized forms; can you report sensitivity to θ for Lmag and any cases where the sign of Δλ2 changed vs. undirected?
7. English-specific Phi-3 effect: Could you rule out prompt templates or tokenizer-specific artifacts (Sec. 5) driving the −0.446 outlier (Fig. 2a)? Have you tried different English passive constructions (by-phrases, short passives) and reported stratified results?

Rating
- Overall (10): 7 — A well-motivated, theoretically grounded spectral diagnostic with solid cross-lingual analyses and causal checks, tempered by aggregation ambiguity and sample-size inconsistencies (Sec. 3.1; Sec. 6.1; Table 4; App. §77).
- Novelty (10): 8 — Using Δλ2 as a compact, training-free fingerprint of syntactic processing across architectures is original and useful (Sec. 3.2; Fig. 2–4; App. A).
- Technical Quality (10): 6 — Strong foundations and robustness checks, but the head aggregation definition and correlation modeling need tightening; ablation statistics are underreported (Sec. 3.1; Sec. 6.3; Table 4; App. B–E).
- Clarity (10): 7 — Clear framework and anchors, but figure resolution and cross-figure sample-size clarity could be improved (Sec. 3; Fig. 2–4; App. C/E).
- Confidence (5): 4 — High familiarity with GSP and interpretability; assessment based on detailed reading of methods, figures, and appendices (Sec. 3.1–3.2; App. B–E).

Summary
This manuscript introduces a spectral graph framework for transformer interpretability that analyzes attention-induced token graphs and uses the Fiedler value (λ2) to quantify early-layer connectivity changes under voice alternations. The primary endpoint is the early-window mean Δλ2 (layers 2–5). Across 20 languages, the authors report model-family fingerprints: Phi‑3‑Mini shows a large English-specific disruption (Δλ2 ≈ −0.446), Qwen2.5‑7B shows small, distributed negative shifts, and LLaMA‑3.2‑1B exhibits muted but systematic effects. They correlate spectral signatures with behavioral NLL differences and conduct head ablation experiments to argue causal relevance. The framework is extended to reasoning strategies via an RCI metric.

Soundness
The approach of constructing Laplacian operators from attention (Sec. 3.1), prespecifying an early window (Sec. 3.2), and using matched contrasts with bootstrap and permutation tests (Sec. 6.1) is sound for observational analysis. Robustness checks across normalization and directionality (App. B) and mixed-effects tokenizer covariates (Sec. 5) increase credibility. The causal head ablations (Sec. 6.4; Table 4) are a valuable addition. Still, several aspects need tightening: the head-aggregation weighting appears mathematically equivalent to uniform if A is strictly row-stochastic (Sec. 3.1); some reported signs and magnitudes for Qwen are near-zero and may not be statistically distinguishable (Fig. 3); the extraordinarily strong spectral–behavioral correlation (r = −0.976, Sec. 6.3) could be inflated by language/morphology or tokenization covariates.

Presentation
Overall organization is strong, with clear mathematical definitions and comprehensive appendices (App. A–G). Figures provide anchors, though several are low resolution and small effect sizes are hard to visually parse (e.g., Fig. 4). The text occasionally overstates uniformity (e.g., Qwen negative shifts, Sec. 6.1) relative to plots, and sample-size reporting is inconsistent across sections (Sec. 4 vs App. §77 vs App. C). The RCI metric for reasoning is defined briefly (App. F), and its interpretation could benefit from more exposition.

Contribution
The paper contributes a compact, interpretable, training-free diagnostic for architectural fingerprints in transformers, linking spectral connectivity to both behavior and attention interventions. The multilingual perspective and tokenizer-stress analysis illuminate cross-architectural sensitivities. The work fills a gap between circuit-level mechanistic analyses and probing by offering a scalable, layer-resolved audit tool.

Strengths
- Solid theoretical justification for λ2 with clear link to global connectivity (App. A.1–A.2).
- Preregistered early-layer endpoint with matched contrasts and uncertainty quantification (Sec. 3.2; Sec. 6.1).
- Extensive robustness to operator choices and directed variants (App. B.1–B.2).
- Family-specific causal ablation profiles (Sec. 6.4; Table 4) supporting functional relevance.
- Cross-lingual breadth and explicit accounting for tokenization granularity (Sec. 5; Table 2).
- Sensible limitations and ethical framing (Sec. 8; App. G–I).

Weaknesses
- Head aggregation weighting may be vacuous under row-stochastic attention; requires clarification or alternative scheme (Sec. 3.1; App. B.3).
- Sample-size inconsistencies (Sec. 4: 10 paraphrases; App. §77: “three paraphrases”; App. C: n=50) obscure the strength of statistical claims and figure comparability.
- Potential overinterpretation of near-zero Qwen effects: CIs overlapping zero and small g_trim values need more cautious language (Fig. 3; Sec. 6.1).
- Spectral–behavioral correlations lack multivariate controls and may reflect confounds (Sec. 6.3; Sec. 5; App. E.3).
- Ablation methodology and statistical significance of Table 4 entries are not fully detailed; replication across languages/seeds is unclear (Sec. 6.4).
- Reasoning generalization uses a different model (phi‑3.5‑mini) and is preliminary; methodological specifics for RCI aggregation are brief (Sec. 7.1; App. F).

Questions
1. Can you confirm whether attention-mass head weights differ from uniform under post-softmax, row-stochastic A (Sec. 3.1)? If they do, what causes head-to-head differences (masking, padding), and how large are they?
2. Please standardize and report n per figure/table: which analyses use n=10 vs n=3 vs n=50 (Sec. 4; App. §77; App. C), and provide effect-size/p-value changes across n.
3. For Qwen, how many language-level Δλ2[2–5] effects have CIs excluding zero after BH–FDR (Fig. 3; Sec. 6.1)?
4. In Sec. 6.3, did you fit mixed-effects models to partial out tokenization fragmentation and language-type effects (Sec. 5), or compute partial correlations?
5. Specify ablation implementation details (e.g., zeroing attention outputs vs logits, handling residual connections) and report CIs/p-values for Table 4 windows; did you verify across multiple seeds/languages?
6. For directed/magnetic Laplacians, please quantify any cases of sign reversals or >15% magnitude changes (App. B.2) and sensitivity to θ.
7. For Phi‑3 English passives (Δλ2 ≈ −0.446; Fig. 2a), can you provide stratified analyses by passive subtype (long vs short, by-phrase vs agentless) and tokenization drift bins?

Rating
- Overall (10): 7 — Valuable, well-argued framework with strong validation and interesting cross-lingual findings, but aggregation and statistical reporting need clarification (Sec. 3.1; Sec. 6.1; Sec. 6.3; Table 4).
- Novelty (10): 8 — Compact spectral fingerprints for syntactic computation across architectures are original and insightful (Sec. 3.2; Sec. 6.1–6.4; App. A).
- Technical Quality (10): 7 — Solid core and robustness, yet head-weighting and correlation controls should be strengthened; ablation stats are thin (Sec. 3.1; Sec. 6.3; Table 4; App. B–E).
- Clarity (10): 7 — Clear math and structure, but figures/resolution and sample-size consistency could improve (Fig. 2–4; Sec. 4; App. C/E).
- Confidence (5): 4 — Confident based on detailed methodological evaluation and appendices; some results hinge on clarifications (Sec. 3.1; Sec. 6.3; App. B–E).

Summary
The authors present a GSP-based interpretability method that transforms multihead attention into token graphs, computes Laplacians, and tracks spectral quantities—especially the Fiedler value λ2—to capture early-layer connectivity changes during voice alternation. They find strong architectural fingerprints: an English-specific disruption for Phi‑3‑Mini, smaller distributed effects in Qwen2.5‑7B, and systematic moderate effects in LLaMA‑3.2‑1B. They validate robustness across operator choices, correlate spectral effects with behavioral NLL differences, and perform targeted attention head ablations to argue causal relevance. Tokenizer fragmentation covariates reveal family-specific sensitivities.

Soundness
The spectral formulation is rigorous and appropriate for attention-induced graphs (Sec. 3.1; App. A). Using Δλ2[2–5] aligns with early multihead integration and is preregistered (Sec. 3.2). Statistical procedures (bootstrap CIs, paired permutation tests, BH–FDR; Sec. 6.1; App. E) are suitable for matched contrasts. The tokenizer-stress analysis (Sec. 5; Table 2) and directed/magnetic variants (App. B) are thoughtful. Concerns include: the potential equivalence of “mass-weighted” head aggregation to uniform under row-stochastic A; sample-size variation undermining consistency; and extremely high correlation magnitudes with small n. The causal ablations (Table 4) are promising but require more detail and statistical treatment.

Presentation
The manuscript is comprehensive and well-structured, with clear math and extensive appendices. However, several figures are low resolution (e.g., Fig. 2, Fig. 4) and small effects are visually hard to discern. The text occasionally overgeneralizes signs relative to plots. Sample-size reporting is inconsistent across sections, which affects reader confidence in the statistical strength of effects per figure.

Contribution
The work advances interpretability by offering a scalable, training-free diagnostic to compare architectures on a controlled syntactic operation, revealing model-family signatures backed by both correlational and intervention evidence. The cross-lingual design and tokenizer-stress covariates provide a nuanced view of architectural sensitivities. The extension to reasoning hints at broader utility, though preliminary.

Strengths
- Strong theoretical grounding and compact endpoint (Δλ2[2–5]) with interpretability (Sec. 3.2; App. A).
- Robustness across graph operators and aggregation choices (App. B.1–B.3).
- Multilingual scope with thoughtful controls and uncertainty quantification (Sec. 4; Sec. 6.1; App. E).
- Family-specific ablation profiles suggesting causal roles for early attention (Sec. 6.4; Table 4).
- Tokenization covariates disentangle subword fragmentation from syntactic sensitivity (Sec. 5; Table 2).
- Explicit limitations and ethics (Sec. 8; App. G–I).

Weaknesses
- Head aggregation weighting may mathematically degenerate to uniform given post‑softmax row-stochastic attention; needs explicit resolution (Sec. 3.1).
- Sample-size inconsistency across sections (Sec. 4 vs App. §77 vs App. C) undermines interpretation of significance and robustness.
- Overinterpreting small near-zero effects for Qwen; more explicit reporting of CI overlaps and q-values is needed (Fig. 3; Sec. 6.1).
- Very strong spectral–behavioral correlations (Sec. 6.3) with n=20 should include multivariate controls; language/morphology and tokenization differences may confound.
- Ablation methods and significance of Table 4 not fully specified; repeatability across seeds/languages unclear.
- Reasoning generalization (Sec. 7.1) is preliminary and uses a different model; RCI definition (App. F) is brief.

Questions
1. How does mass-weighted aggregation avoid degenerating to uniform under row-stochastic A; do masked/padded tokens alter row sums materially, and can you quantify α_h variation across heads/layers (Sec. 3.1)?
2. Please standardize sample-size reporting and annotate figures with n (Sec. 4; App. §77; App. C); provide how CIs and q-values change between n=10 and n=50.
3. For Qwen, how many language-level Δλ2[2–5] effects are FDR-significant, and what are their magnitudes (Fig. 3)?
4. In Sec. 6.3, did you include tokenizer covariates (pieces/char, fragmentation entropy) and voice-type as fixed effects in a mixed model; provide partial correlations?
5. Provide ablation implementation details (e.g., zeroing vs gating), seed repeats, and CIs/p-values for Table 4 entries.
6. Report sensitivity of directed/magnetic Laplacians to θ and any sign/magnitude deviations ≥15% (App. B.2).
7. For Phi‑3 English passives, can you show stratification by passive subtype and tokenization drift bins (≤2 vs >2 tokens) to further rule out tokenization artifacts (Sec. 5; Fig. 2a)?

Rating
- Overall (10): 7 — Strong conceptual contribution and solid empirical program with some methodological and reporting gaps (Sec. 3.1; Sec. 6.1–6.4; Table 2–4; App. B–E).
- Novelty (10): 8 — Δλ2 fingerprints across languages/models are a fresh, interpretable lens on transformer computation (Sec. 3.2; Fig. 2–4; App. A).
- Technical Quality (10): 7 — Well-grounded and robust analyses; needs clarification on aggregation and correlation controls; ablation statistics incomplete (Sec. 3.1; Sec. 6.3; Table 4).
- Clarity (10): 7 — Clear math and structure; figure readability and consistent sample-size reporting should improve (Fig. 2–4; Sec. 4; App. C/E).
- Confidence (5): 4 — High confidence based on deep engagement with methods and appendices; some claims depend on clarifications (Sec. 3.1; Sec. 6.3; App. B–E).

Summary
This paper frames transformer attention as dynamic token graphs and uses spectral diagnostics—especially the Fiedler value—to capture early-layer connectivity changes during voice alternation across languages and model families. The main endpoint (Δλ2[2–5]) reveals family-specific fingerprints (large English-specific disruption in Phi-3, small distributed Qwen effects, moderate LLaMA effects). Robustness to graph operator choices, tokenizer-stress covariates, correlations with behavioral NLL, and targeted head ablations support the interpretability and functional relevance of the approach. Preliminary results suggest broader applicability to reasoning strategies.

Soundness
The mathematical setup is solid and appropriately justified (Sec. 3.1; App. A). The early-window choice is motivated and tested (Sec. 3.2; App. B.4). Statistical procedures (bootstrap, permutation, FDR) are suitable for the matched design (Sec. 6.1; App. E). The tokenizer-stress modeling (Sec. 5) is a thoughtful attempt to separate confounds. Causal ablations (Sec. 6.4) are an asset. Yet the aggregation weighting may not behave as intended under row-stochastic attention (Sec. 3.1), and the reported extremely strong correlations (Sec. 6.3) need multivariate robustness. Some narrative claims (uniform negatives) do not perfectly match figures with small magnitudes and overlapping CIs (Fig. 3). The reasoning generalization is preliminary and uses a different model.

Presentation
The paper is well-structured and readable; equations and definitions are clear, and appendices are rich with details. Figures are informative but sometimes low-resolution, making small differences hard to assess. Sample-size references vary across sections (Sec. 4 vs App. §77 vs App. C), which should be standardized. The ablation methodology needs more explicit description.

Contribution
The work offers a compact, interpretable, and training-free method to reveal architectural processing differences, linking spectral fingerprints to behavior and attention structure. It contributes a practical diagnostic for multilingual model audits and adds a causal angle to spectral interpretability. The idea of treating λ2 as a computational fingerprint for syntactic transformations is impactful.

Strengths
- Clear theoretical grounding and compact endpoint (Sec. 3.2; App. A).
- Thorough robustness checks for operator choices and directionality (App. B).
- Multilingual dataset and tokenizer-stress covariates (Sec. 4–5; Table 2).
- Causal validation via head ablations with distinct family profiles (Sec. 6.4; Table 4).
- Ethical and limitation discussion is careful and appropriate (Sec. 8).

Weaknesses
- Head aggregation weighting likely reduces to uniform under row-stochastic A; needs clarification or alternative (Sec. 3.1).
- Inconsistent sample-size reporting; difficult to compare figures’ statistical strength (Sec. 4; App. §77; App. C).
- Overinterpretation risk for tiny effects (Qwen near zero) with overlapping CIs (Fig. 3).
- Spectral–behavioral correlations (Sec. 6.3) require stronger controls; tokenization drift and morphology may confound.
- Ablation details (implementation, stats) are sparse; repeatability across languages/seeds is unclear (Sec. 6.4).
- Reasoning generalization (Sec. 7.1) is preliminary and uses a different model; RCI description is brief (App. F).

Questions
1. Can you demonstrate that mass-weighted α_h (Sec. 3.1) differs meaningfully from uniform across layers/heads, and explain the source (masking, padding, head sparsity)?
2. Please provide a unified table stating n per language/figure and the effect on CI widths/p-values across n=10 vs n=50 (Sec. 4; App. C).
3. For Qwen, quantify how many per-language effects exclude zero after BH–FDR and list magnitudes (Fig. 3).
4. In Sec. 6.3, did you include partial correlations controlling for pieces/char and fragmentation entropy (Sec. 5), and/or mixed-effects by language?
5. Detail ablation implementation (exact hooks, logits/values), report CIs/p-values for Table 4, and indicate replication across seeds/languages.
6. Report θ-sensitivity for Lmag and any sign/magnitude deviations ≥15% relative to undirected (App. B.2).
7. Provide stratified Phi‑3 English passive analyses by subtype (long/short by-phrase) and tokenization drift to rule out artifacts (Fig. 2a; Sec. 5).

Rating
- Overall (10): 7 — A compelling and well-founded diagnostic with strong validation, tempered by aggregation ambiguity, sample-size consistency issues, and overinterpretation risks (Sec. 3.1; Sec. 6.1–6.4; Fig. 2–4; Table 2–4).
- Novelty (10): 8 — The early-layer Δλ2 fingerprinting across languages and models is a fresh contribution to interpretability (Sec. 3.2; Sec. 6.1; App. A).
- Technical Quality (10): 7 — Robust core; needs clarified aggregation, multivariate correlation controls, and ablation stats (Sec. 3.1; Sec. 6.3; Table 4).
- Clarity (10): 7 — Clear exposition; figure resolution and standardized n reporting should be improved (Fig. 2–4; Sec. 4; App. C/E).
- Confidence (5): 4 — Confident based on thorough reading, but some claims hinge on clarifications and additional stats (Sec. 3.1; Sec. 6.3; App. B–E).

Summary
The paper proposes a graph signal processing approach to interpret transformer computations by analyzing attention-induced token graphs and measuring spectral connectivity changes via the Fiedler value λ2. With a prespecified early window (layers 2–5), Δλ2 between passive and active sentences is used to identify architectural fingerprints across languages and model families. Results include a large English-specific effect for Phi-3-Mini, smaller distributed effects for Qwen2.5‑7B, and moderate systematic effects for LLaMA‑3.2‑1B. Robustness checks, tokenizer-stress covariates, behavioral correlations, and head ablations support the claims. Preliminary evidence extends the framework to reasoning strategy differences.

Soundness
The framework is grounded in well-established spectral graph theory (App. A), and the construction of W, L, and λ2 is appropriate (Sec. 3.1). The early-window endpoint is defensible and tested for stability (Sec. 3.2; App. B.4). Statistical validation (bootstrap, permutation, FDR; Sec. 6.1; App. E) is suitable. The tokenizer-stress modeling (Sec. 5) and directed/magnetic Laplacian checks (App. B.2) are welcome. Concerns: head aggregation weights may default to uniform under row-stochastic attention; reported correlations with behavior are very large for small n; some figures and narrative do not perfectly align on the sign/magnitude of small Qwen effects; ablation methodology details and statistical significance are limited.

Presentation
The paper is readable and carefully structured. Equations and algorithmic choices are explicit. Figures provide anchors but are sometimes low-resolution; small-magnitude differences are difficult to assess visually. Sample-size reporting varies; unify to help readers evaluate robustness. The appendices are comprehensive and useful, though cross-references could be streamlined.

Contribution
This work contributes a practical, interpretable, training-free diagnostic to compare architectures on a controlled syntactic computation, revealing family-level processing strategies and linking them to behavior and interventions. It complements probing and circuit analysis with a scalable spectral lens. The cross-lingual and tokenizer-stress components add nuance, and the preliminary reasoning extension hints at generality.

Strengths
- Theoretical motivation for λ2 and interpretability of Δλ2 as connectivity change (Sec. 3.2; App. A).
- Preregistered early-layer endpoint and matched contrasts with robust uncertainty quantification (Sec. 3.2; Sec. 6.1).
- Robustness across normalization, directionality, and aggregation variants (App. B.1–B.3).
- Causal validation via head ablations with family-specific profiles (Sec. 6.4; Table 4).
- Cross-lingual design and tokenizer-stress covariates (Sec. 4–5; Table 2).
- Clear limitations and ethics (Sec. 8).

Weaknesses
- Head aggregation weighting may be ineffective under row-stochastic A; needs explicit resolution (Sec. 3.1; App. B.3).
- Sample-size reporting inconsistencies (Sec. 4 vs App. §77 vs App. C); figures should indicate n and CIs consistently.
- Potential overstatement of uniform negative Qwen effects given small, near-zero magnitudes with overlapping CIs (Fig. 3; Sec. 6.1).
- Spectral–behavioral correlations (Sec. 6.3) require multivariate controls; tokenization drift and morphology may confound.
- Ablation implementation and statistical significance are not fully specified; replication across seeds/languages unclear (Sec. 6.4).
- Reasoning extension is preliminary and uses a different model; RCI needs more exposition (Sec. 7.1; App. F).

Questions
1. Under post-softmax, row-stochastic attention (Sec. 3.1), do head weights α_h differ from uniform in practice; if so, why? Please provide empirical distributions of α_h across layers/heads.
2. Please standardize n reporting across figures and quantify how CI widths/p-values change between n=10 and n=50 (Sec. 4; App. C).
3. For Qwen, provide the count of FDR-significant language-level effects and their magnitudes to support the “uniformly negative” narrative (Fig. 3; Sec. 6.1).
4. In Sec. 6.3, can you provide partial correlations/mixed-effects models controlling for tokenizer fragmentation and voice-type (Sec. 5; App. E.3)?
5. Detail ablation implementation (logit/value zeroing, residual handling), report CIs/p-values for Table 4 entries, and indicate replication across seeds and languages.
6. Quantify θ-sensitivity for the magnetic Laplacian and any sign/magnitude changes vs. undirected (App. B.2).
7. For Phi‑3 English passive disruptions (Fig. 2a), provide stratified analyses by passive subtype and tokenization drift bins to strengthen the specificity claim.

Rating
- Overall (10): 7 — A solid, interpretable framework with compelling cross-lingual fingerprints and causal checks, moderated by aggregation and statistical reporting concerns (Sec. 3.1; Sec. 6.1–6.4; Table 2–4; App. B–E).
- Novelty (10): 8 — The use of Δλ2 as a compact architectural fingerprint across languages/models is novel and impactful (Sec. 3.2; Fig. 2–4; App. A).
- Technical Quality (10): 7 — Strong modeling and robustness; needs clarification on aggregation, correlation controls, and ablation stats (Sec. 3.1; Sec. 6.3; Table 4).
- Clarity (10): 7 — Clear structure and math; improve figure resolution and consistent n reporting (Fig. 2–4; Sec. 4; App. C/E).
- Confidence (5): 4 — Confident based on detailed examination; key clarifications will solidify the assessment (Sec. 3.1; Sec. 6.3; App. B–E).