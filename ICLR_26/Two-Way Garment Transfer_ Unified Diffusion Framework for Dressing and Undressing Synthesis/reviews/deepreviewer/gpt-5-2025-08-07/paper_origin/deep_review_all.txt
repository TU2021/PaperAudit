Summary
The paper introduces Two-Way Garment Transfer Model (TWGTM), a unified diffusion-based framework that jointly tackles virtual try-on (VTON) and virtual try-off (VTOFF). The core idea is bidirectional feature disentanglement and dual-space conditioning: spatial concatenation in latent space to preserve garment/body topology, and pixel-space processing via a Semantic Abstraction Module (CLIP + QFormer) and a Spatial Refinement Module (Swin + TaskFormer), fused with an Extended Attention Block featuring a zero-initialized linear gate. A phased training strategy bridges the asymmetry in mask availability (mask-guided VTON vs. mask-free VTOFF) by first learning canonical garment masks and later using morphologically augmented square masks. Experiments on VITON-HD and DressCode report competitive or state-of-the-art results, with ablations supporting design choices.

Soundness
Methodologically, the latent-space construction (Section: Method, “Processing in Latent Space” and Eq. (1–2)) is standard for LDMs, and the input triplet I_t = [noised(z(h_i)), z(h_f), resized(h_m)] is clearly defined for both VTON and VTOFF (with reversed spatial order). The rationale that concatenation order switches task direction is plausible and supported by cross-model weight/output similarities (Figure 1(a–b)). The pixel-space design—CLIP+QFormer semantic filtering (Eq. (3–4)), multi-scale spatial refinement with masked attention (Eq. (5–12)), and gated fusion (Eq. (13))—is consistent with contemporary transformer practices. The phased training (Eq. (14–16)) addresses mask asymmetry by first supervising mask prediction and later enforcing shape awareness.

However, two assumptions warrant caution. First, the claim of an “implicit unified deformation field” is not directly instantiated or quantified; the approach learns to condition generation on feature order and pixel-space cues rather than an explicit invertible mapping. Second, the Stage-2 use of square masks (erosion/dilation) introduces a distribution shift relative to real garment boundaries; Variant 3 (“Mask2BBox”) helps VTOFF (Table 4), but suggests sensitivity to mask geometry. Self-checking these concerns against results: quantitative VTON (Tables 1–2) are strong, VTOFF gains (Table 3) are consistent across multiple metrics (SSIM-family, LPIPS, FID/KID, DISTS), and ablations (Table 4; Figures 5–6) substantiate the necessity of SRM, SAM, spatial concatenation, and the proposed fusion. Missing training hyperparameters (e.g., λ, λ’, λ’’) and inference details (e.g., diffusion steps T, compute cost) limit full verification.

Presentation
The paper is generally clear, with helpful diagrams of the pipeline and modules (Figure 2(b–c); Figures 10–11). The mathematical notation is mostly coherent, and the task conditioning signals (target/guidance/mask-guided features) are spelled out. Abundant quantitative tables (Tables 1–4) and qualitative figures (Figures 3–6, 8–9) support claims. That said, there are notable presentation issues: a caption/content mismatch for Figure 4 (text refers to VTOFF, caption says VTON); limited details on the similarity analysis protocol in Figure 1; and omissions of key training/inference settings (e.g., noise schedules, step counts, learning rates, batch sizes). The appendix is referenced, but critical parameters should be summarized in the main paper for reproducibility.

Contribution
TWGTM’s primary contribution is to unify VTON and VTOFF within a single diffusion framework by reversing latent concatenation order and complementing it with dual-space conditioning and phased training. While several components build on known ideas (concatenation à la CatVTON, CLIP-based semantic conditioning, Mask2Former-style masked attention, BLIP-2 QFormer), their integration for two-way garment manipulation is novel and practically valuable. The experimental evidence that fine-tuning one task helps the other (Figures 7–8) underscores the shared modeling capacity. The significance is moderate-to-high for the VTON/VTOFF community, especially as it reduces system fragmentation and improves maintainability.

Strengths
- Unified treatment of VTON and VTOFF with bidirectional conditioning, supported by cross-task similarity analyses (Figure 1(a–b)) and consistent gains across tasks.
- Strong quantitative results for VTON (Tables 1–2) and VTOFF (Table 3), with SSIM/DINO/LPIPS/FID improvements and lowest DISTS for VTOFF.
- Careful ablations (Table 4, Figures 5–6) that isolate the value of SRM, SAM, spatial concatenation, and the Extended Attention Block.
- Sensible training strategy to mitigate mask asymmetry; Stage-1 mask supervision plus Stage-2 shape awareness improves robustness (Eq. (14–16), Variant analyses).
- Practical insights on controllability via rectangular masks (Variant 3) and cross-task fine-tuning effects (Figures 7–8).

Weaknesses
- The “implicit unified deformation field” claim lacks a formal definition or measurement; the method does not explicitly learn/invert a deformation map.
- Reproducibility gaps: missing hyperparameters (λ, λ’, λ’’ in Eq. (14–15)), diffusion steps/schedule, optimizer settings, training compute/time, and code availability.
- Evaluation coverage: VTOFF is reported on VITON-HD only (Table 3) with no DressCode VTOFF metrics; lower-body/dresses VTOFF are not quantitatively demonstrated.
- Efficiency is unreported: no runtime, memory, or throughput vs. baselines; the added modules (TaskFormer, Decoder, Extended Attention) likely affect latency.
- Presentation inconsistencies (Figure 4 caption), and limited elaboration on Figure 1 analysis methodology and thresholds (similarity computation).
- Potential sensitivity to mask geometry (square masks in Stage-2, Variant 3) suggests reliance on shape priors that may not generalize to complex boundaries.

Questions
1. Can you formalize the notion of the “implicit unified deformation field” and provide a diagnostic (e.g., learned attention flow visualization or cycle-consistency) to substantiate invertibility between VTON and VTOFF?
2. What are the exact training/inference hyperparameters: λ, λ’, λ’’ (Eq. (14–15)), diffusion steps T, β schedule, optimizer, learning rate, batch size, and training duration? Any guidance for reproducing Table 3?
3. How sensitive is TWGTM to mask geometry (Stage-2 square masks, Variant 3)? Have you evaluated robustness with irregular/learned masks and on garments with complex boundaries (e.g., lace, ruffles)?
4. Could you report VTOFF on DressCode (upper/lower/dresses) to establish multi-category generalization? If unavailable, explain constraints and provide qualitative evidence.
5. What is the computational footprint (params, GPU memory, training/inference time) compared to CatVTON/TryOffDiff/TryOffAnyone? Does Extended Attention materially impact latency?
6. How is the similarity analysis in Figure 1 computed (layers selected, normalization, thresholds), and can you add statistical significance tests?
7. Could you release code or provide a detailed pseudo-implementation of I_t construction (Figure 2(a)), mask predictor training, and Extended Attention integration to enhance reproducibility?

Rating
- Overall (10): 7 — Strong empirical results and a practically meaningful unified framework, but claims about a unified deformation field and missing reproducibility details temper impact (Tables 1–4; Eq. (14–16); Figure 1).
- Novelty (10): 7 — The bidirectional setup and dual-space conditioning are novel in combination, though many parts are adapted from existing components (Figure 2(b–c); SAM/SRM; CatVTON-like concatenation).
- Technical Quality (10): 7 — Sound LDM-based design with rigorous ablations; however, formalization/measurement of the “unified field” and efficiency reporting are lacking (Eq. (3–13); Table 4).
- Clarity (10): 6 — Pipeline diagrams help, but caption mismatches and missing hyperparameters hinder reproducibility (Figure 4; references to appendix).
- Confidence (5): 4 — Confidence based on consistent quantitative/qualitative evidence and thorough ablations, with minor uncertainties due to unreported settings and efficiency.


Summary
TWGTM proposes a single diffusion model to handle both VTON and VTOFF by reversing the latent concatenation order and augmenting conditioning in pixel space (SAM + SRM) with an Extended Attention Block. A phased training protocol manages mask asymmetry across tasks. Results on VITON-HD and DressCode show competitive performance; ablations indicate the necessity of each module and demonstrate cross-task benefits from fine-tuning.

Soundness
The latent-space formulation (Eq. (1–2); “Processing in Latent Space”) correctly applies LDM principles, and the explicit definitions of h_i, h_f, h_m and I_t make the conditioning mechanism auditable. Pixel-space modules—QFormer-based semantics (Eq. (3–4)) and TaskFormer masked attention (Eq. (5–12))—are standard yet fit for garment-focused spatial reasoning. The Extended Attention Block (Eq. (13)) is a reasonable architectural choice, and zero-initialized gating is a common stabilization technique.

Self-verification against the paper’s claims surfaces two issues. First, while Figure 1 suggests cross-task parameter/output similarity, the analysis methodology is not fully described (thresholding, layers), weakening the argument that only small architectural changes suffice. Second, the switch from true garment masks to square masks in Stage-2 (Section: Training Strategy) may bias geometry learning; Variant 3 (Table 4) improves VTOFF when using rectangles, hinting that gains partly come from stronger geometric priors rather than learned boundary inference. Nevertheless, the quantitative tables (1–3) and ablations (Table 4) consistently indicate the approach works.

Presentation
Figures of the pipeline and attention block (Figure 2(b–c)) are informative, and the math is mostly clean. However, key implementation details are missing in the main text (loss weights, training schedule, inference steps). Figure 4’s caption does not match the surrounding discussion (VTOFF vs. VTON). The analysis plots (Figures 7–8) are helpful but would benefit from error bars/variance reporting. Overall readability is good; reproducibility detail is insufficient.

Contribution
Integrating VTON and VTOFF in one diffusion framework is a valuable practical step; the design shows that a shared model can serve complementary tasks with modest conditioning changes. The dual-space conditioning and phased training are sensible contributions. Novelty is incremental at the component level but meaningful at the system level, especially with empirical proof that task fine-tuning benefits the other task (Figures 7–8).

Strengths
- Unified bidirectional conditioning in latent and pixel spaces with clear module interfaces (Figure 2(b); Eq. (3–13)).
- Robust empirical gains across metrics for both tasks (Tables 1–3) and strong ablations (Table 4; Figures 5–6).
- Practical insight: rectangular masks enable controllable customization for VTOFF (Variant 3).
- Evidence of task synergy through fine-tuning (Figures 7–8).

Weaknesses
- Lack of formalization/evidence for the “implicit unified deformation field”; no cycle-consistency or flow visualization.
- Missing training/inference hyperparameters and efficiency comparisons hinder reproducibility and deployment assessment.
- Evaluation for VTOFF limited to VITON-HD; no multi-category DressCode evaluation on VTOFF.
- Presentation inconsistencies (Figure 4 caption) and limited explanation of Figure 1 similarity metrics.

Questions
1. Please provide details on the weight/output similarity computation in Figure 1 (layers, metrics, thresholds) and its statistical robustness.
2. Can you demonstrate cycle-consistency (VTOFF→VTON→original) or attention-flow visualizations to substantiate the “unified deformation field” claim?
3. What are the exact training hyperparameters (λ, λ’, λ’’; learning rates; steps; β schedules), and inference costs (time/steps), and how do they compare to baselines?
4. Have you evaluated VTOFF on DressCode categories (lower/dresses)? If not, what prevents it—annotation availability, mask prediction reliability?
5. How sensitive is performance to the square-mask training in Stage-2? Would learned boundary masks or irregular masks improve generalization?

Rating
- Overall (10): 6 — A practically useful unified system with strong empirical support, but limited formalization of core claims and missing reproducibility/efficiency details (Tables 1–3; Figures 2, 7–8).
- Novelty (10): 6 — System-level unification is novel; many components are adaptations of known modules (Figure 2(b–c); SAM/SRM; Mask2Former/QFormer).
- Technical Quality (10): 6 — Solid design/ablations, yet key methodological assertions are not rigorously validated; efficiency unreported (Eq. (3–13); Table 4).
- Clarity (10): 7 — Good high-level exposition and diagrams; some caption/analysis gaps and missing hyperparameters (Figure 4; references to appendix).
- Confidence (5): 4 — Confidence grounded in consistent metrics and ablations; reservations due to absent training/inference specifics and analysis formalization.


Summary
This work presents TWGTM, a unified latent diffusion framework for VTON and VTOFF. The model builds dual conditioning: latent-space spatial concatenation to preserve topology, and pixel-space feature streams via a CLIP+QFormer Semantic Abstraction Module and a Swin+TaskFormer Spatial Refinement Module. An Extended Attention Block fuses these with UNet features through a zero-initialized gate. A two-stage training regime first supervises mask prediction (VTOFF) and then enforces shape awareness with square masks. Experiments on VITON-HD and DressCode demonstrate competitive/superior performance; ablations justify module choices.

Soundness
The approach is technically coherent and aligned with established LDM practices (Eq. (1–2)). The conditioning tensors and mask handling are defined (Section: Method, “Processing in Latent Space”), and the fusion mechanism (Eq. (13)) is appropriate for integrating spatial and semantic cues. TaskFormer’s masked attention (Eq. (5–11)) is a logical choice for garment regions. Self-verification: cross-checking the claims against evidence, Tables 1–3 show consistent improvements, and ablations (Table 4; Figures 5–6) reveal that removing SRM or QFormer degrades quality, supporting the dual-stream design. The main conceptual leap—switching concatenation order to obtain two “directions”—works empirically, but the theory of a unified/invertible deformation field remains qualitative.

Areas that need clarification to ensure methodological soundness include exact loss weights (Eq. (14–15)), mask generation details (canonical mask from flattened garment c), and the rationale for square masks in Stage-2 vs. real garment boundaries. Efficiency and generalization are not discussed.

Presentation
The narrative is structured and readable, with modular diagrams (Figure 2(b–c)). Mathematical notation is consistently introduced, and experimental tables are clear. Nonetheless, some details critical for reproduction are relegated to the appendix and not summarized in the main text (hyperparameters, compute). Figure 4’s caption conflict (VTON vs. VTOFF) should be fixed. The similarity analysis in Figure 1 would benefit from methodological description in-text.

Contribution
The main contribution is a single diffusion framework for two traditionally separate tasks with minimal architectural change, demonstrating shared capacity and cross-task benefits. The dual-space conditioning and staged training are practical innovations. While many parts are adaptations of existing techniques, the integration for bidirectional garment manipulation is new and relevant, especially for unified fashion pipelines.

Strengths
- Unified model across VTON/VTOFF with clear conditioning design (Figure 2(a–c); Eq. (3–13)).
- Strong results across diverse metrics (Tables 1–3) with best or near-best scores.
- Thorough ablation suite demonstrating necessity of components (Table 4; Figures 5–6).
- Practical insights on task coupling and fine-tuning benefits (Figures 7–8).

Weaknesses
- Limited theoretical justification/evidence for “unified deformation field.”
- Missing reproducibility essentials (hyperparameters, training schedules, inference steps/costs, code).
- VTOFF evaluation limited in scope; no DressCode VTOFF metrics and limited category coverage.
- No efficiency benchmarks; deployment implications unclear.
- Minor presentation issues (Figure 4 caption; insufficient description of Figure 1 methodology).

Questions
1. Can you provide quantitative diagnostics (e.g., cycle-consistency or alignment scores) that support the “implicit unified deformation field” claim?
2. What are the exact λ, λ’, λ’’ values (Eq. (14–15)), and other training details (optimizer, LR, batch size, T, β schedule)?
3. How does TWGTM’s inference speed/compute compare to CatVTON and TryOffAnyone? Please report latency and memory.
4. Could you extend VTOFF evaluation to DressCode and report category-wise results, including lower garments and dresses?
5. What is the impact of varying mask shapes beyond rectangles in Stage-2 (e.g., irregular masks approximating real garment boundaries)?
6. Please clarify how canonical masks are derived from c and whether errors in c’s segmentation propagate to VTOFF training.

Rating
- Overall (10): 6 — Useful unified system with solid empirical evidence; theoretical framing and reproducibility/efficiency details are incomplete (Tables 1–3; Figure 2; Eq. (14–16)).
- Novelty (10): 6 — Integration is novel for the application; components are largely established (SAM/SRM; Mask2Former/QFormer; concatenation).
- Technical Quality (10): 6 — Method is sound and validated by ablations, but lacks formal analysis and efficiency reporting (Table 4; Figure 1; Eq. (13)).
- Clarity (10): 6 — Generally clear with good figures; missing key training details and minor caption mismatch (Figure 4).
- Confidence (5): 3 — Moderate confidence; results are promising, but missing hyperparameters and efficiency hinder verification.


Summary
The paper proposes TWGTM, a unified diffusion framework that handles both mask-guided VTON and mask-free VTOFF. The design combines latent-space spatial concatenation with pixel-space dual branches (Semantic Abstraction via CLIP+QFormer and Spatial Refinement via Swin+TaskFormer) and fuses them through an Extended Attention Block with a zero-initialized gate. A two-stage training strategy addresses mask asymmetry by first supervising mask prediction from flattened garments and later applying shape-aware training with square masks. Extensive experiments on VITON-HD and DressCode show competitive or superior performance, with ablations validating module contributions and demonstrating cross-task fine-tuning benefits.

Soundness
The approach is technically reasonable and builds on well-founded diffusion and transformer components. The latent-space input formation is precisely described (Section: Method; I_t construction), and the pixel-space modules are articulated with equations (Eq. (3–12)). The Extended Attention gating (Eq. (13)) is appropriate for progressive integration of spatial signals. Results across VTON (Tables 1–2) and VTOFF (Table 3) are consistent; ablations (Table 4) show that removing SRM/SAM or altering fusion harms performance, supporting design soundness.

Self-checks highlight gaps: the “unified deformation field” remains a conceptual claim without explicit modeling or diagnostics; Figure 1’s similarity analysis lacks methodological detail. The Stage-2 reliance on square masks may regularize geometry but risks overfitting to simple boundaries. Efficiency and reproducibility details are absent in the main text.

Presentation
Organization is generally strong, with clear module diagrams (Figure 2(b–c)) and comprehensive experimental tables. However, certain captions are inconsistent (Figure 4), and crucial training details are deferred to the appendix rather than summarized. The similarity analysis (Figure 1) would benefit from in-text procedural descriptions.

Contribution
The unified perspective on VTON/VTOFF and the dual-space conditioning in one diffusion framework is a meaningful advance for the fashion synthesis community, reducing duplication of systems and suggesting transferable knowledge across tasks. The staged mask strategy practically addresses asymmetry. Novelty is moderate: while many components are adapted, their consolidation for bidirectional garment transfer is distinctive.

Strengths
- Unified two-way framework with clear conditioning pathways (latent/pixel) and fusion (Extended Attention).
- Strong empirical performance and thorough ablations demonstrating necessity of components and training phases.
- Practical insights into controllability (rectangular masks) and task synergy via fine-tuning (Figures 7–8).
- Detailed module equations and diagrams aid understanding (Eq. (3–13); Figure 2).

Weaknesses
- Lack of formal evidence/metrics for the “implicit unified deformation field” claim.
- Insufficient reproducibility and efficiency reporting (hyperparameters, compute, inference steps).
- Limited VTOFF evaluation scope; missing DressCode VTOFF results and category diversity.
- Minor but noticeable presentation issues (caption mismatch; Figure 1 methodological detail).

Questions
1. Could you provide a formal diagnostic (e.g., cycle-consistency, learned correspondence maps) to substantiate the “unified deformation field”?
2. Please include key hyperparameters (loss weights, optimizer, LR, batch size, T), and efficiency benchmarks (params, FPS, memory) relative to baselines.
3. How does performance vary with non-rectangular masks or learned boundary masks during Stage-2?
4. Can you extend VTOFF benchmarks to DressCode and report category-specific metrics?
5. What is the exact protocol behind Figure 1’s weight/output similarity; are results consistent across diffusion steps (not just T=30)?

Rating
- Overall (10): 7 — A solid unified system with strong empirical support and clear practical value, tempered by limited formalization and reproducibility details (Tables 1–3; Figure 2; Eq. (14–16)).
- Novelty (10): 7 — Novel integration for two-way garment transfer; component-level novelty is modest (SAM/SRM; concatenation; masked attention).
- Technical Quality (10): 7 — Sound architecture and validated via ablations; missing efficiency and formal diagnostics reduce rigor (Table 4; Figure 1).
- Clarity (10): 7 — Good diagrams and equations; minor caption inconsistency and missing hyperparameters (Figure 4; references to appendix).
- Confidence (5): 4 — High confidence in empirical claims; lower confidence in theoretical framing and efficiency due to missing details.