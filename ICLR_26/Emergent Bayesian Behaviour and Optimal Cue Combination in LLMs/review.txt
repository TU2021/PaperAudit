### Summary

The paper investigates whether **Large Language Models (LLMs)** exhibit **Bayesian computational strategies** in their multimodal cue combination, drawing inspiration from **psychophysics** and the **Bayesian inference** principles used in human perception. The authors introduce **BayesBench**, a new benchmark designed to evaluate how LLMs handle uncertainty in multimodal tasks, specifically in **magnitude estimation** (location, length, distance, and duration) across **text and image modalities**. They also introduce a novel metric, the **Bayesian Consistency Score (BCS)**, to measure how well models integrate noisy cues in a manner consistent with **Bayesian principles**.

The study finds that **LLMs with high accuracy** do not necessarily exhibit **Bayesian consistency** or handle uncertainty in an optimal way. For example, **GPT-5 Mini**, despite its near-perfect accuracy, failed to integrate visual cues efficiently, highlighting a **dissociation** between **model capability** and **decision strategy**. The results also suggest that current **accuracy-based benchmarks** may overlook crucial aspects of **model robustness** and **uncertainty handling**.

---

### Strengths

* **Novel Interdisciplinary Approach**
  The paper applies a **psychophysics framework** to **LLMs**, offering a fresh perspective on evaluating their **implicit computational strategies**. The approach bridges cognitive science and AI, pushing forward the understanding of **LLM behavior** beyond simple **accuracy metrics** (sjdc).

* **Innovative Metrics**
  The **Bayesian Consistency Score (BCS)** is a novel and effective way to measure **Bayes-consistent behavior** in models, which goes beyond standard accuracy metrics. It tracks how models adjust their behavior in response to **manipulations of uncertainty** (d9eK, sjdc).

* **Controlled Experimental Design**
  The authors develop a robust experimental pipeline, allowing **systematic ablation of noise, context**, and **prompt details**, enabling a deeper understanding of how LLMs adapt to changes in their environment (d9eK).

* **Key Finding: Accuracy Does Not Imply Robustness**
  The study uncovers that models like **GPT-5 Mini**, despite being highly accurate, fail to perform optimal **multimodal cue combination**. This highlights that models excelling in accuracy may still struggle with **uncertainty management** and **robust decision strategies** (sjdc).

* **Potential for Future Development**
  **BayesBench** is presented as a framework that can be expanded to more **real-world scenarios** and further refined to assess models' **Bayesian behavior** across a wider range of tasks and **noisy data types** (sjdc).

---

### Weaknesses

* **Dissociation Between Accuracy and Bayesian Consistency**
  A major issue highlighted is the **confounding between accuracy** and **Bayesian behavior**. The **negative correlation between RMSE** and **Bayesian evidence** might be a reflection of circular reasoning, where the observed behavior might simply be a byproduct of **in-context learning (ICL)** rather than true Bayesian computation. The authors need to more clearly separate **perceptual capabilities** from **decision strategies** (d9eK, sjdc).

* **Limited Generalizability of Findings**
  The current study focuses on **synthetic tasks** and does not address how the observed **Bayesian behavior** would generalize to more complex **real-world multimodal tasks**. The benchmark could benefit from **diverse noise conditions** and tasks that involve **conflicting multimodal cues** (sjdc).

* **Questionable Validation of Emergent Bayesian Behavior**
  The paper claims that **Bayesian behavior emerges** in some models, but it does not sufficiently address alternative explanations, such as simple **heuristics** like **regression to the mean**. Without **non-Bayesian control models**, it remains unclear whether the observed behaviors are genuinely Bayesian or if simpler strategies could explain the patterns (sjdc, d9eK).

* **Limited Evaluation of Non-Bayesian Alternatives**
  The study largely focuses on Bayesian models and fails to explore non-Bayesian alternatives, which may also explain the observed patterns. This omission weakens the claim that LLMs exhibit **true Bayesian behavior** (sjdc).
