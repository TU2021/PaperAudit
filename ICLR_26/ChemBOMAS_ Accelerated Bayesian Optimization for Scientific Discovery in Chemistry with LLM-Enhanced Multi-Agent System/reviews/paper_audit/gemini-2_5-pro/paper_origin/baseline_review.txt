1) Summary
This paper introduces ChemBOMAS, a Large Language Model (LLM)-enhanced multi-agent system designed to accelerate Bayesian Optimization (BO) for chemical discovery. The framework addresses the common BO challenges of data scarcity and vast search spaces through two synergistic strategies. A data-driven strategy fine-tunes an 8B-parameter LLM on a small fraction (1%) of labeled data to generate pseudo-data, providing a robust initialization for the optimization process. Concurrently, a knowledge-driven strategy uses a RAG-enhanced LLM to partition the search space into promising subspaces by reasoning over chemical literature and data. A UCB algorithm selects high-potential subspaces, where BO is then performed. The authors evaluate ChemBOMAS on four chemical benchmarks and a wet-lab experiment, demonstrating significant improvements in convergence speed (up to 5x) and final performance compared to baseline methods.2) Strengths
*   **Comprehensive and Rigorous Experimental Validation**
    *   The method is evaluated on four distinct chemical benchmark datasets (Suzuki, Arylation, Buchwald_sub-1, Buchwald_sub-2), demonstrating consistent performance gains across different reaction types and data distributions (Figure 2, Section 4.3.3).
    *   The authors compare ChemBOMAS against a strong and diverse set of four baseline methods, including traditional BO and recent LLM-based approaches like GOLLuM and BO-ICL, providing a clear context for its performance improvements (Figure 2, Appendix C.4).
    *   The inclusion of a real-world wet-lab experiment on a previously unreported reaction is a standout feature. The system's ability to find a 96% yield condition in just two iterations, vastly outperforming a human expert's 15% yield, provides compelling evidence of its practical utility and ability to handle true "cold start" problems (Section 4.3.3, Appendix H, Figure 5).
    *   Thorough ablation studies are presented, which effectively isolate and quantify the contributions of the data-driven and knowledge-driven modules (Table 4), as well as the impact of pre-training and fine-tuning for the regression model (Table 3). This strengthens the claims about the synergistic nature of the framework.*   **Novel and Well-Motivated Synergistic Framework**
    *   The core contribution is the synergistic integration of two distinct LLM-powered strategies to tackle two fundamental challenges in BO. The data-driven pseudo-data generation directly addresses the "cold start" problem (Section 3.3), while the knowledge-driven search space decomposition tackles the "curse of dimensionality" (Section 3.4).
    *   The framework is designed as a closed-loop system where the two modules interact, as illustrated in the system diagram (Figure 1). Pseudo-data informs subspace selection, and experimental results from BO update the search, creating a virtuous cycle.
    *   The ablation study in Table 4 provides strong evidence for this synergy. Removing either the data-driven or knowledge-driven module leads to a significant drop in performance, demonstrating that the combination is more effective than either part in isolation. For example, on the Suzuki dataset, the full model reaches 96.15% yield in 3 iterations, while ablating the data module drops performance to 82.65% and ablating the knowledge module drops it to 88.98%.*   **Effective and Principled Application of LLMs in a Scientific Domain**
    *   The paper demonstrates a sophisticated use of different LLMs for tasks suited to their capabilities. A large, proprietary model (GPT-4o) with RAG is used for complex reasoning and knowledge extraction to partition the search space, mitigating hallucination (Section 3.4). A smaller, open-source model (LLaMA-3.1-8B) is efficiently fine-tuned for a specialized regression task, showing superior performance to zero-shot inference from larger models (Section 3.3, Table 1).
    *   The data-driven module shows that fine-tuning on a very small amount of labeled data (1%) is sufficient to create a high-quality regressor for pseudo-data generation. The analysis in Appendix I.2 (Tables 7 & 8) thoughtfully explores the trade-off between data volume, regressor accuracy, and final BO performance.
    *   The knowledge-driven module's use of RAG to ground the LLM's reasoning in scientific literature and databases is a principled approach to improving reliability and leveraging domain knowledge, a critical step for applying LLMs to scientific discovery (Section 3.4).3) Weaknesses
*   **Inclusion of Speculative and Unverifiable Experimental Results**
    *   Table 1 and the accompanying text in Section 4.3.1 include results for a model named "GPT-5," citing "OpenAI, 2025." This model is not publicly available, and its performance characteristics are unknown. Including fabricated results for a non-existent model is a serious breach of scientific reporting standards and undermines the credibility of the entire experimental evaluation.
    *   The paper asserts that the poor performance of GPT-4o "confirms that these chemical datasets were not part of their training data" (Section 4.3.1). While this is a plausible inference, it is not a confirmation. Such definitive claims about the training data of closed models are unverifiable and should be stated more cautiously as hypotheses.*   **Insufficient Methodological Detail for Reproducibility**
    *   The knowledge-driven module relies on a "hybrid Retrieval-Augmented Generation (RAG) approach" (Section 3.4), but critical implementation details are missing. The paper does not specify the exact literature sources, professional databases, or web search tools used. The process for constructing the vector database and the specific retrieval mechanism (e.g., query formulation, number of retrieved documents) are not described, making this core component of the method impossible to reproduce.
    *   The UCB-based subspace selection algorithm is described inconsistently. Section 3.4 states that "the top-5 nodes by UCB value are selected for further exploration," which suggests a parallel search. However, Algorithm 1 in Appendix F describes a greedy selection of a single best node (`arg max`), which contradicts the main text. This ambiguity makes the tree search strategy unclear.
    *   The paper introduces and evaluates a "data-driven" clustering approach (ChemBOMAS<sub>d-d</sub>) in Table 2, but this method is not described in the main methodology (Section 3). Appendix D alludes to using pseudo-points to select a tree structure, but the connection is not made explicit, leaving the reader to guess the implementation of a method presented as a key comparison point.*   **Ambiguity in Final Model Configuration and Component Evaluation**
    *   It is unclear which clustering strategy (knowledge-driven `ChemBOMAS_k-d` or data-driven `ChemBOMAS_d-d`) is used in the final, integrated ChemBOMAS model that is evaluated against baselines in Figure 2. The methodology focuses on the knowledge-driven approach, but the strong performance of the data-driven variant in Table 2 raises questions about the final design choice and its justification.
    *   The pseudo-data refinement strategy described in Appendix D, which involves removing points based on similarity and performance, is an important detail for mitigating noise. However, its impact is not evaluated. An ablation study showing the effect of this refinement would strengthen the paper's claims about the robustness of the data-driven module.4) Suggestions for Improvement
*   **Ensure Academic Integrity in Experimental Reporting**
    *   Immediately remove all references to "GPT-5" and its associated results from Table 1 and the text. This is non-negotiable for publication at any reputable venue.
    *   Rephrase the claim regarding the training data of general-purpose LLMs. Instead of stating it as a confirmation, present it as a well-supported hypothesis, e.g., "The poor zero-shot performance suggests it is unlikely that these specific benchmark datasets were included in the models' pre-training corpora."*   **Provide Sufficient Detail for Full Reproducibility**
    *   In a new appendix or within Section 3.4, provide a detailed description of the RAG pipeline. This should include: (1) a list of all data sources (e.g., specific journals, Reaxys, PubChem), (2) the methodology for processing these sources into a knowledge base (e.g., text chunking strategy, embedding model used), and (3) the retrieval process (e.g., how queries are formed, the value of k for top-k retrieval).
    *   Clarify the UCB tree search algorithm. Reconcile the "top-5" description in Section 3.4 with the `arg max` in Algorithm 1. If multiple paths are explored per iteration, the algorithm and text should be updated to reflect this. If only one path is chosen, the "top-5" language should be removed.
    *   Add a clear description of the data-driven clustering method (ChemBOMAS<sub>d-d</sub>) to the methodology or an appendix. Explain precisely how the pseudo-data is used to construct or select a tree, explicitly linking to the equations in Appendix D if they are part of this method.*   **Clarify Model Configuration and Strengthen Component Analysis**
    *   Explicitly state which clustering strategy is used in the final ChemBOMAS model presented in Section 4.3.3 and Figure 2. Justify this choice based on the results from Table 2 or other analysis.
    *   Consider adding a small ablation study, perhaps in the appendix, that evaluates the impact of the pseudo-data refinement strategy described in Appendix D. This would demonstrate its contribution to the overall performance and robustness of the framework.5) Score
*   Overall (10): 8 — The paper presents a novel, well-motivated framework with very strong empirical results, including compelling wet-lab validation (Figure 5, Appendix H), but is held back by a major flaw in experimental reporting ("GPT-5" results in Table 1) and a lack of key details for reproducibility.
*   Novelty (10): 8 — The synergistic combination of knowledge-driven search space partitioning and data-driven pseudo-data initialization for BO is a highly novel and impactful contribution to the field (Figure 1, Section 3).
*   Technical Quality (10): 6 — The technical approach is sound and the experimental design is mostly rigorous, but the inclusion of fabricated results for a non-existent model is a severe issue, and the lack of detail for the RAG and UCB components hinders reproducibility (Table 1, Section 3.4).
*   Clarity (10): 8 — The paper is generally well-written and clearly structured with excellent figures (Figure 1, Figure 2), though key methodological details regarding the RAG pipeline, UCB selection, and data-driven clustering are ambiguous or missing (Section 3.4, Table 2).
*   Confidence (5): 5 — I am highly confident in my assessment, as the topic aligns directly with my expertise in Bayesian optimization, machine learning for science, and LLM applications.