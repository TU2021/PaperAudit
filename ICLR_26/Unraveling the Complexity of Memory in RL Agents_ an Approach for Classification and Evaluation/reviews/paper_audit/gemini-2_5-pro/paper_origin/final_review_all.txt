1) Summary
This paper addresses the ambiguity surrounding the term "memory" in Reinforcement Learning (RL). It proposes a formal classification of agent memory inspired by cognitive science, distinguishing between declarative and procedural memory based on knowledge transfer across episodes/environments, and between short-term memory (STM) and long-term memory (LTM) based on the relationship between an agent's context length (K) and the environment's correlation horizon (ξ). The core contributions are a set of precise definitions for these memory types, a decoupling of Memory Decision-Making (Memory DM) tasks from Meta-RL tasks, and a practical methodology (Algorithm 1) for correctly designing experiments to evaluate an agent's LTM and STM capabilities. The authors empirically demonstrate that failing to follow this methodology can lead to incorrect conclusions about an agent's memory, whereas their approach provides clear and reliable assessments.2) Strengths
*   **Actionable Framework for Standardizing Evaluation**
    *   The paper introduces a clear, quantitative framework that moves beyond qualitative descriptions of memory. The definitions are directly tied to measurable parameters of the agent and the environment, making them highly practical for experimental design (Section 5).
    *   The distinction between Declarative Memory (within a single environment/episode) and Procedural Memory (across multiple environments/episodes) is formalized using the number of environments and episodes (`n_envs`, `n_eps`) (Definition 3, Equation 1-2). This provides a simple criterion for classifying the type of memory a task requires.
    *   The definitions of STM and LTM are grounded in the relationship between the agent's context length `K` and the environment's correlation horizon `ξ` (Definition 4). This relative definition is a key insight that clarifies much of the existing confusion.
    *   The framework culminates in a concrete, step-by-step procedure (Algorithm 1) for setting up experiments to test LTM and STM, which is a significant contribution to improving experimental rigor in the field.*   **Strong and Convincing Empirical Validation**
    *   The experiments are not designed to showcase a new state-of-the-art agent, but rather to compellingly demonstrate the central thesis: that improper experimental setup leads to flawed conclusions. This is a powerful and effective use of empirical work.
    *   The experiment in the MiniGrid-Memory environment (Section 6.1, Figure 4) clearly shows how a "variable mode" setup can misleadingly suggest an agent possesses LTM, while a correctly configured "fixed mode" experiment reveals the agent's limitations. This provides direct evidence for the necessity of the proposed methodology.
    *   The experiments in the Passive T-Maze (Section 6.2, Figure 5) effectively illustrate the "relative nature" of memory by showing that the same agent can solve a task when it is framed as STM (`K=15, ξ=15` or `K=5, ξ=5`) but fail when it is framed as LTM (`K=5, ξ=15`), reinforcing the validity of the definitions.*   **Excellent Conceptual Clarity and Organization**
    *   The paper is exceptionally well-written and organized, making complex ideas accessible. The authors effectively motivate the work by highlighting existing inconsistencies in the literature (Section 1, Section 3).
    *   The use of concepts from cognitive science is well-justified and provides an intuitive foundation for the formal definitions (Section 4.1, Appendix B.1).
    *   The visual aids are highly effective. Figure 1 and Figure 3 provide a clear taxonomy of memory types and task frameworks. Figure 2 offers an intuitive visualization of the core LTM/STM distinction relative to the agent's context.
    *   The decoupling of Memory DM from Meta-RL (Section 5, Table 1) provides a useful lens for structuring the problem space and clarifying what type of memory is being evaluated in different research threads.3) Weaknesses
*   **Limited and Potentially Constraining Definition of "Memory Mechanism"**
    *   The formal definition of a memory mechanism, `μ(K)`, as a function that produces an effective context `K_eff >= K` (Definition 6), seems primarily tailored to architectures with explicit recurrent states (like RNNs) or external memory buffers.
    *   It is not immediately clear how this definition applies to other powerful sequence models. For instance, the paper's experiments conclude that Transformer-based agents lack LTM because they cannot handle `ξ > K` (Section 6.1, Section 6.2). This framing implies that a standard Transformer, by its nature, can only solve STM problems, regardless of how large its context `K` is. This could be seen as an oversimplification.
    *   The paper does not discuss how architectures like State-Space Models or Transformers with compressed memory (which are mentioned in Appendix C) fit into the `μ(K)` framework. This narrowness could lead to mischaracterizing the capabilities of architectures that implement memory differently.*   **Overly Rigid Dichotomies May Not Capture Complex Interactions**
    *   The framework relies on strict binary classifications: Declarative vs. Procedural is decided by whether `n_envs × n_eps` is exactly 1 or greater than 1 (Definition 3), and LTM vs. STM is a sharp boundary at `ξ = K` (Definition 4).
    *   This rigidity may not capture more complex, hybrid scenarios. For example, an agent might leverage procedural skills (learned across many episodes) to more efficiently solve a declarative, long-term memory problem within a new episode. The framework, as presented, treats these as mutually exclusive capabilities.
    *   The interaction between different memory systems is a key area of study in cognitive science, but the proposed framework does not provide a clear way to analyze or evaluate such interactions in RL agents.*   **Unclear Applicability to Complex, Less Structured Environments**
    *   The proposed methodology hinges on the ability to identify and quantify the set of all relevant correlation horizons `Ξ` in an environment to calculate the "context memory border" `K_bar` (Algorithm 1, Step 1 & 2).
    *   This is straightforward in the simple, synthetic environments used in the experiments (Passive T-Maze, MiniGrid-Memory), which have a single, well-defined event-recall pair (Section 5.3, Section 6).
    *   However, it is not explained how this critical step could be performed in complex, high-dimensional environments like Atari games or robotics tasks, where there may be countless, overlapping, and implicit long-term dependencies. The practicality of the methodology for these more challenging domains is therefore uncertain.*   **Inconsistent Experimental Details Hinder Reproducibility**
    *   The description of the Passive T-Maze environment in Appendix E.1 presents conflicting information about the reward function. It first states that a correct turn yields a reward of 1 and an incorrect turn 0, but then describes a dense reward variant with a per-step penalty. The manuscript does not clarify which function was used for the experiments.
    *   The reported results in Figure 5, where successful agents achieve a return of 1.0 and random agents achieve 0.5, are only consistent with the sparse reward setting. The dense reward formulation described in Appendix E.1 would result in a maximum possible return of 0.
    *   This discrepancy between the appendix description and the main results undermines the clarity and reproducibility of a key experiment (Section 6.2) used to demonstrate the "relative nature" of memory.4) Suggestions for Improvement
*   **Broaden the Discussion of Memory Mechanisms**
    *   To address the narrow definition of `μ(K)`, the authors should expand their discussion to clarify how their framework interprets a wider range of modern architectures.
    *   For example, they could add a paragraph in Section 5.2 discussing whether a Transformer with a very large context length `K` that covers the entire episode should be considered a powerful STM-only agent or if this constitutes a form of LTM. They could also provide examples of how `μ(K)` might be conceptualized for State-Space Models or models with memory compression techniques.
    *   This would make the framework more robust and prevent it from implicitly favoring certain architectural classes over others.*   **Acknowledge and Discuss Hybrid Memory Scenarios**
    *   The paper would be strengthened by adding a discussion on the limitations of its strict dichotomies and the potential for interactions between memory systems.
    *   A "Limitations" or "Future Work" subsection could explicitly mention that real-world intelligence likely involves a blend of declarative and procedural memory. The authors could speculate on how their framework might be extended to analyze tasks that require, for instance, procedural skills to enable effective LTM storage and retrieval.
    *   This would add valuable nuance and demonstrate a forward-looking perspective on the complexities of agent memory.*   **Provide Guidance on Applying the Methodology to Complex Tasks**
    *   To demonstrate the broader utility of the framework, the authors should provide guidance on how to apply Algorithm 1 to more complex and less structured environments.
    *   This could take the form of a case study or a detailed discussion in the appendix. For example, they could walk through the process of *estimating* the distribution of correlation horizons `Ξ` for a well-known benchmark like Montezuma's Revenge, even without running a full experiment. Discussing the challenges and potential heuristics for this estimation would significantly increase the practical value of the proposed methodology.*   **Clarify Experimental Setup for Reproducibility**
    *   The authors should resolve the ambiguity in Appendix E.1 by explicitly stating which reward function (sparse or dense) was used for the Passive T-Maze experiments.
    *   The description of the reward function should be made consistent with the numerical results presented in Figure 5.
    *   Ensuring consistency across all experimental descriptions and results will significantly improve the paper's value for other researchers seeking to build upon or replicate this work.5) Score
- Overall (10): 7 — The paper provides a much-needed and actionable framework for evaluating memory in RL, though experimental reporting issues reduce confidence in its empirical validation (Figure 5, Appendix E.1).
- Novelty (10): 8 — While the underlying concepts are from cognitive science, their formalization in terms of agent/environment parameters (`K`, `ξ`) and the resulting experimental methodology (Algorithm 1) are highly novel for the RL community.
- Technical Quality (10): 7 — The definitions are precise and the logic is sound (Theorem 1), but the experimental reporting contains a significant inconsistency that affects reproducibility (Appendix E.1 vs Figure 5).
- Clarity (10): 9 — The paper is very well-written with clear definitions and figures (Figure 1, Figure 2), but a contradiction in the appendix regarding experimental details slightly mars its otherwise excellent clarity (Appendix E.1).
- Confidence (5): 5 — I am very confident in my assessment; the paper's claims and the identified issues are well-supported by the provided text and experiments.