Summary

This paper addresses the issue of inconsistent definitions of memory in Reinforcement Learning (RL) agents, proposing a unified taxonomy of memory types, such as short-term vs. long-term memory and declarative vs. procedural memory. The aim is to create a rigorous framework for evaluating memory capabilities in RL agents, given the ambiguity and inconsistency in existing definitions and evaluations.

Key Contributions:

Formal Definitions: The paper formalizes concepts of short-term memory (STM), long-term memory (LTM), and declarative vs. procedural memory within the RL context. These definitions are inspired by cognitive science but are tailored to fit RL tasks.

Unified Framework: It introduces a framework for categorizing memory types in RL agents and a robust experimental methodology for evaluating these memory capabilities based on the correlation horizon (¦Î) and context memory border (K).

Experimental Validation: The paper presents experiments that demonstrate the importance of this unified methodology, showing that incorrect evaluation based on current methods can lead to misleading conclusions about an agent¡¯s memory capabilities.

Strengths:

Conceptual Clarity: The paper brings clarity to a poorly defined area of RL, creating precise, quantifiable definitions for memory types.

Unified Evaluation Method: The methodology introduced enables a consistent and fair evaluation of memory capabilities across different RL models.

Formalization of Cognitive Science Concepts: Translating terms like short-term and long-term memory into measurable constructs for RL is an important contribution.

Experimental Validation: The experiments show that misaligned memory evaluation practices can lead to misjudgments in agent memory capabilities.

Weaknesses:

Lack of Novelty in Memory Concepts: The concepts of STM/LTM and procedural/declarative memory are not new in RL but have been poorly defined. The novelty lies in formalizing and quantifying these concepts rather than introducing entirely new ideas.

Limited Experiments: The experimental validation is somewhat limited. The paper does not provide extensive comparisons with state-of-the-art memory-enhanced RL models and focuses mainly on isolating the methodological effect rather than presenting new insights from broader empirical studies.

Theoretical Focus: The theoretical nature of the work, while valuable, might not be sufficient to stand as a full research contribution without additional experiments or insights into how the theory applies to modern RL architectures.

