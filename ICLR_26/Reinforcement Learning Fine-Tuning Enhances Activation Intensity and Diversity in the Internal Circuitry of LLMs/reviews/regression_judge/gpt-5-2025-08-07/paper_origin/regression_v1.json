{
  "paper": "Reinforcement Learning Fine-Tuning Enhances Activation Intensity and Diversity in the Internal Circuitry of LLMs",
  "runs": [
    {
      "config": {
        "judge_model": "gpt-5-2025-08-07",
        "review_agent": "paper_audit",
        "ai_model": "gpt-5-2025-08-07",
        "baseline_file": "baseline_review.txt",
        "final_file": "final_review_all.txt",
        "temperature": 0.0,
        "max_tokens": 20000,
        "timeout_s": 600,
        "metric": "regression_v2_minimal",
        "prompt_hash": "2142c04332"
      },
      "config_key": "1a46f14f5902ebb0fc2c14773cec6644d2fa5338",
      "inputs": {
        "baseline_review": "reviews/paper_audit/gpt-5-2025-08-07/paper_origin/baseline_review.txt",
        "final_review": "reviews/paper_audit/gpt-5-2025-08-07/paper_origin/final_review_all.txt"
      },
      "regression": {
        "score_delta": {
          "baseline_score": 6.0,
          "final_score": 6.0,
          "delta": 0.0,
          "scale_hint": "1-10"
        },
        "differences": [
          {
            "diff_type": "new_critique",
            "summary": "No alignment of token targets across models for attribution",
            "paperaudit_types": [
              "EXPERIMENTAL_DESIGN_PROTOCOL",
              "METHOD_LOGIC_CONSISTENCY"
            ],
            "why_impacts_score": "Conflates internal changes with output differences; weakens interpretability and validity",
            "evidence": {
              "baseline_quote": "Edge attribution uses self-entropy over generated tokens (Eq. 13), not target-correct labels; justification and trade-offs are brief.",
              "final_quote": "Attribution is computed on each model’s own generated tokens, without aligning the token targets across models."
            }
          },
          {
            "diff_type": "new_critique",
            "summary": "Notational inconsistency in Eq. (1) (undefined d_k)",
            "paperaudit_types": [
              "METHOD_LOGIC_CONSISTENCY",
              "CONTEXT_MISALIGNMENT_INCOHERENCE"
            ],
            "why_impacts_score": "Notation inconsistency undermines clarity and technical precision",
            "evidence": {
              "baseline_quote": "Section 4.2 defines W but not how n_o and n_i correspond to concrete edges.",
              "final_quote": "Eq. (1) uses √d_k in attention while the text defines d_query and does not introduce d_k."
            }
          },
          {
            "diff_type": "new_critique",
            "summary": "Ambiguous Table 1 labeling (Act./Intens./arrows) not explained",
            "paperaudit_types": [
              "RHETORICAL_PRESENTATION_MANIPULATION",
              "CONTEXT_MISALIGNMENT_INCOHERENCE"
            ],
            "why_impacts_score": "Ambiguous labels hinder interpretation and reproducibility",
            "evidence": {
              "baseline_quote": "Improvement percentages in Figure 3b are reported without variance or sample counts for each bar.",
              "final_quote": "Table 1 row labeling uses “Act.”/“Intens.”/arrows (↑/↓), which is not explained in Section 4.2."
            }
          },
          {
            "diff_type": "new_critique",
            "summary": "Undefined diversity metrics used in Figure 3",
            "paperaudit_types": [
              "EXPERIMENTAL_DESIGN_PROTOCOL",
              "CLAIM_RESULT_DISTORTION"
            ],
            "why_impacts_score": "Undefined metrics undermine claimed improvements and replicability",
            "evidence": {
              "baseline_quote": "Figure 3b reports large increases in output entropy, corroborating Table 1 trends.",
              "final_quote": "Additional metrics used in Figure 3 are not defined in Section 4.2."
            }
          },
          {
            "diff_type": "score_rationale_shift",
            "summary": "Clarity sub-score reduced with new reasons (undefined metrics, labeling issues)",
            "paperaudit_types": [
              "RHETORICAL_PRESENTATION_MANIPULATION",
              "CONTEXT_MISALIGNMENT_INCOHERENCE"
            ],
            "why_impacts_score": "Adds concrete clarity deficiencies to justify lower clarity score",
            "evidence": {
              "baseline_quote": "Clarity (10): 6 — ... ambiguity in W construction/granularity and metric parameterization reduces interpretability.",
              "final_quote": "Clarity (10): 5 — ... undefined diversity metrics in Section 4.2, and Table 1 labeling issues reduce interpretability."
            }
          }
        ]
      },
      "generated_at": "2026-01-05T20:40:10"
    }
  ]
}