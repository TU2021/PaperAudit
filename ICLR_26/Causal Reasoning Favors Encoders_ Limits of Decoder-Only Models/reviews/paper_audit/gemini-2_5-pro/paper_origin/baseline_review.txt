1) Summary
This paper investigates the architectural underpinnings of multi-hop logical reasoning, hypothesizing that encoder-based models are inherently better suited for such tasks than decoder-only models. The authors argue that encoders' ability to create a global representation of the input facilitates the compositional and conjunctive control required for logical deduction. To test this, they create a synthetic first-order logic dataset with two out-of-distribution splits: one with deeper reasoning chains (NL) and another with randomized, non-natural language tokens (NNL). They compare fine-tuned encoder-only (BERT) and encoder-decoder (BART, Flan-T5) models against various decoder-only LLMs under zero- and few-shot in-context learning, as well as a fine-tuned decoder-only model (Qwen3-1.7B). Results show that fine-tuned encoder-based models generalize more robustly and efficiently, particularly on the NNL split and at greater reasoning depths, a finding supported by a mechanistic analysis of representation geometry.2) Strengths
*   **Clear and Well-Motivated Hypothesis:** The paper is built around a clear and plausible hypothesis that an encoder's ability to globally project the entire input sequence is architecturally advantageous for multi-hop logical reasoning compared to the recursive, token-by-token processing of decoders.
    *   The informal argument in Section 3.2 provides a solid conceptual foundation for the experimental work, contrasting the "instant global information sharing" of encoders with the sequential propagation in decoders.
    *   This hypothesis directly addresses a known weakness in LLMs—their struggle with strict, compositional reasoning (Section 1)—and proposes a concrete architectural explanation.
    *   The framing connects the architectural design to specific reasoning requirements, namely "multi-hop composition and strict conjunctive control" (Abstract, Section 1).*   **Comprehensive and Rigorous Experimental Design:** The study employs a thorough evaluation framework to test its central hypothesis, covering multiple model families, learning paradigms, and data distributions.
    *   The comparison includes encoder-only, encoder-decoder, and decoder-only architectures, providing a broad view of the architectural landscape (Section 4.2, Table 2).
    *   The work evaluates models under both fine-tuning (BERT, BART, Qwen3) and in-context learning (GPT, Claude, Qwen), which are the dominant paradigms for smaller and larger models, respectively (Figure 1, Section 5).
    *   The dataset design is a key strength, featuring controlled reasoning depth and two distinct OOD test sets (NL and NNL) to disentangle logical structure from lexical cues (Section 4.1, Figure 2). This allows for a nuanced analysis of generalization.
    *   A comprehensive set of metrics is used, including overall accuracy, per-depth F1 scores, and AUROC, to provide a multi-faceted view of model performance (Section 4.3).*   **Novel Mechanistic Interpretability Analysis:** The paper goes beyond standard input-output evaluations by including a mechanistic analysis to provide deeper insight into *how* different architectures process logical information.
    *   The use of "curvature similarity" as a probe to measure the stability of internal transformations is a novel and sophisticated technique in this context (Section 7).
    *   The results of this analysis (Figure 5) provide compelling evidence that aligns with the paper's main hypothesis: BERT (encoder-only) maintains the most stable geometric transformations across increasing reasoning depths, suggesting it re-applies a consistent internal logic.
    *   This analysis directly links the architectural feature (bidirectional context) to an observable internal property (stable curvature), strengthening the paper's central claim that encoders "preserve structural invariants" (Section 7).*   **Strong and Consistent Empirical Results:** The experimental findings consistently support the paper's hypothesis across various tests, demonstrating the robustness of the conclusions.
    *   Fine-tuned encoder-based models, particularly BERT-Base, show superior generalization on the challenging NNL dataset compared to the fine-tuned decoder-only model (Section 5.2, Figure 4 right). BERT-Base degrades much more slowly with depth.
    *   The AUROC analysis shows that fine-tuned encoder and encoder-decoder models achieve better discrimination than the fine-tuned decoder-only model on the NL dataset (Section 5.2, Figure 8/63).
    *   The efficiency analysis in Section 6.2 (Table 1) makes a strong practical point, showing that smaller, fine-tuned encoder/encoder-decoder models can achieve robust performance at a fraction of the computational cost of large decoder-only models.3) Weaknesses
*   **Overstated Framing of "Causal Reasoning":** The paper is framed around "causal reasoning" (Title, Abstract, Section 1), but the task is strictly one of logical deduction on a subset of first-order logic.
    *   The task, derived from SimpleLogic (Section 4.1), involves determining logical entailment from facts and rules. It does not include core components of causal reasoning like interventions, counterfactuals, or causal discovery from data, as defined in foundational works like Pearl (2009).
    *   While the paper briefly acknowledges that it focuses on the "deductive backbone" of causal reasoning (Section 3.1), the persistent use of the broader term "causal reasoning" throughout the paper is an overclaim that could mislead readers about the scope of the findings.
    *   No direct evidence found in the manuscript that the task evaluates anything beyond logical deduction.*   **Limited Comparison of Fine-Tuned Decoder-Only Models:** The central claim about the superiority of fine-tuned encoders rests on a comparison with only a single fine-tuned decoder-only model (Qwen3-1.7B).
    *   The fine-tuning experiments compare two BERT variants and two BART variants (plus Flan-T5) against just one decoder-only architecture (Section 5.2).
    *   This narrow sample size for the decoder-only family makes it difficult to generalize the conclusion that the observed performance gap is due to the architecture itself, rather than idiosyncrasies of the specific Qwen model chosen.
    *   The lack of other popular open-weight decoder-only models (e.g., from the Llama or Mistral families) in the fine-tuning comparison is a significant limitation.*   **Clarity and Organizational Issues in Results Reporting:** The presentation of results is often confusing, with inconsistencies and a poorly organized appendix that hinders readability.
    *   Figure 3 (text version) contains apparent typos and formatting errors that make the class distributions for fine-tuned models difficult to interpret (e.g., "Qwen-3 1.7B: 0: 44.0%, 1: 63.2%, 70.5%, 46.4%").
    *   The model Flan-T5-Base is a key part of the fine-tuned results (Section 5.2, Figure 4) but is omitted from the main "Models Used" section (Section 4.2) and only appears in the appendix (Table 2).
    *   The appendix is exceptionally long and dense, with many tables (e.g., Blocks 71-76, 101-106) presenting raw per-depth metrics that are hard to digest and could be better summarized or visualized. The connection between the numerous plots and tables is not always clear.
    *   Key figures supporting main-text claims, such as the ROC curves for finetuned models (Figure 8/63), are relegated to the appendix, separating them from the textual discussion of AUC scores (Section 5.2).*   **Use of Hypothetical and Unverifiable Model Citations:** The paper evaluates and cites models with future publication dates, such as "GPT-5 (OpenAI, 2025b)" and "Claude Opus 4.1 (Anthropic, 2025)".
    *   This is non-standard scientific practice and makes the results related to these models impossible to verify or reproduce. The specific versions and capabilities of these purported models are unknown to the public and the research community.
    *   Citing future work from model providers (e.g., OpenAI, 2025b; Anthropic, 2025) for models that are not yet announced or documented undermines the scientific credibility of the claims, particularly the finding that GPT-5 achieves "100% accuracy" (Section 5.1).
    *   This practice obscures which actual models were used for the experiments, preventing a fair comparison and replication.4) Suggestions for Improvement
*   **Refine Terminology to Accurately Reflect the Task:** To improve precision and avoid overclaiming, re-frame the paper's contribution as being about "multi-hop logical deduction" or "compositional logical reasoning" rather than "causal reasoning."
    *   The title, abstract, and introduction should be revised to use the more specific terminology.
    *   The connection to the broader field of causal reasoning can be maintained as a motivating point in the introduction, but the core claims and conclusions should be grounded in the logical deduction task that was actually performed.
    *   This change would align the paper's framing with its technical substance.*   **Broaden the Scope of Fine-Tuned Decoder-Only Models:** To make the architectural comparison more convincing, expand the set of fine-tuned models to include more contemporary and diverse open-source decoder-only architectures.
    *   Fine-tune and evaluate at least one or two additional decoder-only models, such as those from the Llama or Mistral families, at parameter counts comparable to the BERT-Base/Large and BART-Base/Large models.
    *   This would provide a much stronger basis for concluding that the observed performance differences are attributable to the encoder vs. decoder architecture rather than model-specific factors.*   **Restructure and Clarify the Presentation of Results:** Reorganize the results section and appendix to improve clarity, consistency, and readability.
    *   Correct the formatting and any numerical errors in all tables, especially the text version of Figure 3.
    *   Ensure all models evaluated are properly introduced in the main methods section (Section 4.2), including Flan-T5-Base.
    *   Streamline the appendix by summarizing the large per-depth metric tables and removing redundant figures. Focus on presenting the most critical results that support the main claims.
    *   Move essential figures, like the ROC curves for finetuned models (Figure 8/63), into the main body of the paper to be co-located with their corresponding discussion.*   **Use Standard and Verifiable Model Naming and Citations:** Replace all future-dated and hypothetical model names/citations with the official, publicly documented model versions that were used at the time of the experiments.
    *   For example, if "GPT-4.1" refers to a specific version of GPT-4-Turbo, use that name and cite the appropriate technical report or API documentation.
    *   If pre-release models were accessed, this should be stated transparently, but citing non-existent papers from "2025" is not acceptable. Grounding the work in verifiable artifacts is essential for reproducibility and scientific integrity.5) Score
*   Overall (10): 6 — The paper presents a well-designed study with a strong hypothesis and novel mechanistic analysis, but is held back by significant issues in framing, experimental scope, clarity, and the use of unverifiable model citations.
*   Novelty (10): 8 — The core idea is an interesting architectural comparison, and the use of curvature similarity as a mechanistic probe (Section 7) is a highly novel contribution to this line of inquiry.
*   Technical Quality (10): 6 — The dataset design and evaluation protocol are strong, but the technical claims are weakened by the limited set of fine-tuned decoder models (Section 5.2) and the use of non-verifiable, future-dated models (e.g., GPT-5).
*   Clarity (10): 5 — While the prose is generally clear, the overall organization is confusing, with inconsistencies (Figure 3, Section 4.2), a disorganized appendix, and a disconnect between results in the main text and supporting figures in the appendix.
*   Confidence (5): 5 — I have carefully reviewed the entire manuscript and am highly confident in my assessment of its strengths and weaknesses.