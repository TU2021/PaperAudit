# Innovation & Motivation Report

## 1. The Authors' Claimed Contribution
- Core Problem: Assess whether decoder-only large language models can reliably perform causal logical reasoning (multi-hop composition and strict conjunctive control), and how they compare to encoder and encoder–decoder architectures under distribution shifts and increasing reasoning depth.
- Claimed Gap: “Do architectural choices (encoder vs decoder-only) fundamentally constrain logical causal reasoning?” [Introduction]. The authors explicitly set a hypothesis: “Encoder projections over the full input should enable more reliable causal composition and robustness to distribution shifts compared to autoregressive decoders.” [Introduction]. From the abstract, they further claim: “ICL alone [is] insufficient; decoder-only [models are] brittle under distributional shifts; fine-tuned encoders/enc–dec generalize better, including NNL.” [Abstract].
- Proposed Solution: Construct synthetic first-order logic datasets (Horn clauses; SimpleLogic without disjunction) with one training split and two out-of-distribution test splits (natural language vs lexical-ablated non-natural-language), stratified by reasoning depth. Compare zero/few-shot in-context learning in decoder-only models against targeted fine-tuning of encoder-only and encoder–decoder models. Augment with mechanistic interpretability via curvature similarity across depths and efficiency (accuracy per hour) analysis. The architectural rationale is articulated in Preliminaries: “Encoders: Bidirectional layers contextualize all tokens; projection z = pool(H) aggregates global information, enabling single-pass evaluation... Decoder-only: Autoregressive recursion... may require backtracking; inference is non-controllable and may need multiple calls.” [Preliminaries].

## 2. Comparative Scrutiny (The "Trial")
Here, we analyze how the paper stands against the identified similar works.

### vs. Advancing Natural Language Formalization to First Order Logic with Fine-tuned LLMs
- Identified Overlap: Both compare encoder–decoder versus decoder-only architectures on FOL-structured tasks and find that fine-tuned, structure-aware encoder–decoder models can outperform decoder-only LLMs. Both emphasize robustness and generalization beyond surface lexical cues.
- Manuscript's Defense: The manuscript focuses on downstream entailment/causal reasoning with multi-hop composition and strict conjunction under OOD depth and lexical ablation (NL vs NNL), rather than upstream NL→FOL translation. It does not cite this work explicitly. Distinguishing claims include: “ICL alone [is] insufficient... decoder-only [are] brittle under distributional shifts; fine-tuned encoders/enc–dec generalize better, including NNL.” [Abstract]; and the methodological choice to ablate lexical cues via an NNL split [Method]. Mechanistic analysis via “curvature similarity across depths 6–11” is also unique to this manuscript [Section 7].
- Reviewer's Assessment: The distinction (upstream formalization vs downstream reasoning execution) is substantive. While themes converge (architectural comparison for FOL-structured problems and the advantage of T5-like models), the manuscript’s OOD depth design and NNL ablation address a different gap—robust causal composition and conjunctive control under distribution shifts. The lack of explicit citation is a minor weakness; otherwise, the overlap does not undermine the claimed contribution.

### vs. Uncovering Graph Reasoning in Decoder-only Transformers with Circuit Tracing
- Identified Overlap: Both interrogate structural reasoning in decoder-only transformers and relate brittleness to path length/complexity. The similar work uses circuit tracing to explain token merging and structural memorization; the manuscript observes decoder brittleness under OOD depth, especially in NNL, and introduces curvature similarity as an invariant probe.
- Manuscript's Defense: The manuscript does not cite this work. It differentiates by (a) cross-architecture benchmarking (encoders, encoder–decoders, decoder-only) on FOL Horn entailment rather than generic graph tasks; (b) OOD test design with lexical ablation (NNL); and (c) geometric invariants via curvature similarity: “Encoders preserve structural invariants... decoder-only shows curvature drift.” [Section 7].
- Reviewer's Assessment: The mechanistic aims overlap, but the methodological probes are different and complementary. This manuscript provides comparative performance evidence and a geometry-based diagnostic across architectures and depths. The novelty is moderate; acknowledging circuit-level interpretability work would strengthen motivation.

### vs. Multitask Kernel-based Learning with First-Order Logic Constraints
- Identified Overlap: Both center reasoning as satisfying FOL constraints via global aggregation. The similar work integrates clauses into kernel machines through a continuous penalty enforcing joint constraints; the manuscript enforces clause-level structure through proof-chain supervision and global encoder projections.
- Manuscript's Defense: Not cited. Differentiation lies in domain and mechanism: the manuscript evaluates transformer architectures (encoder, encoder–decoder, decoder-only) on clause satisfaction under OOD depths and lexical ablation, whereas the similar work frames multitask kernel learning objectives.
- Reviewer's Assessment: The overlap is conceptual (global constraint enforcement), not direct. The manuscript’s architectural comparison and OOD robustness analysis on transformers remain distinct. The motivation stands.

### vs. Partial Is Better Than All: Revisiting Fine-tuning Strategy for Few-shot Learning
- Identified Overlap: Both argue for controlled, targeted adaptation rather than naive transfer. The similar work uses layer-wise partial fine-tuning with evolutionary search; the manuscript performs targeted fine-tuning with supervision on proof chains + final labels and a balanced depth curriculum.
- Manuscript's Defense: Not cited. The manuscript’s distinction is the task (causal logical reasoning) and architecture-level claims about encoders vs decoder-only under OOD depth/lexical shifts, rather than proposing a new fine-tuning algorithm.
- Reviewer's Assessment: Overlap is in philosophy (targeted adaptation). The manuscript’s contribution is an empirical evaluation in FOL reasoning with OOD emphasis, not a new strategy. Motivation remains intact; novelty here is incremental.

### vs. Coalescing: Syntactic Abstraction for Reasoning in First-Order Modal Logics
- Identified Overlap: Both exploit syntactic structure to make reasoning tractable. The similar work reduces first-order modal logics to FOL/propositional proofs; the manuscript constrains to Horn clauses (no disjunction) and uses a DSL ([AND], [IMPLY]) to emphasize structure over lexical cues (via NNL).
- Manuscript's Defense: Not cited. The manuscript distinguishes itself with empirical, architecture-focused robustness tests and geometric invariants in neural models rather than formal reduction methods.
- Reviewer's Assessment: The overlap is methodological in spirit (structure-first reasoning). The manuscript’s empirical angle and depth/lexical OOD design remain distinct. Motivation is not weakened.

### vs. Advancing Natural Language Formalization to First Order Logic with Fine-tuned LLMs (reiterated for FOL-specific closest overlap)
- Identified Overlap: Architecture comparison and finding T5-like models superior; emphasis on structural generalization to unseen arguments.
- Manuscript's Defense: Explicit focus on causal reasoning execution and OOD stress tests. Evidence includes: “Evaluate zero/few-shot ICL... and fine-tuned encoder-only (BERT), encoder–decoder (BART, Flan-T5)... on NL and NNL FOL tasks.” [Abstract/Method]; and “Depth-wise accuracy declines with reasoning depth... sharper drop in NNL.” [Results].
- Reviewer's Assessment: Distinction is valid; the manuscript probes robustness of execution rather than formalization. The motivation to test architectural constraints on causal composition is credible.

## 3. Novelty Verdict
- Innovation Type: Application-Oriented, bordering on Incremental.
- Assessment:
  The paper’s motivation—testing whether architectural choices fundamentally constrain reliable causal logical reasoning under controlled OOD shifts and lexical ablation—is well grounded and supported by its design and evidence. It combines:
  - A structured, depth-stratified dataset with NL vs NNL splits to isolate structural reasoning.
  - A cross-architecture comparison (encoder, encoder–decoder, decoder-only) under zero/few-shot ICL vs targeted fine-tuning.
  - A geometric interpretability probe (curvature similarity) to argue stability of internal updates with depth.
  - An efficiency analysis to inform practical trade-offs.
  Relative to the most similar works, the manuscript does not introduce new theory or algorithms; its contribution is a careful empirical synthesis and stress-testing under OOD conditions. The absence of citations to closely related mechanistic and FOL-architecture studies is a weakness, but the distinctions (downstream causal reasoning execution; lexical ablation; geometric invariants; efficiency framing) are credible and not strawman arguments. The claimed gap survives the comparison, though the novelty is primarily empirical and evaluative rather than conceptual.
  - Strength:
    - Clear hypothesis and experimental design targeting architectural constraints on causal composition.
    - OOD robustness focus (depth 8–11 unseen; NNL lexical ablation) and depth-wise analyses.
    - Mechanistic probe via curvature similarity supporting encoder stability claims.
    - Practical efficiency metrics contextualizing performance vs cost.
  - Weakness:
    - Synthetic Horn-fragment (no disjunction) limits scope; findings may not generalize to richer FOL or real-world text.
    - Reliance on API models with undisclosed details complicates architectural attribution; GPT-5 results confound architecture vs scale/compute.
    - Missing citations to highly relevant contemporaneous works on decoder-only structural reasoning and FOL tasks (e.g., circuit tracing; NL→FOL formalization), reducing the rigor of the positioning.
    - The mechanistic evidence (curvature similarity) is suggestive but may be viewed as a secondary diagnostic relative to stronger interpretability analyses.

## 4. Key Evidence Anchors
- Abstract: “ICL alone insufficient; decoder-only brittle under distributional shifts; fine-tuned encoders/enc–dec generalize better, including NNL.” (sets the central empirical claim and motivation).
- Introduction: “Do architectural choices (encoder vs decoder-only) fundamentally constrain logical causal reasoning?” and “Hypothesis: Encoder projections over the full input should enable more reliable causal composition... compared to autoregressive decoders.” (states the gap and hypothesis).
- Preliminaries: Architectural rationale—“Encoders... projection z = pool(H) aggregates global information... Decoder-only... may require backtracking; inference is non-controllable and may need multiple calls.” (justifies the expected difference).
- Method: NL vs NNL test design; depth stratification; DSL tokens [AND], [IMPLY]; proof-chain supervision (demonstrates structural control over tasks).
- Results (5.2): Finetuned NL accuracy and AUROC—encoders/encoder–decoders outperform decoder-only at modest scales; NNL robustness patterns and early-depth drops (quantifies robustness and brittleness).
- Ablations (6.1): Depth-wise trends—NNL sharp early decline; OOD behavior at depths 8–11 (evidence of distribution-shift sensitivity and encoder stability).
- Mechanistic Interpretability (Section 7): “Curvature similarity across depths 6–11... Encoders preserve structural invariants... decoder-only shows curvature drift.” (mechanistic support for the architectural hypothesis).
- Efficiency (6.2): Accuracy/hour across models; “Recommendation: cost-effective robust causal reasoning favors encoder/encoder–decoder with targeted fine-tuning.” [Conclusion] (motivational significance for practitioners).