Summary
The paper introduces MCCE, a hybrid multi-LLM collaborative co-evolution framework for multi-objective discrete optimization, instantiated on five-objective molecular design (QED, SA, DRD2, GSK3β, JNK3). A frozen, closed-source LLM (e.g., GPT-4o or Gemini) conducts global exploration, while a lightweight local LLM (Qwen2.5-7B-Instruct) is continually refined via Direct Preference Optimization (DPO). The system maintains a trajectory memory of “breakthrough” candidates and constructs similarity-aware DPO triplets to stabilize learning and mitigate distribution shift. The co-evolution loop uses Pareto-based selection and periodic updates, with score normalization within generations and a fixed DPO reference model. Experiments report improved hypervolume, fitness, and diversity metrics, and better Pareto fronts than single-LLM baselines and alternative training paradigms. The paper also claims that collaboration leads to “mutual inspiration,” improving outputs from the frozen API model, though this mechanism is not deeply analyzed.

Strengths
- Clear conceptual design and motivation: a staged co-evolution loop coupling exploration (frozen API LLM) with exploitation (trainable local LLM), guided by Pareto-based selection and diversity maintenance.
- Thoughtful training strategy: diagnosis of instability in SFT/RL for discrete generation and adoption of DPO with a fixed reference model to enhance stability.
- Similarity-aware triplet synthesis for DPO that aims to avoid contradictory preference pairs and reduce distribution shift; memory of breakthrough trajectories to focus learning on meaningful regions.
- Ambitious evaluation with five concurrent objectives and multi-run statistics, reporting gains in hypervolume, fitness curves, and diversity/uniqueness/validity metrics.
- Method exposition is generally clear and modular, with staged descriptions, equations, and algorithmic summaries; appendices provide useful training details and loss monitoring.
- The framework is plausibly generalizable beyond drug design, offering a practical approach to leverage strong but static closed models with an adaptable local learner.

Weaknesses
- Core methodological ambiguity: the similarity function sim(c, q) is defined between a molecule and a textual prompt but not operationalized; it is unclear whether similarity is computed against parent molecules, how it is aggregated, or whether prompts are embedded into molecular-like representations. This affects the correctness and reproducibility of the triplet construction.
- Incomplete evaluation transparency: biochemical scoring surrogates for DRD2, GSK3β, and JNK3 are not detailed (datasets, model architectures, calibration, validation, uncertainty), undermining external validity and hindering independent verification.
- Hypervolume reporting lacks critical specifics: no reference point, objective orientation (maximize/minimize), or confirmation of whether raw or normalized objectives are used. Per-generation normalization may confound cross-generation and cross-run comparability and materially affect HV values.
- Operator alternation and training cadence are under-specified: the schedule for switching between the frozen and local operators, update frequency, selection strategy, and population parameters are only described conceptually without concrete settings, sensitivity analyses, or ablations, limiting replicability and fair comparisons.
- Baseline coverage is narrow: despite referencing related LLM evolutionary systems (e.g., ExLLM, MoLLEO) and other optimizers (e.g., GFlowNets, NSGA-II, MOEA/D), the main results do not include these as baselines, reducing the strength of comparative claims.
- Reporting clarity issues: key metrics (Top1F/Top10F/Top100F and Top1auc/Top10auc/Top100auc) are undefined; several figures are low-resolution with minimal axes/labels and appear duplicative, hampering interpretability.
- Mechanistic uncertainty: the claimed improvement in outputs from the frozen API model (“mutual inspiration”) is not causally analyzed; since parameters are fixed, improvements likely stem from prompt changes, parent selection, or population dynamics. Without ablations, this remains speculative.
- Practicality and constraints: compute and API budgets (calls, tokens, cost, latency) are not reported, and medicinal chemistry constraints (e.g., PAINS, Lipinski) are not discussed, leaving open questions about the real-world utility and feasibility of the generated molecules.
