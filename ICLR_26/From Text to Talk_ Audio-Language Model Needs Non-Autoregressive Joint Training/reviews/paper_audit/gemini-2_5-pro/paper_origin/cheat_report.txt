**Integrity and Consistency Review Report**

This report details significant internal inconsistencies and potential integrity risks identified in the manuscript "From Text to Talk: Audio-Language Models Need Non-Autoregressive Joint Training". The issues noted below are based solely on the content of the provided manuscript and materially affect its scientific validity and trustworthiness.

**1. Pervasive Use of Seemingly Fabricated or Non-Existent References**

A significant number of citations in the manuscript refer to works that appear to be non-existent, future-dated, or have invalid identifiers. This is a critical integrity concern as it misrepresents the scientific landscape and the foundations upon which the current work is built.

*   **Evidence:**
    *   The manuscript frequently cites papers with a publication year of "2025" that are listed as arXiv preprints (e.g., Xu et al., 2025; Long et al., 2025; Huang et al., 2025; Ding et al., 2025; Yu et al., 2025; Nie et al., 2025).
    *   Many of the associated arXiv identifiers in the reference list appear to be invalid or formatted for future dates (e.g., Ding et al., 2025 is cited with "arXiv:2504.18425"; Nie et al., 2025 with "arXiv:2502.09992").
    *   Several citations from the current year (2024) also appear to have invalid identifiers (e.g., DÃ©fossez et al., 2024 with "arXiv:2410.00037"; Zeng et al., 2024 with "arXiv:2412.02612"; Xie & Wu, 2024 with "arXiv:2408.16725").
*   **Impact:** This practice fundamentally undermines the credibility of the literature review and the positioning of the work. It prevents verification of the claims attributed to these sources and suggests a potential fabrication of the research context.

**2. Contradictions Between Textual Claims and Reported Numerical Results**

The manuscript contains several claims in the main text that are directly contradicted by the numerical data presented in its own tables.

*   **Inconsistency 2.1: Performance after Multimodal Pretraining.**
    *   **Claim (Section 4.4):** "when applied on top of the multimodally aligned pretrained model, Pretrain+TtT consistently matches or surpasses Pretrain+AR across both Audio-QA and ASR benchmarks."
    *   **Evidence (Table 1, "Training Strategy Comparison"):** This claim is false. The data in Table 1 shows that the `Pretrain+AR` model outperforms `Pretrain+TtT` on at least two benchmarks:
        *   **Audio-QA (AlpacaEval):** `Pretrain+AR` scores 29.45, while `Pretrain+TtT` scores 26.73 (lower is worse).
        *   **ASR (WenetSpeech-test_meeting):** `Pretrain+AR` achieves a WER of 26.75, while `Pretrain+TtT` achieves 27.59 (higher is worse).
*   **Inconsistency 2.2: Overstated Performance of the Proposed Model.**
    *   **Claim (Section 4.2):** "Our proposed TtT consistently achieves the best performance on all four Audio-QA datasets."
    *   **Evidence (Table 1, "Main Results"):** This statement is an overgeneralization. For the 1.5B model size, the purely autoregressive baseline (`Qwen2.5-1.5B (AR)`) outperforms the proposed model (`TtT-1.5B`) on the AlpacaEval dataset (17.99 vs. 15.68).

**3. Fundamental Logical Contradiction in the Proposed Training Methodology**

The paper's description of its training methodology contains a core logical conflict. A key design choice is presented as an advantage, while simultaneously being identified as a flaw that requires a partial and insufficient solution.

*   **Claim vs. Method:**
    *   The paper claims that its modality-aware attention mask enables "parallel training efficiency where all audio spans can undergo noise addition simultaneously in a single forward pass" (Section 3.4).
    *   However, the paper later acknowledges that this simultaneous masking creates a "cross-span contextual inconsistency" because a given audio span `A_m` is conditioned on preceding audio spans `A_{<m}` that are themselves masked during the same training step (Section 3.3). This is a critical train-test discrepancy, as the model sees corrupted context during training but expects clean context during inference.
    *   The proposed solution, Prefix Preservation Masking (PPM), is only applied to a fraction of training samples (30%, as stated in Section 4.1.4).
*   **Contradiction:** This means that for the majority of training (70% of samples), the model is intentionally trained with a flawed conditioning mechanism where it learns to denoise audio based on corrupted, rather than clean, preceding audio spans. The paper presents parallel processing as a primary benefit but fails to adequately address the severe contextual corruption it introduces.

**4. Inconsistent Reporting of Evaluation Datasets**

The manuscript provides conflicting information regarding the datasets used for Audio-QA evaluation.

*   **Evidence:**
    *   **Table 1 ("Main Results")** and the corresponding textual analysis in **Sections 4.2 and 4.3** explicitly refer to and report results on the "LLaMAQuestions" dataset.
    *   However, **Table 4 ("Evaluation datasets used for Audio-QA and ASR tasks")** in the appendix, which purports to list the evaluation datasets, lists "ReasoningQA" and omits "LLaMAQuestions".
*   **Impact:** This discrepancy creates confusion about which dataset was actually used for a significant portion of the evaluation, affecting the reproducibility and clarity of the experimental setup.

**Conclusion**

The manuscript suffers from several high-impact issues, most notably the use of seemingly fabricated references, which constitutes a serious breach of academic integrity. Furthermore, clear contradictions between textual claims and numerical results, a fundamental logical flaw in the training methodology, and inconsistent reporting of experimental details undermine the scientific validity of the work. Based on these findings, the manuscript is not suitable for publication in its current form.