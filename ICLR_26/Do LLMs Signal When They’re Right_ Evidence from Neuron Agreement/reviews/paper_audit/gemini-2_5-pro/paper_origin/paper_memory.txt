# Global Summary
This paper investigates the internal behavior of Large Language Models (LLMs) to improve sample-evaluate-ensemble decoding methods. The authors argue that existing methods relying on external signals like token probabilities are based on low-dimensional, poorly calibrated projections of richer internal dynamics. Their core findings are that, during generation, correct responses activate significantly fewer unique neurons and exhibit stronger cross-sample agreement in their activation patterns compared to incorrect responses.

Based on these insights, the paper proposes Neuron Agreement Decoding (NAD), an unsupervised best-of-N selection method that operates solely on internal neuron activations. NAD uses metrics like activation sparsity (MinAct) and cross-sample agreement (kNN, Medoid, DBSCAN) to select the best candidate from a pool of generated responses. The method does not require comparable textual outputs, making it applicable to open-ended tasks like coding.

Evaluations on math, science, and coding benchmarks show that NAD matches the performance of majority voting on tasks with verifiable answers and consistently outperforms the average performance of sampled candidates (Avg@64) on open-ended tasks. A key advantage is that these internal signals are reliable early in the generation process (within the first 32 tokens), enabling an aggressive early stopping strategy that reduces token consumption by up to 99% with minimal impact on quality.

# Abstract
The paper explores using internal neuron activations to improve sample-evaluate-ensemble decoding in LLMs, as external signals like token probabilities can be poorly calibrated. The authors present three findings: (1) external signals are low-dimensional projections of internal neuron dynamics; (2) correct responses activate substantially fewer unique neurons than incorrect ones; and (3) neuron activation patterns from correct responses show stronger cross-sample agreement.

Based on these findings, the paper proposes Neuron Agreement Decoding (NAD), an unsupervised best-of-N method that selects candidates using activation sparsity and cross-sample neuron agreement. NAD operates on internal signals and does not require comparable textual outputs. It can predict correctness within the first 32 generated tokens, allowing for early stopping. On math and science benchmarks, NAD's performance matches majority voting. On open-ended coding benchmarks where majority voting is inapplicable, NAD consistently outperforms the average of 64 samples (Avg@64). By enabling early pruning of unpromising generation paths, NAD reduces token usage by 99% with minimal quality loss.

# Introduction
Sample-evaluate-ensemble methods, like majority voting, are widely used to boost LLM reasoning performance without ground truth labels. However, many strategies rely on "external behaviors" such as token probabilities, confidence, or entropy, which may be poorly calibrated after model post-training. The paper questions the reliability of these external signals and proposes investigating "internal behaviors," specifically neuron activation vectors.

The authors' investigation reveals three key points:
1. External behaviors are low-dimensional projections of internal neuron activations.
2. Internal behaviors contain richer signals; specifically, correct responses activate significantly fewer neurons than incorrect ones.
3. Correct responses tend to activate similar sets of unique neurons, showing a pattern of agreement.

These insights lead to the proposal of Neuron-Agreement Decoding (NAD), an unsupervised method that selects high-quality reasoning trajectories based on internal neuron activations. NAD can identify promising candidates early in the generation process (e.g., within 32 tokens), enabling significant efficiency gains through early stopping. The method is evaluated on tasks with verifiable answers (math/science) and open-ended tasks (code generation), demonstrating effectiveness and a token consumption reduction of up to two orders of magnitude.

# Related Work
- **Outputs-based Voting:** This category includes methods like Self-consistency, which samples multiple chain-of-thought solutions and uses a majority vote to select the final answer. It works well for tasks with constrained outputs (e.g., numerical answers) but is less applicable to open-ended generation where answers are not easily comparable. Variants include Soft Self-Consistency.
- **Confidence-Based Selection:** This line of work uses internal confidence metrics. Examples include self-certainty, which uses token-level probabilities to score reasoning chains, and DeepConf, which prunes low-confidence paths during generation based on token prediction entropy. These methods typically require access to the model's probability distribution and may still be limited by the need for comparable answers.

# Preliminaries
This section details a pilot study on the relationship between internal neuron activations, external signals, and response correctness.

### 3.1 NEURON ACTIVATION SET
- Neuron activation is defined based on the SwiGLU-based contribution of a neuron to an output token's logit.
- The set of activated neurons for a sample is defined as all neurons whose contribution exceeds a threshold η for at least one token in the sequence.
- The paper refines this by dividing the generation sequence into chunks of size B, computing the activated set for each chunk, and then taking the union of these sets. This captures localized information during the reasoning process.

### 3.2 NEURON ACTIVATIONS: APPROXIMATE PREIMAGES OF CONFIDENCE METRICS
- The paper hypothesizes that scalar confidence metrics are low-dimensional projections of high-dimensional neuron activation states.
- Experiments on AIME24 with Qwen3-4B-Think (64 responses per instance) show significant correlations between the number of activated neurons and confidence metrics:
    - Negative correlation with Average Self-Certainty (Pearson r = -0.605, Spearman r = -0.631).
    - Positive correlation with Average Entropy (Pearson r = 0.633, Spearman r = 0.660).
- A t-SNE visualization of samples based on the Jaccard similarity of their activated neuron sets reveals distinct clusters. These clusters do not align with entropy values, suggesting that neuron activation patterns contain high-dimensional structural information not captured by scalar metrics.

### 3.3 PRELIMINARY EXPERIMENTS
- Visualizations of neuron activation patterns for multiple responses show that correct responses tend to form central clusters, while incorrect responses are often outliers. This leads to **Insight 1**: Neuron activation patterns can be used to define consensus and identify correct trajectories without text-level matching.
- A quantitative comparison shows that correct responses consistently activate substantially fewer unique neurons than incorrect ones. This trend holds throughout the generation process, token by token. This leads to **Insight 2**: The number of activated neurons in the early stages of generation can serve as a signal for response quality, with fewer activations indicating higher quality.

# Experiments
### 5.1 SETUP
- **Models:** Qwen3-4B-thinking-0527, Qwen3-4B-Instruct-0527, and DeepSeek-R1-0528-Qwen3-8B.
- **Generation Parameters:** n=64 samples per input, temperature=0.6, top-p=0.9.
- **Datasets:**
    - Scientific Reasoning: AIME24, AIME25, GPQA.
    - Code Generation: LiveCodeBench v5 (LCBv5), HumanEval, MBPP.
- **Baselines:** Avg@64 (mean accuracy over 64 samples) and Cons@64 (majority vote, for tasks with canonical answers).
- **Protocol:** Fixed sampling budget of n=64. For code generation, a single-execution protocol is used where only the final selected candidate is executed.

### 5.2 RESULTS
- **Main Results (Table 1):** NAD methods, particularly NAD-kNN, consistently outperform the Avg@64 baseline. For example, on Qwen3-4B-Think, NAD-kNN achieves an average score of 79.9 across all datasets, compared to 76.7 for Avg@64. On math reasoning tasks, NAD's performance is competitive with majority voting (Cons@64). On code generation, where majority voting is inapplicable, NAD provides performance gains over Avg@64. The MinAct method, while less effective than consensus-based NAD variants, still surpasses the baseline.
- **Early Stopping (Table 2):** Applying early stopping after the first chunk (32 tokens) dramatically reduces token consumption while maintaining strong performance. For Qwen3-4B-Think on AIME24+25, NAD-kNN reduces token usage by 97.6% (from 55.2M to 1.3M) while improving accuracy over Avg@64 (80.0% vs. 74.6%). On GPQA, token usage is cut by 98.0%. This demonstrates that early internal signals are reliable indicators of final answer quality.

### 5.3 ANALYSIS
- **Neuron Computation:** An analysis of different top-k filtering methods for defining activated neurons shows that the paper's default method (no sequence-level top-k filtering) achieves the best separation between the activation count distributions of correct and incorrect responses.
- **Early Stopping Position:** The effect of varying the early stopping position from 32 to 16384 tokens was studied. Performance does not monotonically improve with later stopping points; for instance, on AIME24+25, NAD-kNN accuracy is higher when stopping at 4096 tokens (86.7%) than when using the full response (85.0%). This suggests later tokens can introduce noise. Stopping at 32 tokens offers a good balance of performance and efficiency.
- **Neuron Activation and Performance:** A comparison between selecting the response with minimum vs. maximum neuron activations confirms the paper's hypothesis for scientific reasoning tasks, where minimum activation is significantly better. On code generation tasks, the performance gap is smaller, and sometimes the maximum-activation strategy performs better. This is attributed to the open-ended nature of coding, which may require activating a broader range of knowledge.

# Method
The methodology operationalizes the two key insights from the preliminary experiments.

### 4.1 NEURON-AGREEMENT DECODING (NAD)
NAD aims to find consensus among sampled trajectories by analyzing their neuron activation patterns.
- For n sampled trajectories, a pairwise similarity matrix S is computed using the Jaccard index between their activated neuron sets.
- Four selection methods are proposed:
    - **kNN-Agreement:** Selects the sample with the highest sum of similarity scores to its top-k nearest neighbors.
    - **Global Medoid:** Selects the sample that maximizes the sum of similarities to all other samples.
    - **DBSCAN:** Applies DBSCAN clustering to the distance matrix (1-S), identifies the largest cluster, and selects the medoid within that cluster.
    - **MinAct:** A simpler method based on Insight 2, which selects the trajectory with the minimum total number of activated neurons. This method does not require pairwise comparisons.

### 4.2 EARLY STOPPING STRATEGY
- Based on the finding that neuron activation patterns are predictive of quality early in generation, an early stopping strategy is proposed.
- The process involves generating n partial outputs up to a certain position j (e.g., 32 tokens), computing their activated neuron sets, applying one of the NAD selection schemes to choose the most promising trajectory, and then continuing generation for only that selected trace.
- In experiments, the stopping position j is set to the chunk size B=32.

# Conclusion
The paper demonstrates that internal neuron activation patterns in LLMs are reliable signals of response quality. Correct outputs are associated with fewer activated neurons and higher cross-sample agreement in activation patterns. The proposed Neuron-Agreement Decoding (NAD) method leverages these internal signals to select high-quality responses. Experiments show NAD matches majority voting on tasks with canonical answers and surpasses average sampling performance on open-ended coding tasks. By enabling early pruning of low-quality trajectories, NAD can reduce token consumption by up to 99% without sacrificing generation quality, highlighting the potential of using internal model dynamics for more efficient and reliable ensemble decoding.

# References
This section provides a list of all academic papers and resources cited in the manuscript.

# Appendix
### A LIMITATIONS
- The paper did not determine the optimal selector (kNN, Medoid, etc.) for different sampling patterns.
- Storing neuron activations for all samples can have a high storage overhead, though the authors suggest this is manageable with efficient encodings like bitsets.
- The evaluation is conducted under a fixed sampling budget (n=64) and a single-execution protocol for code, which may differ from other resource regimes.

### B IMPLEMENTATION FOR THRESHOLD FUNCTION
- The threshold for identifying activated neurons is determined using a token-level top-k function.
- For each token, the top 64 neuron contribution scores are selected from each layer.
- These scores are aggregated across all layers, and the k-th largest value (with k=500 in experiments) is used as the threshold η for that specific token.
- This token-level thresholding is the default method; sequence-level top-k is only used in a specific ablation.

### C DETAILED EXPERIMENT RESULTS
- This section includes Table 3, which presents detailed accuracy and token consumption results for code generation benchmarks under the early stopping strategy. The results confirm massive token savings (e.g., >97% reduction) while maintaining or improving accuracy over the Avg@64 baseline.
- It also includes additional figures (Figures 9, 10) showing the relationship between early stopping position, accuracy, and token consumption for different NAD variants on the AIME datasets.