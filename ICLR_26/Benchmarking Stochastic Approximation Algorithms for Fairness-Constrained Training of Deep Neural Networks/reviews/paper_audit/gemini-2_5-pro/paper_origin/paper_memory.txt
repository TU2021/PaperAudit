# Global Summary
This paper introduces a benchmark for evaluating stochastic approximation algorithms on fairness-constrained training of deep neural networks (DNNs). The core problem is formulated as a constrained empirical risk minimization (ERM) problem, where the objective and constraints are non-convex, non-smooth, and large-scale. The authors provide a Python toolbox that constructs these problems using US Census data (Folktables) and implements several algorithms. The paper reviews existing methods and experimentally compares three recently proposed but previously unimplemented algorithms: Stochastic Ghost (StGh), Stochastic Smoothed and Linearized AL Method (SSL-ALM), and Stochastic Switching Subgradient (SSw). The evaluation is performed on the ACSIncome dataset, using a small neural network. Key findings suggest that Augmented Lagrangian-based methods (ALM and SSL-ALM) offer the best compromise between improving fairness metrics (like independence and separation) and maintaining model accuracy. The paper explicitly states that no existing algorithm has theoretical convergence guarantees for this general problem setting and cautions that such tools are not a complete solution to ethical issues in machine learning.

# Abstract
The paper addresses the training of Deep Neural Networks (DNNs) with fairness constraints, noting the absence of a standard, widely accepted method. It introduces a benchmark for large-scale, real-world fairness-constrained learning tasks built upon the US Census data (Folktables). The work reviews theoretical challenges and main approaches in stochastic approximation algorithms. It then implements and compares three recent, previously unimplemented algorithms, evaluating their optimization performance and fairness improvement. The code for the benchmark is released as a Python package.

# Introduction
- The paper frames bias mitigation in DNNs as a constrained empirical risk minimization (ERM) problem: `min E[f(x,ξ)] s.t. E[c(x,ζ)] <= 0`.
- Fairness constraints are formulated as bounding the difference in empirical risk across subgroups, covering notions like Demographic Parity, Equal Opportunity, and Equalized Odds (Table 1).
- Despite numerous proposed algorithms, there is no standard toolkit or benchmark for comparing them, considering design choices like sampling, derivative order, and globalization strategies.
- The paper's contributions are: (1) a literature review of relevant algorithms, (2) a toolbox that implements four algorithms and provides a benchmark on real-world fairness problems from US Census data, and (3) numerical experiments comparing these algorithms.

# Related Work
- The constrained ERM approach is classified as an "in-processing" fairness method.
- It is contrasted with other in-processing methods like adversarial learning and adding differentiable regularizers (e.g., HSIC, Fairret).
- The paper argues that hard constraints can be more interpretable for practitioners than weighted penalty terms.
- It mentions existing fairness toolboxes like AIF360 and FairLearn, and benchmarks that often focus only on differentiable minimization.
- The constrained ERM problem formulation is noted to be applicable beyond fairness, in areas like neural network compression, improving statistical performance, and training with Lipschitz bounds.

# Preliminaries
- The standard ERM problem for training a DNN `f_θ` is defined as minimizing a loss function `ℓ` plus a regularizer `R(θ)`.
- Fairness-aware learning is formulated as a constrained ERM problem where the constraint bounds the difference in loss between a protected group `s` and a non-protected group `s_bar`. The specific formulation is: `| (1/|D[s]|) Σ ℓ(f_θ(X_i), Y_i) - (1/|D[s_bar]|) Σ ℓ(f_θ(X_i), Y_i) | <= δ`.
- Three baseline fairness criteria are defined:
    - **Independence (Ind)**: Prediction `Ŷ` is statistically independent of the protected attribute `S`. Also called statistical parity. Fairness gap is `|P(Ŷ=+ | S=s) - P(Ŷ=+ | S=s_bar)|`.
    - **Separation (Sp)**: Prediction `Ŷ` is statistically independent of `S` given the true label `Y`. Also called Equalized Odds. Fairness gap is `Σ |P(Ŷ=+ | S=s, Y=v) - P(Ŷ=+ | S=s_bar, Y=v)|` for `v` in `{+, -}`.
    - **Sufficiency (Sf)**: True label `Y` is statistically independent of `S` given the prediction `Ŷ`. Fairness gap is `Σ |P(Y=+ | S=s, Ŷ=v) - P(Y=+ | S=s_bar, Ŷ=v)|` for `v` in `{+, -}`.

# Method
- The paper addresses the optimization problem `min F(x) s.t. C(x) <= 0`, where `F` and `C` are expectations.
- Key challenges are: large-scale functions requiring sampling, inequality constraints, and non-convexity/non-smoothness from neural networks.
- A review of existing algorithms (Table 2) shows that most do not handle stochastic inequality constraints, and only one ([33]) handles non-smoothness. The paper concludes no algorithm currently exists with convergence guarantees for this general setting.
- Three algorithms are selected for implementation and comparison:
    - **Stochastic Ghost (StGh)**: Combines a non-stochastic method with an unbiased Monte Carlo sampling scheme. It solves a stochastic subproblem to find a search direction `d(x_k)` and updates via `x_{k+1} = x_k + α_k d(x_k)`. The sampling involves drawing a number `N` from a geometric distribution to determine mini-batch sizes.
    - **Stochastic Smoothed and Linearized AL Method (SSL-ALM)**: Based on an augmented Lagrangian (AL) function with an added smoothing term. It performs an inexact gradient descent on the Moreau envelope. It was originally designed for linear constraints but is adapted here. It uses small mini-batches.
    - **Stochastic Switching Subgradient (SSw)**: Designed for weakly convex and non-smooth problems. It switches between an objective update step and a constraint update step based on whether the current iterate `x_k` satisfies the constraint within a given tolerance `ε_k`.

# Experiments
- **Dataset**: ACSIncome from Folktables for the state of Oklahoma. Task is binary classification of income > $50k. It has 17,917 data points and 9 features. The protected attribute is race, binarized into "white" (non-protected) and "non-white" (protected). Data is split 80% train / 20% test, stratified.
- **Model**: A neural network with 2 hidden layers (64 and 32 units), ReLU activations, and 194 parameters. The loss is Binary Cross Entropy with Logits.
- **Algorithms Compared**: StGh, SSL-ALM, ALM (SSL-ALM with smoothing term removed), and SSw. Baselines are unconstrained SGD and SGD with a Fairret regularizer (SGD-Fairret). All experiments are run 10 times.
- **Optimization Performance**:
    - On the training set, ALM and SSL-ALM show the best behavior, minimizing loss while satisfying constraints with low variability.
    - StGh exhibits high variability in both loss and constraint values.
    - SSw, with the chosen parameters, fails to satisfy the constraints.
    - On the test set, ALM and SSL-ALM show a slight bias in constraint satisfaction, which is noted as expected generalization behavior.
- **Fairness Performance (Table 3, Test Set)**:
    - **SGD (baseline)**: Ina: 0.215, Ind: 0.097, Sp: 0.176, Sf: 0.171.
    - **StGh**: Best on fairness metrics (Ind: 0.049, Sp: 0.096) but worst on accuracy (Ina: 0.276).
    - **ALM**: Good compromise. Ina: 0.244, Ind: 0.058, Sp: 0.114, Sf: 0.221.
    - **SSL-ALM**: Similar to ALM. Ina: 0.240, Ind: 0.066, Sp: 0.117, Sf: 0.215.
    - **SSw**: Intermediate performance. Ina: 0.229, Ind: 0.080, Sp: 0.144, Sf: 0.175.
    - **SGD-Fairret**: Minor fairness improvements over SGD. Ina: 0.213, Ind: 0.094, Sp: 0.174, Sf: 0.180.
- The constrained methods generally improve Independence and Separation at the cost of accuracy, while having higher (worse) Sufficiency values than the baselines.

# Conclusion
- The paper provides what is claimed to be the first benchmark for assessing optimization methods on real-world, fairness-constrained DNN training.
- It highlights the challenges of non-convex, non-smooth, large-scale problems and reviews the performance of four practical algorithms.
- **Limitations**: The work identifies that no current algorithm has theoretical guarantees for solving the general fairness-constrained problem. It also includes a strong ethical caution that fair ML tools are not a "silver-bullet" and must be part of a broader, interdisciplinary approach to tackling ethical issues. The provided Python toolbox is intended to stimulate further research.

# References
This section contains the list of 55 references cited throughout the manuscript.

# Appendix
- **Appendix A**: Provides detailed pseudocode for the three main algorithms evaluated: Stochastic Ghost (Algorithm 1), Stochastic Smoothed and Linearized AL Method (Algorithm 2), and Stochastic Switching Subgradient Method (Algorithm 3).
- **Appendix B**: Presents an additional experiment on the SSw algorithm. When using equal stepsizes for the objective and constraint updates (`η_k^f = η_k^c = 0.02`), the algorithm satisfies the constraints well but the objective function is "barely minimized." This illustrates a trade-off in parameter tuning for this method.