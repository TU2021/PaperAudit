# Global Summary
The paper addresses fairness-constrained training of deep neural networks by benchmarking stochastic approximation algorithms on real-world tasks. It formulates constrained empirical risk minimization (ERM) where constraints bound differences in empirical loss across protected subgroups (e.g., demographic parity, equal opportunity, equalized odds). The authors build a benchmark atop US Census Folktables, provide automated construction of constrained ERM from PyTorch/TensorFlow computation graphs, and define up to ‚Äú5.7 billion‚Äù protected subgroup combinations. They implement four practical optimization methods‚ÄîStochastic Ghost (StGh), Stochastic Smoothed and Linearized Augmented Lagrangian Method (SSL-ALM), a plain Augmented Lagrangian Method (ALM), and Stochastic Switching Subgradient (SSw)‚Äîand compare them against SGD baselines (without and with fairness regularization via Fairret). Evaluation uses ACSIncome (Oklahoma) with 17,917 samples, 9 features, race as the protected attribute (binarized), and a 80/20 stratified split (14,333 train; 3,584 test). Metrics include independence (Ind), separation (Sp), sufficiency (Sf), inaccuracy (Ina), and Wasserstein distance (Wd) between group prediction distributions. Across 10 runs per method, StGh achieves the strongest fairness (lowest Ind/Sp) but the worst accuracy; ALM and SSL-ALM offer the best trade-off (improved fairness with moderate accuracy degradation); SSw sits between SGD and other constrained models. Key test-set numbers: SGD Ind 0.097¬±0.006, Sp 0.176¬±0.016, Ina 0.215¬±0.002, Sf 0.171¬±0.009, Wd 0.008¬±0.000; StGh Ind 0.049¬±0.029, Sp 0.096¬±0.039, Ina 0.276¬±0.022, Sf 0.211¬±0.033, Wd 0.003¬±0.002; ALM Ind 0.058¬±0.012, Sp 0.114¬±0.014, Ina 0.244¬±0.007, Sf 0.221¬±0.017, Wd 0.003¬±0.001; SSL-ALM Ind 0.066¬±0.011, Sp 0.117¬±0.023, Ina 0.240¬±0.012, Sf 0.215¬±0.022, Wd 0.004¬±0.001; SSw Ind 0.080¬±0.029, Sp 0.144¬±0.050, Ina 0.229¬±0.013, Sf 0.175¬±0.031, Wd 0.002¬±0.001; SGD-Fairret Ind 0.094¬±0.010, Sp 0.174¬±0.019, Ina 0.213¬±0.002, Sf 0.180¬±0.022, Wd 0.006¬±0.001. Caveats: no algorithm has guarantees for the full general nonconvex, nonsmooth, large-scale stochastic inequality-constrained setting; fairness generalization bias is observed; the benchmark and toolkit are released (https://github.com/humancompatible/train) but are not a comprehensive solution to all ethical issues.

# Abstract
- Problem: Constrained training of DNNs to improve fairness lacks a standard method.
- Contributions:
  - Challenging benchmark of large-scale fairness-constrained learning tasks built on US Census Folktables [22].
  - Theoretical challenges are highlighted; main stochastic approximation approaches are reviewed.
  - Three recently proposed, previously unimplemented algorithms are implemented and compared on optimization performance and fairness improvement.
  - Code released as a Python package: https://github.com/humancompatible/train.
- Scope: Real-world fairness-constrained training; in-processing constraints bounding subgroup empirical risk differences.

# Introduction
- Motivation: Legislative pressure (e.g., EU AI Act) to remove bias; ambiguity in bias definition and mitigation.
- Formulation: Constrained ERM minimizing expected loss subject to expected constraints (Equation (1)).
- Fairness constraints c: Specific forms for demographic parity, equal opportunity, and equalized odds presented (Table 1) as bounds on differences of expected losses across groups and label conditions with parameter Œ¥.
- Engineering: Automated construction of ERM formulations from computation graphs (PyTorch/TensorFlow), choice of fairness constraints, and protected subgroup definitions; US Census via Folktables enabling definitions of up to ‚Äú5.7 billion‚Äù protected subgroups.
- Design choices cataloged (sampling, derivative orders, globalization strategies).
- Contributions:
  - Literature review of algorithms for (1).
  - Toolbox implementing four algorithms and an easy-to-use benchmark on real-world fairness problems.
  - Numerical experiments comparing algorithms and alternative fairness approaches.
- Paper structure: Section 2 related works/fairness notions; Section 3 algorithms; Section 4 experiments; Section 5 conclusions.
- Status: Equal contribution note; preprint under review.

# Related Work
- Fairness method categories:
  - Pre-processing (data modification) [50, 23].
  - In-processing (algorithm modifications; includes constrained ERM (1)) [53].
  - Post-processing (prediction adjustments) [35].
- In-processing approaches:
  - Adversarial fairness (predictor with adversary) [1, 38, 39, 25].
  - Penalization/regularizers (HSIC [37], Fairret [11], Prejudice Remover [34]).
- Hard constraints (rate constraints) [16]: Nonconvex, nonsmooth, large-scale inequality constraints; claim advantages over weighted penalties; rate constraints piecewise-constant (unsuitable for first-order methods).
- Toolboxes: AIF360 [4], FairLearn [8]; others include Pareto front computation [21], differentiable fairness penalties [11].
- Benchmarks and datasets: Surveys [36]; new datasets [22]; benchmark [30] notes ‚Äúnot all widely used fairness datasets stably exhibit fairness issues‚Äù and reviews in-processing methods focused on differentiable minimization; other benchmarks [20, 26, 46, 15]. Statistical aspects of fairness-constrained ERM considered recently [12].
- Applications of (1): Credit scoring, hiring, healthcare [14], ranking/recommendation [47], forecasting linear dynamical systems [55], two-sided markets [54], network compression [13], statistical performance [42, 48], Lipschitz-constrained training [45].
- Common challenge: Large-scale constraints.

# Preliminaries
- DNN regression objective (Equation (2)): ERM loss plus regularizer R(Œ∏), losses include logistic, hinge, absolute deviation, square; DNN recursion defined over L layers (Equation (3)); activations include ReLU, quadratic, hinge, SoftPlus.
- Binary classification setup: Y, ≈∂ ‚àà {+, ‚àí}; dataset attributes; class attribute Y.
- Fairness-constrained ERM (Equation (4)): Minimize ERM subject to bounded difference in average loss between protected and non-protected groups: ‚àíŒ¥ ‚â§ mean loss(ùíü[s]) ‚àí mean loss(ùíü[ sÃÑ ]) ‚â§ Œ¥; R possibly set to 0.
- Fairness metrics (following [3]):
  - Independence (Ind): |P(≈∂=+ | S=s) ‚àí P(≈∂=+ | S= sÃÑ )|.
  - Separation (Sp) / Equalized Odds (EO): sum over v‚àà{+,-} of |P(≈∂=+ | S=s, Y=v) ‚àí P(≈∂=+ | S= sÃÑ , Y=v)|.
  - Sufficiency (Sf): sum over v‚àà{+,-} of |P(Y=+ | S=s, ≈∂=v) ‚àí P(Y=+ | S= sÃÑ , ≈∂=v)|.
- Trade-offs: Independence, separation, and sufficiency cannot be simultaneously attained; fairness-accuracy trade-off.

# Method
- Problem (5): Minimize F(x) subject to C(x) ‚â§ 0, where F and C are expectations over random variables Œæ, Œ∂.
- Challenges: Large-scale objectives/constraints needing sampling; inequality (not just equality) constraints; nonconvexity and nonsmoothness due to DNNs.
- Notation: Projection; geometric distribution N ~ ùí¢(p0); mini-batches; stochastic estimates from J samples (Equation (6): averaged gradients/constraints).
- Table 2 (assumptions overview): Comparison of algorithmic assumptions (stochastic objectives/constraints, differentiability, inequality constraints, etc.). Key claims:
  - Most methods do not consider stochastic constraints; among those that do, only three admit inequality constraints.
  - Except for [33], all assume F at least C^1, limiting nonsmoothness handling.
  - Recent work [19] indicates ‚Äútame locally Lipschitz‚Äù functions are suitable, but no algorithm with guarantees exists for this generality.
- Algorithms selected for practical performance: Stochastic Ghost [27], SSL-ALM [32], Stochastic Switching Subgradient [33].

- Stochastic Ghost Method (StGh):
  - Basis: Non-stochastic Ghost penalty method [28] with stochastic sampling inspired by unbiased Monte Carlo [9].
  - Subproblem (7) (deterministic) and stochastic variant (8) using mini-batch averages; feasibility maintained via Œ∫k and constraints C(xk)+‚àáC(xk)·µÄ d ‚â§ Œ∫k e; infinity-norm bound ‚Äñd‚Äñ‚àû ‚â§ Œ≤.
  - Unbiased direction construction (Equation (9)): Sample N ~ ùí¢(p0), form batches Xk^1 and Xk^{2^{N+1}}, partition into odd/even halves, solve (8) on each, combine to obtain d(xk).
  - Update: x_{k+1} = x_k + Œ±_k d(x_k); stepsize Œ±_k square-summable but not summable; Algorithm 1 details.

- Stochastic Smoothed and Linearized AL Method (SSL-ALM):
  - Originally for stochastic linear constraints [32]; adapted via slack variables for inequality constraints; domain ùìß = ‚Ñù^n √ó ‚Ñù_{‚â•0}^m.
  - Augmented Lagrangian LœÅ(x,y) = F(x) + y·µÄ C(x) + (œÅ/2)‚ÄñC(x)‚Äñ¬≤; proximal AL K_{œÅ,Œº} adds smoothing Œº/2‚Äñx‚àíz‚Äñ¬≤.
  - G(x,y,z;Œæ,Œ∂1,Œ∂2) defined so that E[G] = ‚àáK (Equation (10)); sampling uses Œæ, Œ∂1, Œ∂2 per iteration.
  - Updates (Equation (11)): y_{k+1} = y_k + Œ∑ c(x,Œ∂1); x_{k+1} = proj_ùìß( x_k ‚àí œÑ G ); z_{k+1} = z_k + Œ≤(x_k ‚àí z_k); Algorithm 2 includes y-norm truncation at M_y.

- Stochastic Switching Subgradient (SSw):
  - For weakly convex, possibly nonsmooth F and C over closed convex ùìß; uses subgradients rather than gradients.
  - Inputs: infeasibility tolerances Œµ_k; stepsizes Œ∑_k^f, Œ∑_k^c.
  - At iteration k: estimate cÃÑ^J(x_k) from J samples; if cÃÑ^J(x_k) ‚â§ Œµ_k, update via objective subgradient S^f; else update via constraint subgradient S^c; both updates projected onto ùìß.
  - Outputs recorded from k ‚â• k0; final output randomly sampled from recorded set with probability proportional to stepsizes; Algorithm 3 details. Variant here allows Œ∑_k^f ‚â† Œ∑_k^c (original had equal stepsizes).

# Experiments
- Dataset:
  - ACSIncome (Oklahoma) from Folktables [22]; binary classification: income > $50,000.
  - 9 features; 17,917 data points; protected attribute RAC1P binarized: ‚Äúwhite‚Äù (non-protected) vs ‚Äúnon-white‚Äù (protected).
  - Split: train 80% (14,333), test 20% (3,584); stratified by protected attribute; positive label rates: 30.8% in ‚Äúwhite‚Äù, 20.7% in ‚Äúnon-white‚Äù.
  - Protected attributes removed from features; normalization via StandardScaler.
  - Note: ERM predictors without fairness safeguards are known to learn biases on ACSIncome [30].

- Problems:
  - Constrained ERM (Equation (4)) with R = 0 (loss-difference constraint; specific Œ¥ not specified).
  - Baselines: ERM (Equation (2)) with R = 0 (SGD) and ERM with Fairret fairness regularizer [11] (SGD-Fairret).
  - Loss: Binary Cross Entropy with Logits (Equation (12)); network: 2 hidden layers (sizes 64 and 32), ReLU activation; total parameters: 194.

- Computing environment:
  - Asus Zenbook UX535; AMD Ryzen 7 5800H CPU; 16GB RAM.
  - Python, PyTorch [44].

- Algorithms and parameters:
  - StGh: p0 = 0.4, Œ±0 = 0.05, œÅ = 0.8, œÑ = 1, Œ≤ = 10, Œª = 0.5, \bar{Œ±} = 0.05.
  - SSL-ALM: Œº = 2.0, œÅ = 1.0, œÑ = 0.01, Œ∑ = 0.05, Œ≤ = 0.5, M_y = 10.
  - ALM: Œº = 0 (otherwise same as SSL-ALM).
  - SSw: Œ∑_k^f = 0.5, Œ∑_k^c = 0.05, Œµ_k = 10^{‚àí4} if k < 500, Œµ_k = 0.97 Œµ_{k‚àí1} for k ‚â• 500 at each epoch.
  - Constraint estimation: sample equal number of data points per subgroup.
  - Each algorithm run 10 times; plots show mean, median, quartiles.

- Optimization performance (Figures 1, 2):
  - Four constrained algorithms reduce train loss and largely satisfy train constraints; AL-based methods (ALM, SSL-ALM) show better behavior (lower variability; constraints closer to bounds) than StGh (higher variability) and SSw (fails to satisfy constraints under chosen parameters).
  - ERM baselines minimize loss faster and with less variability but do not satisfy constraints.
  - On test, ALM/SSL-ALM constraints slightly biased towards negative values; generalization behavior noted (see [12]).
  - Runtime details beyond plots are not specified in text.

- Fairness performance (Figure 3, Table 3, Figure 4):
  - Prediction distributions: SGD (no fairness) shows notable group disparity; constrained models (StGh, SSL-ALM, ALM, SSw) yield closer distributions; SGD-Fairret is intermediate.
  - Wasserstein distances (Wd) reflect distribution closeness; constrained models have lower Wd than SGD.
  - Table 3 (mean ¬± std over 10 runs; train and test):
    - SGD: Train Ind 0.094¬±0.004, Sp 0.132¬±0.007, Ina 0.201¬±0.001, Sf 0.115¬±0.006, Wd 0.008¬±0.000; Test Ind 0.097¬±0.006, Sp 0.176¬±0.016, Ina 0.215¬±0.002, Sf 0.171¬±0.009, Wd 0.008¬±0.000.
    - StGh: Train Ind 0.048¬±0.026, Sp 0.049¬±0.028, Ina 0.273¬±0.024, Sf 0.200¬±0.038, Wd 0.002¬±0.001; Test Ind 0.049¬±0.029, Sp 0.096¬±0.039, Ina 0.276¬±0.022, Sf 0.211¬±0.033, Wd 0.003¬±0.002.
    - ALM: Train Ind 0.058¬±0.007, Sp 0.061¬±0.016, Ina 0.240¬±0.012, Sf 0.197¬±0.011, Wd 0.003¬±0.000; Test Ind 0.058¬±0.012, Sp 0.114¬±0.014, Ina 0.244¬±0.007, Sf 0.221¬±0.017, Wd 0.003¬±0.001.
    - SSL-ALM: Train Ind 0.066¬±0.009, Sp 0.071¬±0.015, Ina 0.233¬±0.017, Sf 0.186¬±0.013, Wd 0.003¬±0.001; Test Ind 0.066¬±0.011, Sp 0.117¬±0.023, Ina 0.240¬±0.012, Sf 0.215¬±0.022, Wd 0.004¬±0.001.
    - SSw: Train Ind 0.077¬±0.029, Sp 0.115¬±0.029, Ina 0.224¬±0.017, Sf 0.133¬±0.015, Wd 0.001¬±0.001; Test Ind 0.080¬±0.029, Sp 0.144¬±0.050, Ina 0.229¬±0.013, Sf 0.175¬±0.031, Wd 0.002¬±0.001.
    - SGD-Fairret: Train Ind 0.091¬±0.012, Sp 0.121¬±0.017, Ina 0.201¬±0.002, Sf 0.106¬±0.010, Wd 0.005¬±0.001; Test Ind 0.094¬±0.010, Sp 0.174¬±0.019, Ina 0.213¬±0.002, Sf 0.180¬±0.022, Wd 0.006¬±0.001.
  - Narrative: StGh best Ind/Sp but worst Ina; SSw intermediate; ALM/SSL-ALM provide best compromise (improved Ind/Sp with moderate Ina degradation); SGD-Fairret slightly improves Sf relative to SGD (observed on train).

# Conclusion
- Claim: First benchmark assessing optimization methods on real-world fairness-constrained training instances.
- Summary: Highlights challenges (nonconvex, nonsmooth, large-scale; inequality constraints; stochastic objectives/constraints) and evaluates four practical algorithms.
- Limitations:
  - No existing algorithm with guarantees for the fully general fairness-constrained problem.
  - The toolbox/benchmark is intended to spur further research; it is not a comprehensive solution to all biases and ethical issues.
  - Emphasizes the need for fair ML within interdisciplinary pipelines; cautions against using toolkits as an excuse for ‚ÄúBusiness-As-Usual‚Äù [2, 52].

# References
- Includes references to fairness toolkits (AIF360 [4], FairLearn [8]), datasets and benchmarks (Folktables [22], FFB [30], surveys [36], [26]), constrained optimization algorithms (StGh [27, 28], SSL-ALM [32], SSw [33], SQP/ALM methods [6, 29, 40, 41, 49]), fairness metrics and frameworks ([3], regularizers [11, 34, 37]), and applications (healthcare [14], rankings [47], compression [13], Lipschitz training [45]).
- The paper cites 55 references (numbered [1]‚Äì[55]). Specific bibliographic details are provided in the manuscript‚Äôs reference list.

# Appendix
- A: Algorithm pseudocodes (Algorithms 1‚Äì3).
  - Algorithm 1 (StGh): Inputs, sampling strategy (N ~ ùí¢(p0), mini-batches X_k^1 and X_k^{2^{N+1}}), direction computation via Equation (9), stepsize update Œ±_k = Œ±_{k‚àí1}(1 ‚àí Œ±ÃÇ Œ±_{k‚àí1}), projection not specified, iterate update.
  - Algorithm 2 (SSL-ALM): Inputs, sampling Œæ, Œ∂1, Œ∂2; y update with truncation if ‚Äñy_{k+1}‚Äñ ‚â• M_y ‚áí reset y_{k+1} = 0; x update via proj_ùìß and G (Equation (10)); z update.
  - Algorithm 3 (SSw): Inputs K, Œµ_k, Œ∑_k^f, Œ∑_k^c, mini-batch size J, starting index k0; feasibility check via cÃÑ^J(x_k); objective/constraint subgradient updates; output sampling from recorded indices with probability P(œÑ=k) = Œ∑_k / ‚àë_{s‚ààI} Œ∑_s.
- B: Additional experiments on SSw.
  - Setting: Equal objective and constraint stepsizes Œ∑_k^f = Œ∑_k^c = 0.02.
  - Observation: Constraints satisfied well, but objective function barely minimized (illustrated for train/test over ~30 seconds; figures show loss curves trending to ~0.65 and constraint values near bounds).
- Figures: Loss and constraint trajectories (train/test) and SSw detailed plots; image placeholders and captions provided.
- Missing details: Exact Œ¥ (constraint bound) not specified; exact runtime per algorithm not specified in text.