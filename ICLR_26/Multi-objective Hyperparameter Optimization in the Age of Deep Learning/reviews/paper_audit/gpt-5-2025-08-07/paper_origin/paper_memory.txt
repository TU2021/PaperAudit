# Global Summary
- Problem: Deep Learning hyperparameter optimization often requires optimizing multiple objectives (e.g., validation error, training cost) and practitioners possess prior beliefs about good hyperparameter regions. Existing HPO algorithms rarely use expert priors, and none support multi-objective priors; many also ignore cheap approximations (multi-fidelity).
- Approach: PriMO, a Bayesian optimization algorithm that (i) integrates multi-objective expert priors in its acquisition function with a controlled decay and ε-greedy exploration, and (ii) exploits cheap approximations via a multi-fidelity initial design using MOASHA to seed BO at maximum fidelity. Objectives are scalarized with random weights.
- Evaluation scope: 8 DL surrogate benchmarks (PD1: cifar100, imagenet, lm1b, translate_wmt; YAHPO-Gym LCBench tasks: 126026, 146212, 168330, 168868). Metrics: dominated hypervolume and mean relative ranks. Protocol: 25 seeds, 20 equivalent full function evaluations per optimizer-benchmark-seed, with statistical significance via LMEM and CD diagrams. Baselines include BO+RW, ParEGO, HB+RW, MOASHA, NSGA-II, Random Search, plus prior-based MO adaptations (πBO+RW, MO-Priorband, RS+Prior). Single-objective baselines: BO, HyperBand, Priorband+BO, πBO.
- Key findings: PriMO claims state-of-the-art multi-objective and single-objective performance with strong anytime and final results, robust to misleading priors, and effective use of cheap approximations. Under good priors, PriMO delivers speedups “up to ~10x” (language model xFormer hypervolume), and overall ranks indicate PriMO best among evaluated algorithms. Ablations indicate all components (initial MF design, MO priors, ε-BO) are necessary.
- Quantitative highlights: 25 seeds; 20 evaluations per run; initial design size 5; ε = 0.25; reduction factor η = 3; γ = exp(−n_BO^2 / n_d); LM (xFormer) hypervolume speedup up to ~10x; overall relative rank curves show PriMO around ~1.8–2.2 vs baselines ~2.2–3.2 (scale 1–4) in Figure 1; compute: ~172 CPU hours (~5160 core hours), 30 cores (Intel Xeon Gold 6242), ~0.02 CPU hours per seed (~0.6 core hours on average).
- Caveats explicitly stated: Priors modeled as Gaussians; priors are over individual objectives rather than Pareto fronts; scalarization is linear though hypervolume scalarization may offer guarantees; details on exact numeric hypervolume improvements per benchmark are visual and not always tabulated.

# Abstract
- Introduces PriMO as “the first HPO algorithm that can integrate multi-objective user beliefs.”
- Claims state-of-the-art performance across 8 DL benchmarks for both multi-objective and single-objective settings.
- Highlights speedups “up to ~10x” when leveraging good priors.

# Introduction
- Motivation: DL pipelines are sensitive to hyperparameters; manual tuning incorporates expert beliefs but is costly. Existing prior-guided HPO research focuses on single-objective; DL often requires multi-objective optimization (e.g., cost, latency, fairness).
- Desiderata for multi-objective HPO for DL:
  1. Utilize cheap approximations (multi-fidelity proxies).
  2. Integrate multi-objective expert priors and recover from misleading priors.
  3. Strong anytime performance under limited budgets.
  4. Strong final performance as budgets grow.
- Table 1 overview (RS, EA, MOMF, MO-BO vs PriMO): PriMO is reported to satisfy all four desiderata; existing algorithms satisfy at most half.
- Figure 1 (Overall relative ranks): PriMO achieves best mean relative ranks across 8 DL benchmarks; curves indicate PriMO around ~1.8–2.2 vs BO+RW ~2.2–2.8, MOASHA ~2.2–3.2, ParEGO ~3.0–3.2 (scale 1–4).
- Figure 1 (Language Model XFormer hypervolume): PriMO shows “~10x speedup” leveraging good priors; hypervolume quickly reaches ~10400 vs slower baselines (scale 8000–11000).
- Contributions:
  - First consideration of expert priors for multiple objectives; naive adaptations are not robust.
  - PriMO integrates multi-objective priors in BO’s acquisition and uses cheap proxies in initial design (MOASHA), achieving up to 10x speedups.
  - Demonstrates SOTA across multi- and single-objective DL benchmarks; robust across prior strengths; ablations verify necessity of components.

# Method
- Problem formulation: Minimize vector-valued objective f(λ) with cheap approximations and expert priors. For each objective f_i, define prior π_{f_i}(λ) = P(f_i(λ) = min_{λ′∈Λ} f_i(λ′)). Compound prior Π_f(λ) = {π_{f_i}(λ)}_{i=1}^n.
- Cheap approximations: \hat{f}_i(λ, z) is a low-fidelity proxy; f_i(λ) = \hat{f}_i(λ, z_max). Goal: arg min_{λ} (\hat{f}_1(λ, z_max), …, \hat{f}_n(λ, z_max)), guided by Π_f(λ).
- Acquisition and priors (Section 4.1):
  - Each iteration selects one objective prior uniformly at random.
  - Acquisition weighting: α(λ, D) · π_{f_j}(λ)^γ with γ = exp(−n_BO^2 / n_d), reducing dependence on priors as BO samples accumulate.
  - ε-greedy: with probability ε, use base α(λ, D); with 1−ε, use prior-augmented α; j ∼ Uniform(1..n).
  - Scalarization: random linear weights w_i > 0, sum to 1; minimize Σ_i w_i \hat{f}_i(λ, z_max).
- Initial design (Section 4.2):
  - Use MOASHA to sample configurations at varying fidelities, accumulating “equivalent full function evaluations” until threshold n_init is reached.
  - Only max-fidelity evaluations (z = z_max) are included in BO dataset D. Weights w guide initial scalarized inclusion.
  - Rationale: MOASHA’s strong early performance and budget invariance provide a head-start before BO.
- PriMO algorithm (Section 4.3, Algorithm 3):
  - Inputs: f, search space Λ (dimension n_d), priors Π_f, initial design size n_init, reduction factor η, fidelities [z_min, z_max], budget B, ε.
  - Steps: sample weights w; run initial design to get D; iterate BO with moprior_bo, increment n_BO; evaluate at z_max; update D; return Pareto set P_f(D).
- Single-objective adaptation: Replace MOASHA with ASHA in initial design; sample from single prior; ε-BO unchanged.

# Motivation
- Study naive solution: adapt MOASHA to sample configurations from priors either every iteration (100%) or half the iterations (50%).
- Findings (Figure 2):
  - Under good priors, always sampling from prior outperforms standard MOASHA.
  - Under misleading priors, always sampling causes “drastically poor performance.”
  - 50% prior sampling does better overall than MOASHA but fails to utilize good priors as effectively as 100% sampling or prior-based RS.
- Conclusion: Naive prior integration is not robust; motivates PriMO’s design to leverage good priors and recover from bad ones.

# Experiments
- Research questions: RQ1–RQ6 cover anytime/final performance, single-objective performance, leveraging priors, robustness to bad priors, effectiveness of cheap approximations via initial design, and necessity of components.
- Setup (Section 5.1):
  - Metric: mean dominated hypervolume; report relative rankings across budgets.
  - Seeds: 25; Budget: 20 equivalent full function evaluations per optimizer-benchmark-seed.
  - Benchmarks: 8 (PD1: cifar100-wide_resnet-2048, imagenet-resnet-512, lm1b-transformer-2048, translate-wmt-xformer-64; YAHPO-LCBench task IDs 126026, 146212, 168330, 168868).
  - Objectives: validation error + training cost; fidelity: epochs.
  - Priors: combinations of all-good, all-bad, mixed, and overall average; constructed following single-objective literature (Appendix D).
- Baselines (Section 5.2):
  - MO literature: BO+RW, ParEGO, HB+RW, MOASHA, NSGA-II.
  - Prior-based MO adaptations: RS+Prior, MOASHA+Prior, πBO (extended with random scalarizations, πBO+RW), Priorband (extended to MO as MO-Priorband).
  - Single-objective: BO, HyperBand, Priorband+BO, πBO.
- Results (Section 5.3):
  - Multi-objective: PriMO shows strongest anytime and final performance in relative rank across all benchmarks (Figure 3). Under good priors, PriMO’s advantage vs BO+RW is more pronounced. Hypervolume plots per benchmark (Figure 4) show PriMO best very early, attributed to the initial design; ε-BO maintains strong anytime performance and final SOTA across benchmarks.
  - PriMO reduces prior dependence after ~10 BO samples due to the chosen γ setting.
  - Single-objective: PriMO is overall best for both anytime and final performance (Figure 6); Priorband and πBO start strong under good priors but are quickly outperformed “within a few full function evaluations.”
- Robustness (Section 5.4):
  - All-bad priors: PriMO recovers from a poor start and “nearly catches up with BO+RW” by end of budget (competitive final performance).
  - Mixed and overall conditions: PriMO best early and significantly better by final iteration; prior-based MO adaptations (e.g., πBO+RW) are more prone to misleading priors (Appendix I reports statistical significance).
- Ablations (Section 5.5):
  - Components: initial design (MOASHA), MO priors, ε-BO with random weights.
  - Initial design gives substantial early boost (RQ5). Without ε-BO, performance does not sustain; pairing MF initial design with ε-BO is needed for strong long-run performance.
  - Removing priors or ε-BO degrades performance; MOASHA with PriMO sampler is robust but not the most competitive.
- Additional compute efficiency and scaling (Appendix H.3):
  - Initial design size 5; asynchronous MF yields ~3.5 equivalent evaluations (~3 max-fidelity configs for GP fit), yet PriMO achieves better early performance than BO-based baselines.
- Statistical significance (Appendix I):
  - LMEM-based tests and CD diagrams validate PriMO’s early and final superiority; seed independence confirmed via GLRT; benchmarks informative; PriMO significantly better overall than baselines across conditions.
- Resource usage (Appendix K):
  - Hardware: CPU cluster with 30 cores (Intel(R) Xeon(R) Gold 6242 @ 2.80GHz).
  - Per-seed runtime: ~0.02 CPU hours (~0.6 core hours on average); MF optimizers ~0.15 core hours; model-based baselines often >5 minutes (~2.5 core hours).
  - Scale: 19 optimizers; prior-based MO evaluated under 4 prior combinations; single-objective under 2 priors; 20 evaluations; 8 benchmarks; 25 seeds; total ~172 CPU hours (~5160 core hours).

# Related Work
- Single-objective prior integration: Priorband (integrates expert priors and cheap approximations throughout optimization), πBO (prior-augmented acquisition with decay; no cheap approximations), PrBO (TPE-based pseudo-posteriors). Authors report their MO adaptations perform poorly under misleading priors and that PriMO’s design addresses these issues.
- Multi-objective cheap approximations: HB+RW, MOASHA, MO-TPE, MF extensions (MF-OSEMO, iMOCA) and EHVI-based fidelity methods, but these often use proxies throughout and can be computationally expensive. PriMO distinctively uses cheap approximations as an initial design before BO.

# Discussion
- Limitations:
  - Priors modeled as Gaussian distributions; PriMO supports any prior distribution but experiments use Gaussians.
  - Priors over Pareto fronts could be beneficial but are non-trivial to define for experts; PriMO already achieves SOTA with simple priors.
  - Linear scalarization is used; hypervolume scalarization may offer guarantees for non-convex fronts.

# Conclusion
- PriMO is presented as the first algorithm to integrate multi-objective expert priors and to fulfill all desiderata for practical DL HPO (cheap approximations, multi-objective priors, strong anytime and final performance).
- Claims SOTA performance and efficiency under constrained budgets across both multi-objective and single-objective settings.

# Appendix
- Implementation details (Appendix C):
  - Built on NePS; initial design via MOASHA (ε-net from Syne Tune); η = 3; initial design size = 5; ε = 0.25; base acquisition qLogNoisyEI (BoTorch); WeightedAcquisition adapted from πBO.
- Prior construction (Appendix D):
  - For each objective: uniformly sample 100,000 configurations; evaluate at z_max; good prior = best config perturbed by Gaussian noise σ = 0.01; bad prior = worst config; priors as Gaussian N(λ, σ^2) with σ = 0.25.
- Baselines (Appendix E):
  - BO in NePS (q-Log-NoisyEI; initial design size = search space dimension).
  - HyperBand (η = 3).
  - πBO (NePS γ = e^{−n_BO / n_d} in single-objective; MO extension uses random weights and randomly chosen priors per iteration).
  - BO+RW (random scalarizations), ParEGO (SMAC3), NSGA-II (Nevergrad defaults), HB+RW, MOASHA (NePS; η = 3).
  - MO-Priorband: MOMF + scalarized incumbents; η = 3.
  - Priorband+BO: model-based extension using q-Log-NoisyEI.
- Benchmarks and metrics (Appendix F–G):
  - PD1 reference points for HVI: valid_error_rate (max) = 1.0; train_cost (max): cifar100 = 30, imagenet = 5000, lm1b = 1000, translate_wmt = 20000.
  - LCBench tasks (126026, 146212, 168330, 168868) reference points: val_cross_entropy (max) = 1.0; time (max seconds): 150, 150, 5000, 200 respectively.
  - Common YAHPO-LCBench search space includes batch_size [16, 512], learning_rate [1e-4, 0.1], momentum [0.1, 0.99], weight_decay [1e-5, 0.1], num_layers [1, 5], max_units [64, 1024], max_dropout [0.0, 1.0], epoch [1, 52].
  - Evaluation protocol: HV vs static reference point; equivalent function evaluations z/z_max for MF optimizers; single-objective uses normalized regret; 25 seeds; 20 evaluations.
- Additional analyses (Appendix H):
  - Good priors: Pareto fronts show PriMO and BO+RW locate most non-dominated points; PriMO better coverage; πBO+RW sometimes marginally better due to longer prior dependence; MO-Priorband often worst.
  - Bad priors: PriMO recovers best final performance across benchmarks; πBO+RW fails to recover.
  - Compute efficiency: PriMO’s initial MF design needs ~3.5 equivalent evaluations to yield ~3 max-fidelity points for GP fit; despite fewer samples, PriMO achieves better early performance.
- Significance (Appendix I):
  - LMEMs and GLRT confirm seed independence and benchmark informativeness; CD diagrams at 10 and 20 evaluations show PriMO significantly better overall; under good priors early performance comparable only to πBO+RW; under bad priors PriMO significantly better than prior-based baselines and competitive with BO+RW.
- Code and resources (Appendix J–K):
  - Public repository includes priors, experiment code, plots, reproducibility guidelines, and raw results.
  - Total compute ~172 CPU hours (~5160 core hours); MF optimizers ~0.15 core hours/run; model-based ~2.5 core hours/run.
- Licenses: Apache 2.0, BSD 3-Clause, MIT across used packages (NePS, hpoglue, mf-prior-bench, YAHPO Gym, HyperBO PD1, Nevergrad, SMAC, Syne Tune ε-net, lmem-significance).

# References
- Cited works include foundational and contemporary methods relevant to HPO, Bayesian optimization, multi-objective optimization, and DL benchmarks: HyperBand (2017), BOHB (2018), ParEGO (2006), NSGA-II (2002), EHVI and MO-BO methods, Priorband (2023), πBO (2022), mf-prior-bench (2025), NePS (2025), YAHPO-Gym (2022), HyperBO PD1 (2024), and others. Specific references and bibliographic details are listed in the manuscript’s References section.