### Summary

This paper introduces **OvA-LP**, a framework for **Federated Fine-Tuning (FFT)** that tackles the challenge of **non-IID data** in decentralized machine learning. The method focuses on **suppressing local drift** at its source, which is caused by heterogeneous client distributions, using a minimalist approach: **linear probing (LP) on a frozen encoder**, **one-vs-all (OvA) heads**, and a **two-stage training schedule**. OvA-LP is shown to outperform traditional **personalized** or **PEFT** (parameter-efficient fine-tuning) methods under non-IID conditions, providing higher **stability** and **efficiency** without sacrificing much accuracy. The framework has been tested on **CIFAR-100** and **DomainNet** datasets, demonstrating strong results and generalizability to different datasets, model architectures, and participation ratios.

---

### Strengths

1. **Source-Level Drift Suppression**:

   * OvA-LP focuses on mitigating drift before it begins by freezing the encoder, removing **label bias** using OvA heads, and controlling **variance** with a two-stage training schedule. This proactive design stands out compared to methods that try to address drift after it has already occurred.

2. **Simplicity and Efficiency**:

   * The framework uses a **minimalist approach** by combining simple components that are easy to implement and computationally efficient. By only fine-tuning the linear head, OvA-LP achieves strong performance without the need for complex modules like **MoE** or **LoRA**.

3. **Empirical Validation**:

   * OvA-LP shows strong **non-IID robustness** and **fast convergence** across multiple experiments, demonstrating its practical applicability in federated learning (FL) environments. It achieves up to **93.4% Non-IID accuracy** on **CIFAR-100** with **100% participation**, which is a substantial improvement over **PEFT methods**.

4. **Clear Theoretical Motivation**:

   * The bias-variance perspective in the paper clearly explains why each component of OvA-LP contributes to improving model stability under non-IID conditions. The framework is grounded in well-understood concepts, with each design choice aimed at addressing specific sources of drift.

5. **Modularity and Generality**:

   * OvA-LP¡¯s modularity allows it to be integrated with other personalization and aggregation schemes, making it adaptable to a range of FL tasks. The authors also extended the framework to different backbones (e.g., **RoBERTa**, **ConvNeXt**) and **NLP** tasks, confirming its broad applicability.

---

### Weaknesses

1. **Unfair Baseline Comparison**:

   * A significant weakness is the unfair comparison between OvA-LP and **PEFT-based baselines** like **PFPT** and **FFT-MoE**. While these methods adapt the encoder (which introduces drift), OvA-LP avoids this by freezing the encoder. Comparing these methods directly without equalizing the encoder configurations skews the results. The paper would benefit from a **fairer comparison** by ensuring all methods use the same **frozen encoder** configuration, or by comparing OvA-LP with **LoRA-based** federated methods.

2. **Limited Theoretical Depth**:

   * The **bias-variance decomposition** is used as a **conceptual framework**, but the lack of formal proofs or bounds weakens the theoretical rigor. The paper does not provide concrete mathematical guarantees for the proposed design, leaving the claims about drift suppression and variance control largely **qualitative**.

3. **Narrow Scope of Validation**:

   * The paper mainly focuses on **vision tasks** using **ViT encoders**, with **CIFAR-100** and **DomainNet** as the primary datasets. The generalization to other tasks, such as **NLP** or **time-series**, is not well-explored. While some NLP experiments are presented with **RoBERTa** and **SBERT**, a broader **cross-domain evaluation** would strengthen the claims of OvA-LP's robustness and applicability.

4. **Practical Assumptions**:

   * The paper's **100% client participation** assumption is unrealistic in most real-world FL settings. The efficiency claims of OvA-LP are based on this idealized setup, but **partial participation** results should have been analyzed more thoroughly. The revised manuscript addresses this by presenting results under **partial participation**, but the assumption of **100% participation** still overshadows the practical implications of the method.

5. **Missing Sensitivity Analysis**:

   * There is no detailed analysis of how hyperparameters or **Non-IID severity** affect performance. The paper mentions that **OvA-LP** works well with fixed hyperparameters, but a **comprehensive sensitivity analysis** would provide deeper insight into the robustness of the framework under varying conditions.
