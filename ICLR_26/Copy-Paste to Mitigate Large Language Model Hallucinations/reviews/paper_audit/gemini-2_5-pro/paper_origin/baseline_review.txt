1) Summary
This paper addresses the problem of contextual faithfulness in Retrieval-Augmented Generation (RAG), where large language models (LLMs) may hallucinate by ignoring provided context in favor of their internal parametric knowledge. The authors observe an inverse correlation between the degree to which a model copies from the context and its hallucination rate. Based on this, they propose CopyPasteLLM, a two-stage framework. First, three "CopyPaste-Prompting" methods are used to generate high-copying responses, which serve as preferred examples. Second, this preference data is used to fine-tune a base LLM using Direct Preference Optimization (DPO), teaching it to favor context-grounded, high-copying outputs. The resulting model shows significant improvements in faithfulness on several benchmarks, notably achieving 12.2%-24.5% higher accuracy on FaithEval with 50x less training data than a strong baseline. A novel analysis method reveals the model learns to suppress its reliance on parametric knowledge.2) Strengths
*   **Novel and Well-Motivated Core Idea**
    *   The central hypothesis—that a higher degree of copying from the context can serve as a proxy for and a mechanism to improve contextual faithfulness—is intuitive and compelling. This idea is grounded in an empirical observation of an inverse correlation between copying degree and hallucination on the RAGTruth dataset (Figure 1, Section 2.2).
    *   This approach elegantly connects the problem of faithfulness to the problem of attribution. By design, responses with a high copy degree are inherently attributable to the source context, addressing a key challenge in RAG systems (Section 1, Section 5).
    *   The formalization of "copying degree" using Copy Coverage (κ) and Copy Density (δ) provides a quantifiable and optimizable objective for the proposed methods (Section 2.1, Equation 1).*   **Strong Empirical Performance and Data Efficiency**
    *   The proposed CopyPasteLLM achieves state-of-the-art results, significantly outperforming strong baselines on challenging counterfactual benchmarks. On FaithEval, it improves accuracy by 12.2 to 24.5 percentage points over the best baseline across three different models (Table 1, Section 4.1.2).
    *   The method is remarkably data-efficient. The authors report achieving these results using preference data generated from only 365 query-context pairs, which is 1/50th of the data used by the Context-DPO baseline (Section 4.1.2). This makes the approach highly practical.
    *   The performance gains are consistent across multiple models (Mistral-7B, Llama-3-8B, Llama-3.1-8B) and datasets, including both counterfactual (FaithEval, ConFiQA) and standard QA settings (PubMedQA) (Table 1, Table 3).*   **Comprehensive and Automated Methodological Pipeline**
    *   The two-stage framework is well-structured. Stage 1 provides a systematic way to generate high-quality preference data through three distinct prompting strategies (CP-Order, CP-Link, CP-Refine) that explore a spectrum from hard to soft constraints (Section 3.1, Figure 2).
    *   The preference data construction pipeline in Stage 2 is fully automated, incorporating multi-criteria filtering, an LLM-as-judge tournament for ranking, and a clever "answer stamping" technique to create informative preference pairs (Section 3.2, Algorithm 2). This removes the need for expensive human annotation.
    *   The use of Direct Preference Optimization (DPO) is a suitable and effective choice for internalizing the desired high-copying behavior into the model's policy (Section 3.2, Algorithm 2).*   **Insightful Mechanistic Analysis**
    *   The paper goes beyond demonstrating performance and offers a plausible mechanistic explanation for the model's effectiveness. The proposed Context-Parameter Copying Capturing algorithm provides a tool for token-level analysis of knowledge sourcing (Section 3.3, Algorithm 3).
    *   The logit analysis shows that CopyPasteLLM not only relies more on contextual knowledge but also does so earlier in the generation process compared to the base model (Figure 3, Section 4.2).
    *   The hidden state analysis using UMAP is particularly insightful, suggesting that the training does not significantly alter the model's representation of contextual knowledge but instead recalibrates its reliance on parametric knowledge by creating a clearer separation between the two knowledge sources in its representation space (Figure 4, Section 4.2).3) Weaknesses
*   **Unclear Scalability and Cost of Preference Generation**
    *   The preference data generation in Stage 1 relies on multiple LLM calls per sample, especially for the iterative CP-Refine method which involves a writer-reviewer loop (Section 3.1, Algorithm 1). While the paper demonstrates success with 365 samples, the computational cost and latency of this process for generating larger-scale preference datasets are not discussed.
    *   The generation of candidate responses for DPO training was performed with a specific powerful model (DeepSeek-V3-0324) (Appendix D). The quality of the generated preference data, and thus the final performance of CopyPasteLLM, may be highly dependent on the capability of this generator model. The robustness of the prompting methods across different generator models is not explored.
    *   No direct evidence found in the manuscript regarding the time or computational resources required for the data generation stage.*   **Potential Negative Trade-offs are Under-explored**
    *   The strong emphasis on copying might negatively impact other desirable qualities of a generated response, such as conciseness, synthesis of information from multiple disparate sentences, and linguistic creativity or naturalness. The paper evaluates fluency via perplexity in Stage 1 (Table 2 in Appendix, not in main text) but lacks a qualitative or human evaluation of the final CopyPasteLLM outputs to assess these potential trade-offs.
    *   The framework's effectiveness is predicated on the context containing a complete and correct answer. The paper acknowledges this limitation in the appendix (Appendix G), but it is a critical point for real-world RAG applications where contexts are often noisy or incomplete. This limitation deserves more prominent discussion in the main paper.
    *   The evaluation metrics for RQ2 (Accuracy and Hit Rate) are primarily focused on correctness in multiple-choice or short-answer settings (Appendix A, Section 4.1.2). This may not fully capture the quality of the longer, free-form responses that the model is trained to produce.*   **Ambiguities in the Analysis Methodology**
    *   The Context-Parameter Copying Capturing algorithm (Algorithm 3) contains several implementation details that lack clarity. For instance, the criterion for identifying "meaningless tokens" (line 8) is not defined, which could significantly affect the analysis.
    *   The logic for categorizing a token as contextual (`x_j in C`) versus parametric (`x_j in A_para`) is presented as mutually exclusive, but common words could easily appear in both, and the algorithm's handling of this overlap is not fully specified (Algorithm 3, lines 12-17).
    *   The "logits power" metric is defined late in the appendix (Appendix I, Equation 2) and its mathematical motivation is not explained. It is unclear why this specific formulation (sum of squared logits multiplied by the square root of sample count) was chosen over simpler alternatives, making the interpretation of Figure 3 less grounded.4) Suggestions for Improvement
*   **Discuss Scalability and Generalization of Data Generation**
    *   Please add a discussion in the main text or appendix about the computational cost (e.g., number of API calls, tokens processed per sample) of the Stage 1 preference generation pipeline. This would help readers assess the practicality of scaling the approach.
    *   To improve the claim of robustness, please include a brief ablation or discussion on how the choice of the generator model (DeepSeek-V3-0324) affects the quality of the preference data and the final performance. For example, does using a smaller generator model still yield effective preference pairs?
    *   Provide an estimate of the resources used for data generation to complement the training details provided in Appendix D.*   **Conduct a More Holistic Evaluation of Trade-offs**
    *   To provide a more balanced view of the model's capabilities, please consider adding a small-scale human evaluation. This evaluation could compare outputs from CopyPasteLLM and a strong baseline (e.g., the base model or Context-DPO) on dimensions like naturalness, conciseness, and ability to synthesize information, in addition to faithfulness.
    *   Please move the discussion of key limitations, particularly the assumption of context completeness, from Appendix G into a dedicated "Limitations" or "Discussion" section in the main paper to give it appropriate visibility.
    *   Consider adding a qualitative analysis with a few examples of generated outputs in the appendix to showcase the model's behavior and illustrate the differences between the CopyPasteLLM and baseline responses in a more tangible way.*   **Clarify the Analysis Algorithm and Metrics**
    *   Please refine the description of Algorithm 3. Explicitly define what constitutes a "meaningless token" (e.g., a list of stop words).
    *   Please clarify the logic in Algorithm 3 for handling tokens that could be classified as both contextual and parametric. For example, does the algorithm prioritize one category over the other, or are such tokens excluded from the analysis?
    *   Please introduce the "logits power" formula (Equation 2) in the main methodology section (e.g., Section 3.3) where the analysis is first described. Include a brief justification for its specific mathematical form to help the reader understand its properties and interpret the results in Figure 3 more accurately.5) Score
*   Overall (10): 8 — The paper presents a novel, effective, and data-efficient method for a critical problem, supported by strong results and insightful analysis (Table 1, Figure 4).
*   Novelty (10): 9 — The core idea of using high copy-degree as a direct preference for DPO to improve faithfulness is highly novel and intuitive (Section 1, Figure 1).
*   Technical Quality (10): 8 — The methodology is sound and the experiments are thorough, though the analysis algorithm could be specified more clearly (Algorithm 3, Equation 2).
*   Clarity (10): 8 — The paper is generally well-written and clearly structured, but key details about the analysis method are relegated to the appendix or are ambiguous (Section 3.3, Appendix I).
*   Confidence (5): 5 — I am highly confident in my assessment, as the paper aligns with my area of expertise in RAG and LLM fine-tuning.