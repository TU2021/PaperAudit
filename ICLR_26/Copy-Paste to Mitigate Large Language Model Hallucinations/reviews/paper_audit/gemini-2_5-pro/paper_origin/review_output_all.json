{
  "baseline_review": "1) Summary\nThis paper addresses the problem of contextual faithfulness in Retrieval-Augmented Generation (RAG), where large language models (LLMs) may hallucinate by ignoring provided context in favor of their internal parametric knowledge. The authors observe an inverse correlation between the degree to which a model copies from the context and its hallucination rate. Based on this, they propose CopyPasteLLM, a two-stage framework. First, three \"CopyPaste-Prompting\" methods are used to generate high-copying responses, which serve as preferred examples. Second, this preference data is used to fine-tune a base LLM using Direct Preference Optimization (DPO), teaching it to favor context-grounded, high-copying outputs. The resulting model shows significant improvements in faithfulness on several benchmarks, notably achieving 12.2%-24.5% higher accuracy on FaithEval with 50x less training data than a strong baseline. A novel analysis method reveals the model learns to suppress its reliance on parametric knowledge.2) Strengths\n*   **Novel and Well-Motivated Core Idea**\n    *   The central hypothesis—that a higher degree of copying from the context can serve as a proxy for and a mechanism to improve contextual faithfulness—is intuitive and compelling. This idea is grounded in an empirical observation of an inverse correlation between copying degree and hallucination on the RAGTruth dataset (Figure 1, Section 2.2).\n    *   This approach elegantly connects the problem of faithfulness to the problem of attribution. By design, responses with a high copy degree are inherently attributable to the source context, addressing a key challenge in RAG systems (Section 1, Section 5).\n    *   The formalization of \"copying degree\" using Copy Coverage (κ) and Copy Density (δ) provides a quantifiable and optimizable objective for the proposed methods (Section 2.1, Equation 1).*   **Strong Empirical Performance and Data Efficiency**\n    *   The proposed CopyPasteLLM achieves state-of-the-art results, significantly outperforming strong baselines on challenging counterfactual benchmarks. On FaithEval, it improves accuracy by 12.2 to 24.5 percentage points over the best baseline across three different models (Table 1, Section 4.1.2).\n    *   The method is remarkably data-efficient. The authors report achieving these results using preference data generated from only 365 query-context pairs, which is 1/50th of the data used by the Context-DPO baseline (Section 4.1.2). This makes the approach highly practical.\n    *   The performance gains are consistent across multiple models (Mistral-7B, Llama-3-8B, Llama-3.1-8B) and datasets, including both counterfactual (FaithEval, ConFiQA) and standard QA settings (PubMedQA) (Table 1, Table 3).*   **Comprehensive and Automated Methodological Pipeline**\n    *   The two-stage framework is well-structured. Stage 1 provides a systematic way to generate high-quality preference data through three distinct prompting strategies (CP-Order, CP-Link, CP-Refine) that explore a spectrum from hard to soft constraints (Section 3.1, Figure 2).\n    *   The preference data construction pipeline in Stage 2 is fully automated, incorporating multi-criteria filtering, an LLM-as-judge tournament for ranking, and a clever \"answer stamping\" technique to create informative preference pairs (Section 3.2, Algorithm 2). This removes the need for expensive human annotation.\n    *   The use of Direct Preference Optimization (DPO) is a suitable and effective choice for internalizing the desired high-copying behavior into the model's policy (Section 3.2, Algorithm 2).*   **Insightful Mechanistic Analysis**\n    *   The paper goes beyond demonstrating performance and offers a plausible mechanistic explanation for the model's effectiveness. The proposed Context-Parameter Copying Capturing algorithm provides a tool for token-level analysis of knowledge sourcing (Section 3.3, Algorithm 3).\n    *   The logit analysis shows that CopyPasteLLM not only relies more on contextual knowledge but also does so earlier in the generation process compared to the base model (Figure 3, Section 4.2).\n    *   The hidden state analysis using UMAP is particularly insightful, suggesting that the training does not significantly alter the model's representation of contextual knowledge but instead recalibrates its reliance on parametric knowledge by creating a clearer separation between the two knowledge sources in its representation space (Figure 4, Section 4.2).3) Weaknesses\n*   **Unclear Scalability and Cost of Preference Generation**\n    *   The preference data generation in Stage 1 relies on multiple LLM calls per sample, especially for the iterative CP-Refine method which involves a writer-reviewer loop (Section 3.1, Algorithm 1). While the paper demonstrates success with 365 samples, the computational cost and latency of this process for generating larger-scale preference datasets are not discussed.\n    *   The generation of candidate responses for DPO training was performed with a specific powerful model (DeepSeek-V3-0324) (Appendix D). The quality of the generated preference data, and thus the final performance of CopyPasteLLM, may be highly dependent on the capability of this generator model. The robustness of the prompting methods across different generator models is not explored.\n    *   No direct evidence found in the manuscript regarding the time or computational resources required for the data generation stage.*   **Potential Negative Trade-offs are Under-explored**\n    *   The strong emphasis on copying might negatively impact other desirable qualities of a generated response, such as conciseness, synthesis of information from multiple disparate sentences, and linguistic creativity or naturalness. The paper evaluates fluency via perplexity in Stage 1 (Table 2 in Appendix, not in main text) but lacks a qualitative or human evaluation of the final CopyPasteLLM outputs to assess these potential trade-offs.\n    *   The framework's effectiveness is predicated on the context containing a complete and correct answer. The paper acknowledges this limitation in the appendix (Appendix G), but it is a critical point for real-world RAG applications where contexts are often noisy or incomplete. This limitation deserves more prominent discussion in the main paper.\n    *   The evaluation metrics for RQ2 (Accuracy and Hit Rate) are primarily focused on correctness in multiple-choice or short-answer settings (Appendix A, Section 4.1.2). This may not fully capture the quality of the longer, free-form responses that the model is trained to produce.*   **Ambiguities in the Analysis Methodology**\n    *   The Context-Parameter Copying Capturing algorithm (Algorithm 3) contains several implementation details that lack clarity. For instance, the criterion for identifying \"meaningless tokens\" (line 8) is not defined, which could significantly affect the analysis.\n    *   The logic for categorizing a token as contextual (`x_j in C`) versus parametric (`x_j in A_para`) is presented as mutually exclusive, but common words could easily appear in both, and the algorithm's handling of this overlap is not fully specified (Algorithm 3, lines 12-17).\n    *   The \"logits power\" metric is defined late in the appendix (Appendix I, Equation 2) and its mathematical motivation is not explained. It is unclear why this specific formulation (sum of squared logits multiplied by the square root of sample count) was chosen over simpler alternatives, making the interpretation of Figure 3 less grounded.4) Suggestions for Improvement\n*   **Discuss Scalability and Generalization of Data Generation**\n    *   Please add a discussion in the main text or appendix about the computational cost (e.g., number of API calls, tokens processed per sample) of the Stage 1 preference generation pipeline. This would help readers assess the practicality of scaling the approach.\n    *   To improve the claim of robustness, please include a brief ablation or discussion on how the choice of the generator model (DeepSeek-V3-0324) affects the quality of the preference data and the final performance. For example, does using a smaller generator model still yield effective preference pairs?\n    *   Provide an estimate of the resources used for data generation to complement the training details provided in Appendix D.*   **Conduct a More Holistic Evaluation of Trade-offs**\n    *   To provide a more balanced view of the model's capabilities, please consider adding a small-scale human evaluation. This evaluation could compare outputs from CopyPasteLLM and a strong baseline (e.g., the base model or Context-DPO) on dimensions like naturalness, conciseness, and ability to synthesize information, in addition to faithfulness.\n    *   Please move the discussion of key limitations, particularly the assumption of context completeness, from Appendix G into a dedicated \"Limitations\" or \"Discussion\" section in the main paper to give it appropriate visibility.\n    *   Consider adding a qualitative analysis with a few examples of generated outputs in the appendix to showcase the model's behavior and illustrate the differences between the CopyPasteLLM and baseline responses in a more tangible way.*   **Clarify the Analysis Algorithm and Metrics**\n    *   Please refine the description of Algorithm 3. Explicitly define what constitutes a \"meaningless token\" (e.g., a list of stop words).\n    *   Please clarify the logic in Algorithm 3 for handling tokens that could be classified as both contextual and parametric. For example, does the algorithm prioritize one category over the other, or are such tokens excluded from the analysis?\n    *   Please introduce the \"logits power\" formula (Equation 2) in the main methodology section (e.g., Section 3.3) where the analysis is first described. Include a brief justification for its specific mathematical form to help the reader understand its properties and interpret the results in Figure 3 more accurately.5) Score\n*   Overall (10): 8 — The paper presents a novel, effective, and data-efficient method for a critical problem, supported by strong results and insightful analysis (Table 1, Figure 4).\n*   Novelty (10): 9 — The core idea of using high copy-degree as a direct preference for DPO to improve faithfulness is highly novel and intuitive (Section 1, Figure 1).\n*   Technical Quality (10): 8 — The methodology is sound and the experiments are thorough, though the analysis algorithm could be specified more clearly (Algorithm 3, Equation 2).\n*   Clarity (10): 8 — The paper is generally well-written and clearly structured, but key details about the analysis method are relegated to the appendix or are ambiguous (Section 3.3, Appendix I).\n*   Confidence (5): 5 — I am highly confident in my assessment, as the paper aligns with my area of expertise in RAG and LLM fine-tuning.",
  "final_review": "1) Summary\nThis paper addresses the problem of contextual faithfulness in Retrieval-Augmented Generation (RAG), where large language models (LLMs) may hallucinate by ignoring provided context in favor of their internal parametric knowledge. The authors observe an inverse correlation between the degree to which a model copies from the context and its hallucination rate. Based on this, they propose CopyPasteLLM, a two-stage framework. First, three \"CopyPaste-Prompting\" methods are used to generate high-copying responses, which serve as preferred examples. Second, this preference data is used to fine-tune a base LLM using Direct Preference Optimization (DPO), teaching it to favor context-grounded, high-copying outputs. The resulting model shows significant improvements in faithfulness on several benchmarks, notably achieving 12.2%-24.5% higher accuracy on FaithEval with 50x less training data than a strong baseline. A novel analysis method is proposed to reveal the model's knowledge sourcing.2) Strengths\n*   **Novel and Well-Motivated Core Idea**\n    *   The central hypothesis—that a higher degree of copying from the context can serve as a proxy for and a mechanism to improve contextual faithfulness—is intuitive and compelling. This idea is grounded in an empirical observation of an inverse correlation between copying degree and hallucination on the RAGTruth dataset (Figure 1, Section 2.2).\n    *   This approach elegantly connects the problem of faithfulness to the problem of attribution. By design, responses with a high copy degree are inherently attributable to the source context, addressing a key challenge in RAG systems (Section 1, Section 5).\n    *   The formalization of \"copying degree\" using Copy Coverage (κ) and Copy Density (δ) provides a quantifiable and optimizable objective for the proposed methods (Section 2.1, Equation 1).*   **High Reported Performance and Data Efficiency**\n    *   The proposed CopyPasteLLM is reported to achieve state-of-the-art results, significantly outperforming strong baselines on challenging counterfactual benchmarks. On FaithEval, it is claimed to improve accuracy by 12.2 to 24.5 percentage points over the best baseline across three different models (Table 1, Section 4.1.2).\n    *   The method is presented as remarkably data-efficient. The authors report achieving these results using preference data generated from only 365 query-context pairs, which is stated to be 1/50th of the data used by the Context-DPO baseline (Section 4.1.2).\n    *   The performance gains are reported to be consistent across multiple models (Mistral-7B, Llama-3-8B, Llama-3.1-8B) and datasets, including both counterfactual (FaithEval, ConFiQA) and standard QA settings (PubMedQA) (Table 1, Table 3).*   **Comprehensive and Automated Methodological Pipeline**\n    *   The two-stage framework is well-structured. Stage 1 provides a systematic way to generate high-quality preference data through three distinct prompting strategies (CP-Order, CP-Link, CP-Refine) that explore a spectrum from hard to soft constraints (Section 3.1, Figure 2).\n    *   The preference data construction pipeline in Stage 2 is fully automated, incorporating multi-criteria filtering, an LLM-as-judge tournament for ranking, and an \"answer stamping\" technique to create informative preference pairs (Section 3.2, Algorithm 2). This removes the need for expensive human annotation.\n    *   The use of Direct Preference Optimization (DPO) is a suitable and effective choice for internalizing the desired high-copying behavior into the model's policy (Section 3.2, Algorithm 2).*   **Proposes a Novel Method for Mechanistic Analysis**\n    *   The paper proposes the Context-Parameter Copying Capturing algorithm, a tool for token-level analysis of knowledge sourcing during generation (Section 3.3, Algorithm 3).\n    *   This method extends prior work by applying the analysis to the entire Chain-of-Thought reasoning process, rather than just short final answers, which could provide more granular insights (Section 3.3).\n    *   The algorithm is designed to capture and differentiate between contextual and parametric knowledge usage by running generation with and without context and analyzing the top-K tokens, which is a reasonable approach for this type of analysis (Algorithm 3).3) Weaknesses\n*   **Critical Issues in Experimental Reporting and Validity**\n    *   There is a major, unexplained contradiction regarding the training data size. The abstract and main text repeatedly claim training was performed with data derived from \"only 365 training samples\" (Abstract, Section 4.1.2), but Appendix A states that RAGTruth (839 samples), FaithEval (1,000 samples), and PubMedQA (1,000 samples) were all used for training (Table 4). This discrepancy fundamentally undermines the central claim of data efficiency.\n    *   The experimental design suggests potential data contamination. Table 4 in Appendix A indicates that the FaithEval and PubMedQA datasets were used for both \"Train\" and \"Eval\". The manuscript does not state whether disjoint splits were used, raising serious concerns that the model may have been evaluated on data it was trained on, which would invalidate the reported performance metrics.*   **Potential Integrity Issues in Analysis Results**\n    *   The UMAP visualizations presented in the appendix appear to contain duplicated figures, which calls the integrity of the mechanistic analysis into question. The plots for the Mistral-7B-Instruct-v0.2 model are visually identical for the FaithEval dataset (Appendix Figure 8) and the RAGTruth dataset (Appendix Figure 9). It is highly improbable for UMAP projections on two different datasets to be identical, suggesting a reporting error where one result was copied over the other. This undermines the conclusions drawn in Section 4.2 about how the model works.*   **Unclear Scalability and Cost of Preference Generation**\n    *   The preference data generation in Stage 1 relies on multiple LLM calls per sample, especially for the iterative CP-Refine method (Section 3.1, Algorithm 1). The computational cost of this process for generating larger-scale datasets is not discussed.\n    *   The quality of the generated preference data may be highly dependent on the capability of the generator model (DeepSeek-V3-0324, Appendix D). The robustness of the prompting methods across different generator models is not explored.\n    *   The \"50x\" data efficiency claim is ambiguous. The paper compares its \"365 query-context pairs\" to the baseline's \"18,000 samples\" (Section 4.1.2), but the proposed method generates ~5 preference pairs per source sample (Algorithm 2). It is unclear if the baseline's 18,000 samples refers to source pairs or final preference pairs, making the comparison difficult to verify.*   **Potential Negative Trade-offs are Under-explored**\n    *   The strong emphasis on copying might negatively impact other desirable qualities like conciseness, synthesis of information, and linguistic naturalness. The paper lacks a qualitative or human evaluation of the final CopyPasteLLM outputs to assess these potential trade-offs.\n    *   The framework's effectiveness is predicated on the context containing a complete and correct answer. The paper acknowledges this limitation in the appendix (Appendix G), but it is a critical point for real-world RAG applications that deserves more prominent discussion.\n    *   The evaluation metrics for RQ2 (Accuracy and Hit Rate) are primarily focused on correctness in multiple-choice or short-answer settings (Appendix A, Section 4.1.2), which may not fully capture the quality of longer, free-form responses.*   **Ambiguities in the Analysis Methodology**\n    *   The Context-Parameter Copying Capturing algorithm (Algorithm 3) contains several implementation details that lack clarity. For instance, the criterion for identifying \"meaningless tokens\" (line 8) is not defined.\n    *   The logic for categorizing a token as contextual (`x_j in C`) versus parametric (`x_j in A_para`) is presented as mutually exclusive, but common words could appear in both, and the algorithm's handling of this overlap is not specified (Algorithm 3, lines 12-17).\n    *   The \"logits power\" metric is defined late in the appendix (Appendix I, Equation 2) and its mathematical motivation is not explained, making the interpretation of Figure 3 less grounded.4) Suggestions for Improvement\n*   **Clarify Experimental Setup and Ensure Valid Evaluation**\n    *   Please resolve the contradiction regarding the training data size. The manuscript must clearly state the exact origin and composition of the 365 samples and explain how this relates to the datasets listed as \"Train\" in Table 4.\n    *   Please explicitly confirm whether strictly disjoint splits of FaithEval and PubMedQA were used for training and evaluation. If there was overlap, the experiments must be re-run with a clean separation to ensure the validity of the results.*   **Verify and Correct the Mechanistic Analysis**\n    *   Please carefully review and correct the UMAP visualizations in the appendix. The apparent duplication between Figure 8 and Figure 9 for the Mistral-7B model must be addressed. If it is an error, the correct figure should be provided, and the conclusions in Section 4.2 should be revisited based on the corrected results.*   **Discuss Scalability and Refine Efficiency Claims**\n    *   Please add a discussion about the computational cost (e.g., number of API calls, tokens processed per sample) of the Stage 1 preference generation pipeline to help readers assess its practicality.\n    *   Please include a brief ablation or discussion on how the choice of the generator model affects the quality of the preference data and the final performance.\n    *   Please clarify the basis for the \"50x\" data efficiency claim by specifying whether the baseline's \"18,000 samples\" refers to source documents or final preference pairs, ensuring an apples-to-apples comparison.*   **Conduct a More Holistic Evaluation of Trade-offs**\n    *   Please consider adding a small-scale human evaluation comparing outputs from CopyPasteLLM and a baseline on dimensions like naturalness, conciseness, and ability to synthesize information.\n    *   Please move the discussion of key limitations, particularly the assumption of context completeness, from Appendix G into a dedicated \"Limitations\" section in the main paper.\n    *   Consider adding a qualitative analysis with a few examples of generated outputs in the appendix to showcase the model's behavior and illustrate the differences between the CopyPasteLLM and baseline responses.*   **Clarify the Analysis Algorithm and Metrics**\n    *   Please refine the description of Algorithm 3 by explicitly defining what constitutes a \"meaningless token\" (e.g., a list of stop words).\n    *   Please clarify the logic in Algorithm 3 for handling tokens that could be classified as both contextual and parametric.\n    *   Please introduce the \"logits power\" formula (Equation 2) in the main methodology section (e.g., Section 3.3) and include a brief justification for its specific mathematical form.5) Score\n*   Overall (10): 3 — The paper proposes an interesting idea, but critical flaws in experimental reporting, potential data contamination, and apparent duplication of results severely undermine the validity of its central claims (Table 4, Figure 8, Figure 9).\n*   Novelty (10): 6 — The core heuristic of using high copy-degree as a preference signal for DPO is a novel engineering contribution, though the broader framework of using preference optimization for faithfulness may have precedents.\n*   Technical Quality (10): 2 — The technical quality is severely compromised by a major contradiction in reported training data size, potential train-test contamination, and duplicated figures in the analysis (Table 4, Appendix A, Figure 8, Figure 9).\n*   Clarity (10): 5 — While generally well-written, the paper contains critical ambiguities and contradictions regarding the experimental setup that make it difficult to understand what was actually done (Section 4.1.2 vs. Table 4).\n*   Confidence (5): 5 — I am highly confident in my assessment, as the identified issues are based on direct contradictions and evidence found within the manuscript and its appendix.",
  "scores": {
    "baseline": {
      "parsed": {
        "overall": 8,
        "novelty": 9,
        "technical_quality": 8,
        "clarity": 8,
        "confidence": 5
      },
      "max": {
        "overall": 10,
        "novelty": 10,
        "technical_quality": 10,
        "clarity": 10,
        "confidence": 5
      },
      "missing": []
    },
    "refined": {
      "parsed": {
        "overall": 3,
        "novelty": 6,
        "technical_quality": 2,
        "clarity": 5,
        "confidence": 5
      },
      "max": {
        "overall": 10,
        "novelty": 10,
        "technical_quality": 10,
        "clarity": 10,
        "confidence": 5
      },
      "missing": []
    }
  },
  "reviews": "1) Summary\nThis paper addresses the problem of contextual faithfulness in Retrieval-Augmented Generation (RAG), where large language models (LLMs) may hallucinate by ignoring provided context in favor of their internal parametric knowledge. The authors observe an inverse correlation between the degree to which a model copies from the context and its hallucination rate. Based on this, they propose CopyPasteLLM, a two-stage framework. First, three \"CopyPaste-Prompting\" methods are used to generate high-copying responses, which serve as preferred examples. Second, this preference data is used to fine-tune a base LLM using Direct Preference Optimization (DPO), teaching it to favor context-grounded, high-copying outputs. The resulting model shows significant improvements in faithfulness on several benchmarks, notably achieving 12.2%-24.5% higher accuracy on FaithEval with 50x less training data than a strong baseline. A novel analysis method is proposed to reveal the model's knowledge sourcing.2) Strengths\n*   **Novel and Well-Motivated Core Idea**\n    *   The central hypothesis—that a higher degree of copying from the context can serve as a proxy for and a mechanism to improve contextual faithfulness—is intuitive and compelling. This idea is grounded in an empirical observation of an inverse correlation between copying degree and hallucination on the RAGTruth dataset (Figure 1, Section 2.2).\n    *   This approach elegantly connects the problem of faithfulness to the problem of attribution. By design, responses with a high copy degree are inherently attributable to the source context, addressing a key challenge in RAG systems (Section 1, Section 5).\n    *   The formalization of \"copying degree\" using Copy Coverage (κ) and Copy Density (δ) provides a quantifiable and optimizable objective for the proposed methods (Section 2.1, Equation 1).*   **High Reported Performance and Data Efficiency**\n    *   The proposed CopyPasteLLM is reported to achieve state-of-the-art results, significantly outperforming strong baselines on challenging counterfactual benchmarks. On FaithEval, it is claimed to improve accuracy by 12.2 to 24.5 percentage points over the best baseline across three different models (Table 1, Section 4.1.2).\n    *   The method is presented as remarkably data-efficient. The authors report achieving these results using preference data generated from only 365 query-context pairs, which is stated to be 1/50th of the data used by the Context-DPO baseline (Section 4.1.2).\n    *   The performance gains are reported to be consistent across multiple models (Mistral-7B, Llama-3-8B, Llama-3.1-8B) and datasets, including both counterfactual (FaithEval, ConFiQA) and standard QA settings (PubMedQA) (Table 1, Table 3).*   **Comprehensive and Automated Methodological Pipeline**\n    *   The two-stage framework is well-structured. Stage 1 provides a systematic way to generate high-quality preference data through three distinct prompting strategies (CP-Order, CP-Link, CP-Refine) that explore a spectrum from hard to soft constraints (Section 3.1, Figure 2).\n    *   The preference data construction pipeline in Stage 2 is fully automated, incorporating multi-criteria filtering, an LLM-as-judge tournament for ranking, and an \"answer stamping\" technique to create informative preference pairs (Section 3.2, Algorithm 2). This removes the need for expensive human annotation.\n    *   The use of Direct Preference Optimization (DPO) is a suitable and effective choice for internalizing the desired high-copying behavior into the model's policy (Section 3.2, Algorithm 2).*   **Proposes a Novel Method for Mechanistic Analysis**\n    *   The paper proposes the Context-Parameter Copying Capturing algorithm, a tool for token-level analysis of knowledge sourcing during generation (Section 3.3, Algorithm 3).\n    *   This method extends prior work by applying the analysis to the entire Chain-of-Thought reasoning process, rather than just short final answers, which could provide more granular insights (Section 3.3).\n    *   The algorithm is designed to capture and differentiate between contextual and parametric knowledge usage by running generation with and without context and analyzing the top-K tokens, which is a reasonable approach for this type of analysis (Algorithm 3).3) Weaknesses\n*   **Critical Issues in Experimental Reporting and Validity**\n    *   There is a major, unexplained contradiction regarding the training data size. The abstract and main text repeatedly claim training was performed with data derived from \"only 365 training samples\" (Abstract, Section 4.1.2), but Appendix A states that RAGTruth (839 samples), FaithEval (1,000 samples), and PubMedQA (1,000 samples) were all used for training (Table 4). This discrepancy fundamentally undermines the central claim of data efficiency.\n    *   The experimental design suggests potential data contamination. Table 4 in Appendix A indicates that the FaithEval and PubMedQA datasets were used for both \"Train\" and \"Eval\". The manuscript does not state whether disjoint splits were used, raising serious concerns that the model may have been evaluated on data it was trained on, which would invalidate the reported performance metrics.*   **Potential Integrity Issues in Analysis Results**\n    *   The UMAP visualizations presented in the appendix appear to contain duplicated figures, which calls the integrity of the mechanistic analysis into question. The plots for the Mistral-7B-Instruct-v0.2 model are visually identical for the FaithEval dataset (Appendix Figure 8) and the RAGTruth dataset (Appendix Figure 9). It is highly improbable for UMAP projections on two different datasets to be identical, suggesting a reporting error where one result was copied over the other. This undermines the conclusions drawn in Section 4.2 about how the model works.*   **Unclear Scalability and Cost of Preference Generation**\n    *   The preference data generation in Stage 1 relies on multiple LLM calls per sample, especially for the iterative CP-Refine method (Section 3.1, Algorithm 1). The computational cost of this process for generating larger-scale datasets is not discussed.\n    *   The quality of the generated preference data may be highly dependent on the capability of the generator model (DeepSeek-V3-0324, Appendix D). The robustness of the prompting methods across different generator models is not explored.\n    *   The \"50x\" data efficiency claim is ambiguous. The paper compares its \"365 query-context pairs\" to the baseline's \"18,000 samples\" (Section 4.1.2), but the proposed method generates ~5 preference pairs per source sample (Algorithm 2). It is unclear if the baseline's 18,000 samples refers to source pairs or final preference pairs, making the comparison difficult to verify.*   **Potential Negative Trade-offs are Under-explored**\n    *   The strong emphasis on copying might negatively impact other desirable qualities like conciseness, synthesis of information, and linguistic naturalness. The paper lacks a qualitative or human evaluation of the final CopyPasteLLM outputs to assess these potential trade-offs.\n    *   The framework's effectiveness is predicated on the context containing a complete and correct answer. The paper acknowledges this limitation in the appendix (Appendix G), but it is a critical point for real-world RAG applications that deserves more prominent discussion.\n    *   The evaluation metrics for RQ2 (Accuracy and Hit Rate) are primarily focused on correctness in multiple-choice or short-answer settings (Appendix A, Section 4.1.2), which may not fully capture the quality of longer, free-form responses.*   **Ambiguities in the Analysis Methodology**\n    *   The Context-Parameter Copying Capturing algorithm (Algorithm 3) contains several implementation details that lack clarity. For instance, the criterion for identifying \"meaningless tokens\" (line 8) is not defined.\n    *   The logic for categorizing a token as contextual (`x_j in C`) versus parametric (`x_j in A_para`) is presented as mutually exclusive, but common words could appear in both, and the algorithm's handling of this overlap is not specified (Algorithm 3, lines 12-17).\n    *   The \"logits power\" metric is defined late in the appendix (Appendix I, Equation 2) and its mathematical motivation is not explained, making the interpretation of Figure 3 less grounded.4) Suggestions for Improvement\n*   **Clarify Experimental Setup and Ensure Valid Evaluation**\n    *   Please resolve the contradiction regarding the training data size. The manuscript must clearly state the exact origin and composition of the 365 samples and explain how this relates to the datasets listed as \"Train\" in Table 4.\n    *   Please explicitly confirm whether strictly disjoint splits of FaithEval and PubMedQA were used for training and evaluation. If there was overlap, the experiments must be re-run with a clean separation to ensure the validity of the results.*   **Verify and Correct the Mechanistic Analysis**\n    *   Please carefully review and correct the UMAP visualizations in the appendix. The apparent duplication between Figure 8 and Figure 9 for the Mistral-7B model must be addressed. If it is an error, the correct figure should be provided, and the conclusions in Section 4.2 should be revisited based on the corrected results.*   **Discuss Scalability and Refine Efficiency Claims**\n    *   Please add a discussion about the computational cost (e.g., number of API calls, tokens processed per sample) of the Stage 1 preference generation pipeline to help readers assess its practicality.\n    *   Please include a brief ablation or discussion on how the choice of the generator model affects the quality of the preference data and the final performance.\n    *   Please clarify the basis for the \"50x\" data efficiency claim by specifying whether the baseline's \"18,000 samples\" refers to source documents or final preference pairs, ensuring an apples-to-apples comparison.*   **Conduct a More Holistic Evaluation of Trade-offs**\n    *   Please consider adding a small-scale human evaluation comparing outputs from CopyPasteLLM and a baseline on dimensions like naturalness, conciseness, and ability to synthesize information.\n    *   Please move the discussion of key limitations, particularly the assumption of context completeness, from Appendix G into a dedicated \"Limitations\" section in the main paper.\n    *   Consider adding a qualitative analysis with a few examples of generated outputs in the appendix to showcase the model's behavior and illustrate the differences between the CopyPasteLLM and baseline responses.*   **Clarify the Analysis Algorithm and Metrics**\n    *   Please refine the description of Algorithm 3 by explicitly defining what constitutes a \"meaningless token\" (e.g., a list of stop words).\n    *   Please clarify the logic in Algorithm 3 for handling tokens that could be classified as both contextual and parametric.\n    *   Please introduce the \"logits power\" formula (Equation 2) in the main methodology section (e.g., Section 3.3) and include a brief justification for its specific mathematical form.5) Score\n*   Overall (10): 3 — The paper proposes an interesting idea, but critical flaws in experimental reporting, potential data contamination, and apparent duplication of results severely undermine the validity of its central claims (Table 4, Figure 8, Figure 9).\n*   Novelty (10): 6 — The core heuristic of using high copy-degree as a preference signal for DPO is a novel engineering contribution, though the broader framework of using preference optimization for faithfulness may have precedents.\n*   Technical Quality (10): 2 — The technical quality is severely compromised by a major contradiction in reported training data size, potential train-test contamination, and duplicated figures in the analysis (Table 4, Appendix A, Figure 8, Figure 9).\n*   Clarity (10): 5 — While generally well-written, the paper contains critical ambiguities and contradictions regarding the experimental setup that make it difficult to understand what was actually done (Section 4.1.2 vs. Table 4).\n*   Confidence (5): 5 — I am highly confident in my assessment, as the identified issues are based on direct contradictions and evidence found within the manuscript and its appendix."
}