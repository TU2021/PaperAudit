# Global Summary
This paper addresses the problem of contextual faithfulness hallucinations in Retrieval-Augmented Generation (RAG), where Large Language Models (LLMs) may ignore provided context in favor of their internal parametric knowledge. The authors observe an inverse correlation between the degree to which a model copies from the context and the rate of hallucinations. Based on this, they propose CopyPasteLLM, a model trained to prefer high-copying responses. The method is a two-stage pipeline: first, three prompting strategies (CP-Order, CP-Link, CP-Refine) are used to generate candidate responses with a high degree of copying. Second, these high-copying responses are used to create preference data for training a base LLM using Direct Preference Optimization (DPO). The resulting CopyPasteLLM is evaluated on counterfactual (FaithEval, ConFiQA) and standard (PubMedQA) question-answering datasets. The main claim is that CopyPasteLLM achieves state-of-the-art performance with remarkable data efficiency, improving accuracy on the FaithEval benchmark by 12.2% to 24.5% over the best baseline while using only 365 training samples (1/50th of the baseline's data). A novel interpretability tool, Context-Parameter Copying Capturing, suggests that the model's effectiveness stems from recalibrating its confidence in internal parametric knowledge rather than altering its contextual processing capabilities.

# Abstract
The paper tackles the challenge of contextual faithfulness in Retrieval-Augmented Generation (RAG), where LLMs can hallucinate by not trusting the provided context. An inverse correlation between the degree of response copying and context-unfaithful hallucinations is observed on the RAGTruth dataset. This motivates the proposed CopyPasteLLM, which is trained using a two-stage high-copying response preference training pipeline. Three prompting methods are designed to generate high-copying responses, which are then used to create preference data automatically. On the FaithEval, ConFiQA, and PubMedQA datasets, CopyPasteLLM achieves the best performance in both counterfactual and original contexts. Notably, it shows accuracy improvements of 12.2% to 24.5% on FaithEval over the best baseline, using only 365 training samples, which is 1/50th of the baseline's training data. To explain its effectiveness, the paper introduces the Context-Parameter Copying Capturing algorithm. This analysis reveals that CopyPasteLLM recalibrates its reliance on internal parametric knowledge, favoring the external context during generation.

# Introduction
- **Problem:** LLMs used in RAG systems suffer from knowledge conflicts, often favoring their internal parametric knowledge over external context, leading to contextual faithfulness hallucinations. This is a critical issue in knowledge-intensive domains like medical consultations.
- **Existing Solutions & Gaps:** Current approaches include generation with citations and improving faithfulness via prompting, constrained decoding, or fine-tuning. However, citation methods may lack consistency between content and source, while other methods lack explicit attribution.
- **Proposed Solution:** The paper proposes a "copy-paste" generation strategy where the model directly quotes original sentences from the context. This is intended to reduce paraphrasing hallucinations and provide inherent, verifiable attribution.
- **Motivating Observation:** An inverse correlation between copying degree and hallucination density was observed on the RAGTruth dataset (Figure 1), suggesting that high copying can mitigate hallucinations.
- **Method Overview:** The paper introduces CopyPaste, a two-stage pipeline. Stage 1 uses "CopyPaste-Prompting" to generate high-copying responses. Stage 2 uses this data to train "CopyPasteLLM" via Direct Preference Optimization (DPO) to internalize a preference for contextual evidence.
- **Analysis Tool:** A "Context-Parameter Copying Capturing" algorithm is proposed to analyze the model's reliance on contextual versus parametric knowledge during Chain-of-Thought reasoning. The analysis suggests CopyPasteLLM recalibrates confidence in its parametric knowledge.

# Preliminaries
- **Problem Formulation:** The task, termed CopyPaste, is to generate an answer A given a query Q and context C, by maximizing the reuse of lexical units from C. The goal is to optimize a trade-off between faithfulness (copying), query relevance, and fluency.
- **Quantification of Copying:** Two metrics from Grusky et al. (2018) are used to measure the degree of copying:
    - Copy Coverage (κ): The fraction of answer tokens covered by copied fragments.
    - Copy Density (δ): A length-sensitive variant that emphasizes longer copied fragments.
- **Motivating Observation on RAGTruth:** A preliminary analysis on the RAGTruth QA subset (839 questions, 6 models) showed a clear pattern where models with higher copy coverage (κ) and copy density (δ) exhibited lower hallucination density.

# Method
The proposed method is a two-stage pipeline followed by an interpretability analysis.

- **Stage 1: CopyPaste-Prompting:** This stage constructs high-copying responses using three prompting methods:
    - **CP-Order (hard-constraint):** Selects relevant sentences from the context and reorders them to form a coherent answer.
    - **CP-Link (hard-constraint):** Similar to CP-Order, but allows the model to generate short transition sentences to improve fluency.
    - **CP-Refine (soft-constraint):** An iterative writer-reviewer loop where a "writer" model generates an answer and a "reviewer" model provides feedback to increase the copying score until a threshold is met.

- **Stage 2: CopyPasteLLM Training:** This stage internalizes the preference for high-copying responses using DPO.
    - **Candidate Generation:** For each query-context pair, six response types are generated: Base, Attributed, Citations, CP-Order, CP-Link, and CP-Refine.
    - **Preference Data Construction:**
        1.  **Multi-Criteria Filtering:** Candidates are filtered based on contextual faithfulness (AlignScore, MiniCheck), copying strength (κ, δ), query relevance, and fluency.
        2.  **Hallucinations Tournament:** An Elo-style LLM-as-Judge tournament ranks the remaining candidates, specifically diagnosing "Twist" and "Causal" hallucinations.
        3.  **Stamping Answers:** For samples with gold answers, the gold answer is appended to the top-ranked CopyPaste candidate (chosen), and incorrect answers are appended to other CopyPaste candidates (rejected). This creates informative preference pairs.
        4.  **Preference Alignment:** The resulting preference pairs (chosen vs. rejected) are used to fine-tune a base LLM with DPO. The process yields about five preference pairs per sample.

- **Context-Parameter Copying Capturing:** An interpretability algorithm to probe knowledge usage at a token level during Chain-of-Thought generation. It runs generation with and without context, collecting top-K tokens and their hidden states. Tokens from the context are labeled "contextual knowledge," while tokens preferred in the context-free run are labeled "parametric knowledge."

# Experiments
The experiments are structured around three research questions (RQs).

- **RQ1: CopyPaste-Prompting Effectiveness:**
    - **Findings (Table 2):** The CopyPaste-Prompting methods consistently outperform baselines (Attributed, Citations).
    - **CP-Refine** shows the best balance, excelling in hallucination reduction (best in 3/4 models) and contextual faithfulness (+10.9% to +19.1% over baselines) while maintaining fluency.
    - **CP-Order** leads in contextual faithfulness but has poor fluency.
    - A strong correlation between optimal hallucination performance and best contextual faithfulness was observed in 18/24 scenarios (75%).
    - CopyPaste-Prompting methods achieve significantly higher copy coverage and density than baselines (Appendix Figure 5).

- **RQ2: CopyPasteLLM Performance:**
    - **Data Efficiency:** CopyPasteLLM was trained using preference data constructed from only 365 query-context pairs, which is 50x smaller than the 18,000 samples used by the Context-DPO baseline.
    - **Counterfactual Settings (Table 1):** On the FaithEval dataset, CopyPasteLLM surpasses the strongest baselines by 12.6, 12.2, and 24.5 percentage points on Llama-3-8B, Mistral-7B-v0.2, and Llama-3.1-8B, respectively. It achieves a peak accuracy of 92.8% with Llama-3-8B, far exceeding GPT-4o's reported 47.5%.
    - **Non-Counterfactual Settings (Table 3):** On PubMedQA and ConFiQA-QA, it shows modest but consistent improvements (average accuracy gain of 1.01%). On the more difficult ConFiQA-MR and ConFiQA-MC subsets, it improves average accuracy from 84.49% to 94.37%, with a notable 20.67% improvement on Mistral-7B-v0.2 for the MR subset.

- **RQ3: Interpretable Analysis of CopyPasteLLM:**
    - **Logits Analysis (Figure 3):** Using the Context-Parameter Copying Capturing algorithm, the analysis shows that CopyPasteLLM exhibits significantly stronger and earlier utilization of contextual knowledge and reduced reliance on parametric knowledge compared to the base model.
    - **Hidden States Analysis (Figure 4):** UMAP visualizations of hidden states show that:
        - CopyPasteLLM creates a clearer separation between contextual and parametric knowledge representations compared to the base model.
        - The contextual knowledge representations in CopyPasteLLM are nearly co-distributed with those in the base model.
        - The parametric knowledge representations differ substantially between CopyPasteLLM and the base model.
    - **Conclusion:** The authors infer that CopyPasteLLM works by recalibrating the model's confidence in its internal parametric knowledge, effectively suppressing it, rather than by enhancing its contextual processing abilities.

# Related Work
- **Problem Context:** The paper situates its work within the challenge of ensuring contextual faithfulness in RAG, where LLMs often favor their pretrained parametric knowledge.
- **Existing Research Areas:**
    - **Evaluation:** Studies that construct synthetic scenarios to show LLMs' preference for internal knowledge.
    - **Mechanistic Analysis:** Work identifying model components (attention heads, FFNs) responsible for processing internal vs. external knowledge.
    - **Solutions:** The paper reviews solutions like generation with citations, prompt engineering, decoding methods, and fine-tuning.
- **Contribution:** The copy-paste strategy is presented as a novel approach that simultaneously enhances faithfulness through lexical reuse and provides inherent attribution, which is then internalized into the model's behavior via preference optimization.

# Conclusion
The paper proposes CopyPasteLLM, a two-stage framework to mitigate RAG hallucinations by promoting and internalizing high-copying behavior. This approach is motivated by an observed inverse correlation between copying degree and hallucination. CopyPasteLLM is highly data-efficient, achieving 12.2%-24.5% accuracy improvements on FaithEval with only 365 training samples (50x fewer than baselines). The proposed Context-Parameter Copying Capturing analysis suggests the model's effectiveness comes from recalibrating its confidence in parametric knowledge. The copy-paste paradigm is presented as a solution for both faithfulness and attribution in RAG.

# Appendix
- **Ethics & Reproducibility:** The authors acknowledge the risk of copying biased or incorrect source material and state their commitment to reproducibility by providing experimental details, using public datasets (RAGTruth, FaithEval, PubMedQA, ConFiQA), documenting hyperparameters, and releasing code and prompts.
- **Experimental Setup:**
    - **Datasets:** RAGTruth (839 samples for training), FaithEval (1,000 samples), PubMedQA (1,000 samples), ConFiQA (36,000 samples).
    - **Metrics:** AlignScore, MiniCheck, LLM-as-Judge for RQ1; Hit Rate and Accuracy for RQ2.
    - **Models:** Base models include Mistral-7B-v0.2, Llama-3-8B, Llama-3.1-8B, Qwen2.5-72B, and DeepSeek-V3.
    - **Baselines:** Stage 1 (Attributed, Citations), Stage 2 (Context-DPO, Canoe, ParamMute, CoCoLex).
- **Algorithms:** Formal algorithms are provided for CopyPaste-Prompting (Alg 1), CopyPasteLLM training (Alg 2), Context-Parameter Copying Capturing (Alg 3), and Copy Fragment Detection (Alg 4).
- **Implementation Details:** Fine-tuning is done with DPO and LoRA (r=64, α=128). The optimizer is AdamW (lr 5e-5), with a cosine schedule and DPO temperature β=0.3. Training lasts for 1-2 epochs.
- **Limitations:** The paper notes limitations including scenarios with incomplete context, the need for a deeper mechanistic understanding (e.g., analyzing specific attention heads/FFNs), and the potential extension to multimodal contexts.
- **Prompts:** All prompts used for CopyPaste-Prompting, baselines, and LLM-as-Judge evaluations are provided.

# References
The manuscript includes a comprehensive list of references to related work in RAG, LLM hallucinations, faithfulness evaluation, and mitigation techniques.