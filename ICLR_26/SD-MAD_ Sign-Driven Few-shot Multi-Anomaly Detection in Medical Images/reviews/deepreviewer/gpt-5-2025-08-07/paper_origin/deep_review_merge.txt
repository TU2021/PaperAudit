Summary
The paper introduces SD-MAD, a sign-driven, few-shot framework for multi-anomaly detection in medical imaging built on CLIP/MedCLIP. The method fine-tunes selected transformer layers with a lightweight residual “Shift Adapter” and trains with an anchor-based inter-anomaly loss that uses a “normal” prompt as an anchor to enlarge margins both between normal vs. anomaly and among multiple anomaly categories. At inference, an automatic sign-selection step aims to filter out outlier or ambiguous textual prompts to reduce intra-class uncertainty. The authors propose evaluation protocols tailored to realistic clinical scenarios: general anomaly detection at image- and pixel-level, multi-label prediction (Hamming score and subset accuracy), and category-wise AUROC. Experiments on BMAD datasets (general AD) and fastMRI+ brain MRI slices (multi-anomaly) report improvements over CLIP, MedCLIP, and other few-shot baselines, with qualitative visualizations highlighting prompt ambiguity and an ablation indicating robustness to the adapter’s weighting.

Strengths
- Addresses a clinically relevant and under-explored setting: few-shot, multi-anomaly, multi-label detection where multiple findings can co-exist in a single image.
- Practical, efficient fine-tuning via adapters that preserve CLIP/MedCLIP priors while enabling targeted adaptation to medical anomalies.
- Anchor-based inter-anomaly loss explicitly promotes separation among categories and reduces false positives from irrelevant anomalies, aligning well with the task’s requirements.
- Introduces evaluation protocols that reflect multi-label clinical decision-making, including Hamming score, subset accuracy, and category-wise AUROC, in addition to general AD metrics.
- Demonstrates consistent gains on fastMRI+ multi-anomaly tasks and competitive performance on BMAD general AD, with per-category improvements and informative qualitative analyses.
- Clear overall structure with helpful pipeline figures and result tables; visualizations effectively motivate the need for sign selection; ablation suggests the method is not overly sensitive to at least one key hyperparameter.

Weaknesses
- The sign-generation pipeline is insufficiently specified: no details on the language model(s) used, prompt templates, number of signs per category, expert curation or validation, and standardization across datasets; raises concerns about prompt quality, overlap, and noise.
- The core inference-time sign-selection mechanism is not operationally defined: key quantities and decision regions are introduced but not concretely computed; no algorithm, metrics, thresholds, or sensitivity analysis are provided, limiting reproducibility and interpretability.
- Pixel-level adaptation via integration with MVFA is under-described: how losses are combined, weights chosen, and pixel-level maps derived from text–image similarities are not specified, weakening methodological rigor.
- Missing training details hinder reproducibility: optimizer, learning rate, batch size, temperature, default adapter weighting, and other hyperparameters are not reported.
- Decision rules and calibration for multi-label predictions are unclear, leading to surprising results (e.g., near-zero subset accuracy for some baselines and a perfect category AUROC) without context on class prevalence, thresholds, or confidence intervals.
- Experimental scope is narrow: multi-anomaly evaluation is limited to brain MRI slices and primarily 1-shot; there is no shot-scaling analysis, cross-organ/modalities validation, cross-dataset generalization, or statistical significance testing.
- The anchor-based prediction may depend on dataset-specific assumptions about the “normal” boundary; sensitivity to the choice of normal prompt(s), alternative anchors, or multiple anchor formulations is not examined.
- The approach to ambiguous prompts relies on hard filtering, which may discard useful shared information; alternative strategies such as soft weighting or modeling shared prompts are not explored.
- Minor presentation issues (e.g., duplicated references, notation inconsistencies) detract from clarity.
