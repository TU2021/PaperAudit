### Summary

The paper presents **ECO** (Enhanced Code Optimization), a performance-aware prompting framework designed to improve **Large Language Models (LLMs)** for generating **optimized code**. It addresses key challenges in code optimization by distilling **runtime optimization instructions (ROIs)** from slow-fast code pairs, enabling the model to understand the reasoning behind performance gains. ECO works by combining two complementary components: a **symbolic advisor** that provides deterministic bottleneck diagnoses, and an **ROI retriever** that retrieves relevant optimization rationales. These components generate **performance-aware prompts** that can guide any LLM to produce efficient code without requiring fine-tuning. Empirical results show that ECO achieves speedups of up to **7.81¡Á**, significantly improving code generation efficiency while maintaining correctness. The method is shown to outperform other baseline methods like instruction-only prompting and **retrieval-augmented generation (RAG)**.

---

### Strengths

* **Novel approach to code optimization**
  ECO addresses a critical issue in existing code optimization methods¡ª**superficial pattern imitation**¡ªby focusing on **why optimizations work**, rather than just applying pattern-based code transformations. This enables LLMs to improve both **accuracy** and **performance reasoning** (kEGt, 5KXa).

* **Effective dual-module design**
  The **symbolic advisor** (providing deterministic bottleneck detection) and the **ROI retriever** (offering contextual optimization guidance) create a **complementary design**. Reviewers appreciated that both modules work together to balance **precision** (via the symbolic advisor) and **flexibility** (via the ROI retriever) (kEGt, 5KXa).

* **Model-agnostic and practical for deployment**
  ECO¡¯s **model-agnostic** design makes it easily deployable across a range of **open-source and closed-source LLMs**. The absence of the need for **fine-tuning** ensures it is a practical solution for real-world applications (5KXa, z5NH).

* **Strong empirical results**
  ECO outperforms several baselines, achieving impressive **speedups** (up to 7.81¡Á) while maintaining **high accuracy**. This is seen as a significant improvement over existing optimization methods (z5NH, kEGt).

* **Cross-language scalability**
  ECO demonstrates its ability to scale beyond C++ by successfully applying the ROI retriever to **Python benchmarks** (PIE-Python), showing that ECO can adapt to multiple programming languages with minimal effort (z5NH, 5KXa).

* **Proven robustness and reliability**
  The internal analysis and experiments show that the components of ECO, particularly the **ROI distillation process**, are **reliable** and **effective** in optimizing code. The framework also adapts well to **beam search**, providing additional improvements when combined with multi-step refinement (5KXa, kEGt).

---

### Weaknesses

* **Lack of comparison with recent and stronger baselines**
  Several reviewers expressed concerns about the choice of baselines, noting that many of the **comparison methods** (e.g., Supersonic, SBLLM) are outdated and fail to reflect recent advances in code optimization. Some felt the comparison with these **weak baselines** may not fully validate the method¡¯s strengths (5KXa, z5NH).

* **Limited diversity in evaluation datasets**
  The evaluation was primarily conducted on **C++ benchmarks** (PIE), and concerns were raised about the **lack of diversity** in the test cases, particularly for more **complex algorithmic problems**. Reviewers suggested that incorporating more **complex and diverse benchmarks** would make the results more compelling (5KXa, z5NH).

* **Manual effort in rule and ROI curation**
  The symbolic advisor relies on **manually curated rules** for identifying bottlenecks, which raises concerns about the **scalability** of ECO, particularly when adapting to new languages or types of inefficiencies. The paper does not adequately address how to **automate this process** (5KXa).

* **Unclear comparison to compiler-driven optimization**
  ECO is presented as a complement to **compiler optimizations** (e.g., GCC¡¯s -O3 flag), but it was not compared explicitly against these methods. Reviewers were unsure whether ECO's optimizations (e.g., replacing cin with scanf, loop invariant hoisting) overlap with or improve upon those achieved by compilers (5KXa, z5NH).

* **ROI distillation reliability concerns**
  The process of distilling **ROIs** using an LLM-as-judge was flagged for its **reliability**. Reviewers questioned whether the distilled ROIs ever misidentify the **root causes of inefficiencies** (e.g., misattributing a performance issue to a loop instead of a data structure). They were also concerned about the **propagation of errors** from inaccurate ROIs to ECO's overall performance (z5NH, kEGt).

* **Limited exploration of scalability and smaller models**
  ECO¡¯s performance on **smaller models** (e.g., 3B parameters) was not explored in depth. Reviewers suggested testing **simplified prompt variants** or **smaller ROIs** to improve **efficiency** without sacrificing performance on smaller models. This would help expand ECO's applicability (z5NH).

* **Lack of exploration into agent composition strategies**
  While the paper discusses the idea of **agent composition** (composing agents with complementary strengths), reviewers felt the paper did not **fully explore** how to implement these **orchestration strategies** or identify when composition would be most effective (5KXa).


