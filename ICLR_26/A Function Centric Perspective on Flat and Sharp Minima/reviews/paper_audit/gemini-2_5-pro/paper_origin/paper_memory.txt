# Global Summary
This paper challenges the conventional wisdom that flatter minima in the loss landscape of neural networks lead to better generalization. The authors propose a "function-centric" perspective, arguing that the geometry of a solution (its sharpness or flatness) is primarily a reflection of the complexity of the learned function, rather than a direct indicator of performance. Through extensive empirical studies on single-objective optimization problems and modern image classification tasks (CIFAR-10, CIFAR-100, TinyImageNet with ResNet, VGG, ViT), the paper demonstrates that common regularization techniques like SAM, weight decay, and data augmentation often lead to *sharper* minima. Crucially, these sharper, regularized models frequently outperform their flatter, unregularized counterparts not only in generalization but also in safety-critical metrics like calibration (ECE), robustness to corruptions, and functional consistency. The authors reconcile the behavior of SAM, originally motivated to find flat minima, by arguing it promotes local robustness, which can coincide with increased global sharpness. The core conclusion is that sharpness is not inherently detrimental; it can be a signature of a well-regularized model that has learned a more complex and appropriate function for the task.

# Abstract
The paper revisits the connection between flat minima and generalization in deep neural networks, proposing that sharpness is a function-dependent property, not a universal indicator of poor performance. Empirical studies, ranging from single-objective optimization to image classification, show that regularized models (using SAM, weight decay, or data augmentation) often converge to sharper minima. These sharper minima can coincide with better generalization, calibration, robustness, and functional consistency. In contrast, unregularized baselines tend to find flatter minima but perform worse across these metrics. The findings suggest that function complexity, influenced by inductive biases from regularization, governs solution geometry, calling for a "function-centric" reappraisal of the loss landscape.

# Introduction
- The paper challenges the prevailing view that flat minima are desirable for generalization, as supported by prior work (Li et al., 2018; Foret et al., 2021). It acknowledges counterarguments, such as Dinh et al. (2017) showing sharpness can be manipulated via reparameterization.
- It extends the investigation beyond generalization to safety-critical properties like adversarial robustness, calibration, and functional diversity, whose relationship with flatness is underexplored.
- The central hypothesis is a "function-centric" view: a solution's geometry reflects the learned function's complexity, not its quality. Sharper minima might represent more expressive or better-regularized solutions.
- The empirical investigation starts with single-objective optimization problems (e.g., Sphere, Rosenbrock) to show that global minima can be intrinsically sharp or flat depending on the function's complexity.
- It then scales to deep learning with ResNet, VGG, and ViT on CIFAR and TinyImageNet, comparing baseline models to those with SAM, weight decay, and data augmentation.
- Key findings summarized:
    1.  Regularized models often converge to sharper minima yet achieve better generalization and safety metrics.
    2.  SAM's benefits frequently arise despite increasing sharpness.
    3.  There is no universal "Goldilocks zone" for sharpness; it depends on the function, architecture, and inductive biases.
- Figure 1 shows scatter plots for 240 ResNet-18 runs on CIFAR-10, visually demonstrating that regularized models (e.g., with augmentation) cluster at higher sharpness values (Fisher-Rao Norm, Relative Flatness) and lower generalization gaps compared to the baseline.

# Related Work
- The historical basis for preferring flat minima is cited, starting with Hochreiter & Schmidhuber (1997) and later reaffirmed by Li et al. (2018) with landscape visualization.
- Sharpness-Aware Minimization (SAM) (Foret et al., 2021) is mentioned as an optimizer explicitly designed to find flatter minima, though some work has challenged this interpretation (Wen et al., 2023).
- The fundamental challenge to sharpness as an intrinsic property by Dinh et al. (2017) is noted, which showed it can be arbitrarily increased via reparameterization. This led to the development of reparameterization-invariant metrics (Petzka et al., 2021).
- The paper positions itself as revisiting this topic from a function-centric perspective, arguing that regularization enables learning more complex functions that may reside in sharper minima, contrary to the conventional view.

# Method
- **Sharpness Metrics:** The study uses three established metrics:
    - Fisher-Rao Norm (Liang et al., 2019)
    - Relative Flatness (Petzka et al., 2021)
    - Average-case SAM-Sharpness (Foret et al., 2021)
- **Calibration:** Measured using Expected Calibration Error (ECE), where lower values are better.
- **Functional Diversity:** Measured by prediction disagreement on the test set. Lower disagreement (higher functional similarity) is interpreted as a desirable property reflecting stability.
- **Robustness:** Assessed using mean corruption accuracy on CIFAR10-C and CIFAR100-C datasets. Higher accuracy indicates greater robustness.
- The paper argues these metrics provide a broader view of model quality beyond standard accuracy.

# Experiments
- **Single-Objective Optimisation:**
    - Himmelblau's function is used as an example with four global minima, each having different local geometry (e.g., max eigenvalue ranging from 80.550 to 133.786), demonstrating that optimality does not imply a specific geometry.
    - Six other functions are analyzed (Sphere, Rosenbrock, etc.). Their global minima have inherently different sharpness. For example, the Sphere function is flattest (Hessian trace 4.0), while Rosenbrock is sharpest (Hessian trace 1002.0).
    - An MLP trained on these functions converges to minima whose sharpness reflects the target function's complexity, suggesting that seeking flatness is only optimal for intrinsically flat functions.

- **High-Dimensional Optimisation Problems:**
    - **Setup:** Experiments use ResNet, VGG, and ViT on CIFAR-10, CIFAR-100, and TinyImageNet. Six training conditions (`controls`) are compared: Baseline, Baseline+SAM, Augmentation, Augmentation+SAM, Weight Decay, Weight Decay+SAM. All experiments use 10 matched seeds with identical initialization and data order.
    - **Hypothesis:** Regularization increases sharpness while improving performance on accuracy and safety metrics.
    - **Results for ResNet18 on CIFAR10 (Table 3):**
        - The `Baseline` model is the flattest (Fisher-Rao Norm: 0.032, SAM Sharpness: 1.366E-05, Relative Flatness: 34.607) but has the worst performance (Test Acc: 0.720, ECE: 0.186, Corruption Acc: 58.614).
        - `Augmentation + SAM` is the best performing model (Test Acc: 0.908, ECE: 0.014, Corruption Acc: 71.419) but is also the sharpest on two metrics (Fisher-Rao Norm: 5.571, Relative Flatness: 4970.972).
    - **Results for ResNet18 on CIFAR100 (Table 5):**
        - A similar trend holds. `Baseline` is flattest and worst. `Augmentation + SAM` is best on most metrics and is very sharp (e.g., Fisher-Rao Norm of 4.179 vs. 0.294 for baseline).
    - **Results for ResNet18 on TinyImageNet (Table 7):**
        - `Augmentation + SAM` is again a top performer and is significantly sharper (Fisher-Rao Norm: 25.193) than the baseline (0.479).
    - **Key Claims:**
        - Regularizers consistently increase sharpness and improve performance.
        - Low-dimensional loss landscape visualizations can be misleading and appear broader even when quantitative sharpness metrics increase.
        - SAM does not always flatten the minima; it often increases sharpness across multiple metrics. This is reconciled by viewing SAM as promoting *local* robustness, not necessarily *global* flatness.
        - Better safety properties (calibration, robustness) are consistently found at sharper minima than the unregularized baseline.
        - There is no "Goldilocks zone" for sharpness; the appropriate level is task- and architecture-dependent.

# Conclusion
The paper concludes by reiterating its function-centric view of loss landscape geometry. The empirical results show that standard regularization techniques (weight decay, data augmentation, SAM) often produce sharper minima that exhibit superior performance in generalization, calibration, robustness, and functional consistency. This challenges the "flatter is better" heuristic. The authors explain SAM's effectiveness through its promotion of local robustness, which can lead to globally sharper solutions. The work suggests that sharpness can be a beneficial trait, potentially reflecting the learning of more complex functions with tighter decision boundaries required by the task, and calls for a re-evaluation of geometric intuitions in deep learning.

# Appendix
- **A:** Provides definitions for the seven single-objective optimization functions. Details the MLP training setup (3-layer ReLU, Adam optimizer, 10k data points). Includes experiments showing that even when models are trained to the same target loss, their sharpness differs according to the intrinsic complexity of the function they are fitting.
- **B:** Provides details on the sharpness metrics. Fisher-Rao Norm is calculated using an analytical formula. SAM-sharpness is averaged over 100 perturbations at a distance of ρ=0.005. Relative Flatness is noted as computationally expensive.
- **C:** Provides details on the safety-critical metrics, including the use of TorchMetrics for ECE.
- **D:** Details the experimental settings for the deep learning models, including hyperparameters (e.g., SGD, 100 epochs, batch size 256, SAM ρ=0.05, WD=5e-4), architectures, and datasets. Notes that for CIFAR100 and TinyImageNet, sharpness was calculated on a subset (20%) of the training data for some metrics due to computational cost. Relative Flatness was not computed for TinyImageNet due to memory constraints.
- **E:** Presents a hyperparameter sweep for SAM's ρ on ResNet-18/CIFAR-10. It shows that a larger ρ leads to sharper minima. The best performance was achieved with ρ=0.25, which was significantly sharper than the baseline or the standard ρ=0.05 setting.
- **F, G, H:** Provide extensive additional results for ResNet-18, VGG-19, and Vision Transformer (ViT) respectively.
    - These sections include hyperparameter sweeps for batch size (128, 256) and learning rate (1e-3, 1e-2), confirming that the main finding (regularization leads to sharper, better models) holds across different settings.
    - They also validate that calculating sharpness on augmented vs. standard training data yields similar trends.
    - The results for VGG and ViT on CIFAR-10, CIFAR-100, and TinyImageNet (for VGG) are consistent with the ResNet findings presented in the main paper.

# References
This section lists the bibliographic references cited throughout the manuscript.