# Innovation & Motivation Report

## 1. The Authors' Claimed Contribution
- Core Problem: The paper targets the limitations of current mobile GUI agents built on multimodal LLMs that are passive (reactive to explicit instructions) and ignore user-related context (profile, history, time, location), which constrains proactive intent anticipation and personalization.
- Claimed Gap: “Current mobile GUI agents are passive and instruction-bound; users may have latent or poorly specified needs. Agents also ignore user context (profile, time/location, long-term histories), missing personalization.” The Related Work further emphasizes: “Prior datasets lack user context and do not study proactive suggestion without an initial instruction.”
- Proposed Solution: FingerTip 20K, a user-oriented benchmark with two tracks: (i) proactive task suggestion from user/context signals (profile, time, scenario, historical intents, optionally initial screenshots); (ii) personalized task execution that imitates user-specific action preferences based on historical action traces, with standardized action space, longitudinal real-world data, and multi-metric evaluation (success, similarity/alignment, efficiency, cost). The paper also demonstrates fine-tuning of a 7B model on user-oriented data to improve both proactivity and personalization.

## 2. Comparative Scrutiny (The "Trial")
Here, we analyze how the paper stands against the identified similar works.

### vs. FingerTip 20K: A Benchmark for Proactive and Personalized Mobile LLM Agents
- Identified Overlap: Identical title and authors; the abstract describes the same benchmark vision and two tracks (proactive suggestion and personalized execution) with user-contextual, longitudinal mobile interactions and fine-tuning evidence.
- Manuscript's Defense: This appears to be the same work (a prior abstract/preprint description of the benchmark). The manuscript is the fully specified, data- and metric-rich instantiation of that vision, with detailed formalizations, dataset statistics, splits, standardized action space, execution on-device via ADB, and quantitative results across baselines and fine-tuning.
- Reviewer's Assessment: Not a separate prior art undermining novelty; rather, this is the comprehensive version of the same benchmark. No contradiction with the claimed gap or solution. However, from a publication perspective, editors should ensure versioning and avoid duplicate publication.

### vs. AMEX: Android Multi-annotation Expo Dataset for Mobile GUI Agents
- Identified Overlap: Both provide large-scale datasets for generalist mobile GUI-control agents grounded in screenshots and action chains; both fine-tune baseline agents and evaluate execution success.
- Manuscript's Defense: The paper explicitly contrasts FingerTip with AMEX and others in Table 1: AMEX includes UI trees/screens and stepwise actions but “no profile/context” and focuses on “execution only,” whereas “FingerTip … includes profile and context; proactive suggestion and personalized execution.” Related Work asserts: “Prior datasets lack user context and do not study proactive suggestion without an initial instruction.”
- Reviewer's Assessment: The distinction is significant. FingerTip introduces two user-centric capabilities—proactivity without an initial instruction and personalization via user histories—that AMEX does not cover. This addresses the stated gap credibly and with concrete task definitions and metrics.

### vs. A3: Android Agent Arena for Mobile GUI Agents
- Identified Overlap: Both evaluate agents in-the-wild on real Android tasks with standardized action abstractions and automated LLM-based outcome judging; both aim for cross-agent comparability.
- Manuscript's Defense: The paper situates A3 within Related Work (Table 1 lists benchmarks such as A3) and notes that existing datasets/benchmarks focus on “execution only” and lack user context. It further claims: “Prior systems remain reactive and ignore user preferences; some clarify ambiguous instructions but still require initial prompts.”
- Reviewer's Assessment: FingerTip extends the evaluation paradigm with two new tracks centered on user context and proactivity. Relative to A3, the new intent-suggestion task and personalization alignment metric (Sim2) are meaningful expansions beyond execution-only benchmarking.

### vs. AutoDroid: LLM-powered Task Automation in Android
- Identified Overlap: Both adopt a model-centric approach to Android automation, bridging UI to LLMs and augmenting models with external knowledge; both execute stepwise actions and measure success/efficiency.
- Manuscript's Defense: The Related Work characterizes prior agents broadly: “Prior systems remain reactive and ignore user preferences; some clarify ambiguous instructions but still require initial prompts.” AutoDroid is not explicitly cited in the provided references summary, but it fits this category of instruction-driven automation without user personalization or proactive intent inference from user context.
- Reviewer's Assessment: FingerTip’s contribution is orthogonal and complementary: it defines upstream proactivity (predicting intent without instruction) and user-specific execution alignment. This is a valid and substantial distinction from AutoDroid’s app-domain knowledge augmentation and instruction-conditioned execution.

### vs. GUI-World: A Video Benchmark and Dataset for Multimodal GUI-oriented Understanding
- Identified Overlap: Both argue that agents must handle dynamic, multi-step GUI contexts and benefit from temporal information and operation histories; both compare generalist vs fine-tuned models.
- Manuscript's Defense: While GUI-World focuses on GUI understanding across desktop/web and video modalities, FingerTip targets mobile control with user-oriented signals and execution on real devices. The FingerTip dataset includes per-step screenshots and histories (I_history, A_history), aligning with GUI-World’s call for temporal grounding, but adds user profile/time/scenario and personalized execution—capabilities not present in GUI-World.
- Reviewer's Assessment: Overlap is thematic (temporal/sequential grounding), but the novelty here is the user-centered mobile benchmark with proactivity and personalization. This is a distinct contribution that addresses a different, user-context gap.

### vs. Large Language Model-Brained GUI Agents: A Survey
- Identified Overlap: The survey outlines frameworks, datasets, action models, and evaluation needs for GUI agents; FingerTip operationalizes these foundations in the mobile domain.
- Manuscript's Defense: The paper claims to fill a gap the survey highlights: the need for richer data and evaluation for real-world effectiveness, adding explicit user context and proactivity to the mobile GUI agent paradigm.
- Reviewer's Assessment: As a survey, this does not diminish FingerTip’s novelty; rather, FingerTip concretely advances the surveyed agenda with new tasks and data.

### vs. SecComp, Ripple, Android Anti-forensics, TEE-based Features, WMT Translation Suggestion, ADAPT (IWPT), Shesop Healthcare, AiDroid
- Identified Overlap: These works are tangential—security defenses, static analysis, OS anti-forensics, hardware security utilization, shared-task suggestion in MT, dependency parsing, a specific health app, and malware detection.
- Manuscript's Defense: Not directly cited, and not central to mobile GUI agent proactivity/personalization. The paper does acknowledge privacy and deployment constraints in Appendix (on-device processing, differential privacy), which is relevant to the OS/security ecosystem.
- Reviewer's Assessment: These do not materially weaken the motivation. The core comparisons for novelty are with mobile GUI agent datasets/benchmarks and automation systems; on that axis, FingerTip’s differentiation is preserved.

## 3. Novelty Verdict
- Innovation Type: Application-Oriented (benchmark/dataset and task framing), with a substantive expansion in evaluation scope via user-context-driven proactivity and personalization.
- Assessment:
  The paper’s motivation is well-supported by explicit contrasts to existing datasets and systems: prior benchmarks focus on execution-only with no user profiles or contextual signals, and prior agents are instruction-bound and reactive. FingerTip credibly introduces two underexplored capabilities—proactive intent suggestion without initial instructions and user-aligned execution—grounded in longitudinal, real-world data. Empirical findings (low SR1/SR2 for generalists, improved performance via fine-tuning) substantiate that the proposed tasks expose real headroom and that user-oriented data are valuable.
  - Strength:
    • Clear, evidence-backed gap: “Prior datasets lack user context and do not study proactive suggestion without an initial instruction,” and “Prior systems remain reactive and ignore user preferences.”
    • Concrete, user-centered task definitions and formalizations for proactivity and personalization; comprehensive dataset collected from real devices over time.
    • Multi-metric evaluation including success, alignment (Sim2), efficiency (step ratio), and cost, plus ablations on screenshots and sequence length; fine-tuning results show substantial gains, supporting the motivation.
  - Weakness:
    • Personalization effect appears modest overall (Sim2 ≈ 1 for many models), raising questions about how strongly current agents can exploit user histories; the paper could further isolate the contribution of each user-context signal (profile, time, scenario vs histories) via ablations.
    • Domain bias (all users from mainland China) may limit generalizability of the benchmark and the claimed user-context benefits across global app ecosystems.
    • The proactive suggestion success rates are low across models; while this demonstrates task difficulty, the practical utility depends on future model improvements—the paper could strengthen motivation by deeper error analysis linking failures to specific missing context cues.

## 4. Key Evidence Anchors
- Introduction: “Current mobile GUI agents are passive and instruction-bound; users may have latent or poorly specified needs. Agents also ignore user context (profile, time/location, long-term histories), missing personalization.”
- Related Work: “Prior datasets lack user context and do not study proactive suggestion without an initial instruction.” Table 1 contrasts AMEX, AndroidLab, AitW, SPA-Bench, A3 vs FingerTip, highlighting that FingerTip “includes profile and context; proactive suggestion and personalized execution.”
- Preliminaries: Formalization of Track 1 (I = f(U, T, S, I_history, O)) and Track 2 next-action generation (A_{t+1}, O_{t+1}, AT_{t+1} = f(U, I_true, A_history, A_agent, O_t, AT_t)), establishing the proactive and personalized modeling objectives.
- Experiments:
  • 5.2 Overall Performance: Low SR1 for generalists (≤7.2%) and SR2 markedly higher for GUI-specific models vs generalists; Sim2 ≈ 1 indicates limited personalization—justifying the benchmark’s challenge and headroom.
  • 5.3 Effect of task difficulty: More initial screenshots improve SR1; longer sequences reduce SR2—empirically grounding the proactive and sequential control challenges.
  • 5.4 Effect of fine-tuning: LoRA fine-tuning of Qwen-2.5-VL-7B yields substantial gains (SR1 from 3.1→9.7; Sim1 0.25→0.49; SR2 1.5→12.5; Sim2 0.95→1.21; step ratio improved), demonstrating that user-oriented data enables agents to better leverage context—supporting the central motivation.