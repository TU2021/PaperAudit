Based on a critical review of the manuscript, several clear internal inconsistencies and missing details have been identified that materially affect the paper’s correctness and trustworthiness.

### **Integrity and Consistency Report**

**1. Contradiction Regarding Scaling with Model Size**

There is a direct contradiction between the textual claims in the Limitations section and the data presented in Figure 7 regarding uncertainty scaling with model size.

*   **Claim:** The Limitations section (Block 36) explicitly states: "Previous works on scaling laws for deep learning show clear trends of test performance with respect to model parameters; however, with our experimental setup, **we did not observe the same for predictive uncertainties (see Fig. 7)**".
*   **Evidence:** Figure 7 (Block 30, right-hand side plots) clearly shows trends for predictive uncertainties as a function of model size (P). For all tested data subset sizes (N), Total Uncertainty (TU) and Aleatoric Uncertainty (AU) show a consistent *increasing* trend with model size, while Epistemic Uncertainty (EU) shows a consistent *decreasing* trend.
*   **Inconsistency:** The claim that no trends were observed is factually incorrect according to the data presented in the figure cited to support this very claim. The manuscript presents clear trends but dismisses them in the text as non-existent. This is a significant internal contradiction.

**2. Unsubstantiated Key Result in Introductory Figure**

A prominent result presented in the introductory figure (Figure 1) for the "Deep Ensembles" method is not substantiated anywhere in the main experimental section or the appendix.

*   **Claim:** Figure 1 (Block 3, Block 4) claims that for a ResNet-18 on CIFAR-10, Deep Ensembles exhibit an Epistemic Uncertainty scaling with a coefficient of **γ = -0.80**. This is the steepest and most compelling scaling law shown in the introductory figure.
*   **Evidence:**
    *   Section 4.1.1 and Figure 2 (Block 14, Block 19) report Deep Ensemble results for **WideResNet** architectures, not ResNet-18, with different scaling coefficients (γ_EU is -0.61 or -0.56).
    *   Appendix B and Figure 13 (Block 55, Block 56) report Deep Ensemble results for ResNet architectures, but on the **CIFAR-100** dataset, not CIFAR-10. The reported coefficients (e.g., γ_EU = -0.47 for ResNet-18) do not match the value in Figure 1.
*   **Inconsistency:** There is no experiment reported in the manuscript that corresponds to the setup (ResNet-18 on CIFAR-10) and produces the result (γ = -0.80) claimed for Deep Ensembles in Figure 1. The evidence for one of the paper's primary motivating examples is missing.

**3. Misleading Presentation of MCMC Results**

Another key result from the introductory Figure 1, for the MCMC method, is not discussed in the main experimental section, which is misleading.

*   **Claim:** Figure 1 (Block 3, Block 4) presents a result for "MCMC" on ResNet-18/CIFAR-10, showing an Epistemic Uncertainty scaling of **γ = -0.44**.
*   **Evidence:** The main experimental section discusses MCMC results only for the ImageNet-32 dataset (Section 4.1.1, Block 17, referring to Figure 8). The CIFAR-10 MCMC experiment that produced the γ = -0.44 result is found only in the appendix, in Figure 14 (Block 57, Block 60), specifically for the "ResNet-18 (First+Second) - ID" setup where γ_EU = -0.44.
*   **Inconsistency:** A result featured prominently in the paper's introduction is absent from the main experimental narrative and relegated to the appendix without mention in the main text. This disconnect between the introduction and the experimental section weakens the paper's narrative structure and transparency.

**4. Inconsistent Reporting of Experimental Procedures**

The description of how results from multiple experimental runs are aggregated and visualized is inconsistent.

*   **Claim:** The caption for Figure 2(a) (Block 14) states, "each point × corresponds to the average over 10 independent folds".
*   **Evidence:**
    *   The plots in Figure 2(a) (visible in Block 4) use circular markers, not '×' markers.
    *   In contrast, Figure 10 in the appendix (Block 48, Block 49), which also reports results averaged over 10 folds, uses a different visualization scheme: it shows faint lines for each of the 10 individual runs and a bold '×' marker for the average.
*   **Inconsistency:** The inconsistent visualization and description make it ambiguous whether Figure 2(a) is showing the average of 10 runs as claimed, or a single representative run. This lack of clarity affects the interpretation of the results' robustness.

### **Conclusion**

The manuscript contains significant internal inconsistencies. The direct contradiction regarding model size scaling (Point 1) and the missing evidence for a key introductory claim (Point 2) are major flaws that undermine the scientific validity and trustworthiness of the work. The other issues further point to a lack of care in the presentation and reporting of the results. These issues must be addressed before the manuscript can be considered for publication.