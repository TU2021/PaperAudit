Summary
The paper investigates whether predictive uncertainty in deep learning obeys empirical scaling laws with respect to dataset size. Across vision (CIFAR-10/100, ImageNet-32) and text tasks (GPT-2 on algorithmic data; fine-tuned Phi-2), the authors measure Total Uncertainty (TU), Aleatoric Uncertainty (AU), and Epistemic Uncertainty (EU) via an entropy-based decomposition and fit power laws versus training set size N. They examine multiple uncertainty quantification (UQ) methods—MC Dropout, Deep Ensembles, and MCMC (including partially stochastic networks)—and report generally consistent power-law decay trends, especially for EU, with exponents that vary by architecture and setting (e.g., ResNet-18 and WideResNet on CIFAR, ImageNet-32 with shallower trends; OOD on CIFAR-10-C showing reduced decay). Ablations demonstrate sensitivity to optimization choices (e.g., ViT schedules leading to near-flat EU; EU growth under SAM). Theoretically, the paper derives EU ∼ O(1/N) for identifiable Bayesian linear models and connects TU to Watanabe’s Singular Learning Theory (SLT) generalization error, proposing SLT as a framework for interpreting uncertainty scaling in overparameterized regimes. The authors also illustrate extrapolations of uncertainty scaling to plan data requirements for targeted uncertainty levels.

Strengths
- Broad empirical scope across modalities, datasets, architectures, and UQ methods, including both in-distribution and out-of-distribution settings.
- Consistent observation of approximate power-law behavior in predictive uncertainty, particularly EU, across many configurations and methods (MC Dropout, Deep Ensembles, MCMC).
- Insightful optimization ablations that reveal sensitivity of uncertainty scaling to training choices (ViT schedule effects; SAM-induced EU trends).
- Theoretical grounding for identifiable linear models with clear derivations showing EU ∼ O(1/N), and a principled conceptual link to SLT generalization error.
- Transparent reporting of experimental setups and limitations, with comprehensive figures and appendices that detail architectures and training protocols.
- Practical demonstration of extrapolating uncertainty scaling to estimate data requirements and identify regimes where epistemic uncertainty becomes negligible.

Weaknesses
- The claims of power-law scaling are not supported by statistical fit diagnostics; there are no reported confidence intervals, R², residual analyses, or comparisons against alternative functional forms, which is especially problematic when exponents are near zero or positive (e.g., some ViT and ImageNet-32 cases; OOD settings with shallow or flat trends).
- Some results rely on single folds or runs and limited N ranges (e.g., 10K–50K), which undermines robustness and the strength of asymptotic interpretations; averaging and error bars are not consistently provided across panels.
- Heavy reliance on entropy-based TU/AU/EU metrics, which have known interpretability limitations, without sensitivity checks to alternative uncertainty metrics (e.g., logits variance, mutual information variants) or calibration measures (e.g., ECE, NLL).
- Theoretical presentation includes a sign inconsistency in Sec. 5.2 Eq. (10) relative to the appendix; the appendix’s non-negative decomposition is correct and the main text should be aligned.
- The extension from identifiable linear models to deep, singular regimes via SLT remains qualitative and speculative, without quantitative predictions or validation in deep networks.
- ImageNet-32 exponents appear much closer to zero than for CIFAR, but the analysis lacks multi-fold averages, error bars, and discussion of potential causes.
- The MCMC approach uses partially stochastic networks and practical approximations, so conclusions characterized as “Bayesian scaling” reflect approximate posteriors; diagnostics of mixing or effective sample size are not reported.
- Model-size and compute scaling are only lightly addressed; parameter-count effects are limited and not controlled by matched training budgets, and compute scaling is not studied.
- The SAM explanation for EU increasing with N is qualitative and not supported by curvature or Hessian-spectrum measurements.
- Extrapolation exercises extend far beyond observed N without uncertainty bands or validation at larger N, weakening confidence in practical planning claims.
