Integrity and consistency risk report

Summary
The manuscript presents a two-stage RTSSL approach combining EM-based estimation of the missingness mechanism and classifier with a doubly robust estimator of the class distribution, then plugging the estimated unlabeled distribution into pseudo-labeling methods (SimPro/BOAT). While much of the derivation is coherent, there are several high-impact internal inconsistencies and missing evidentiary elements that materially affect correctness and trustworthiness.

Key issues

1) Mis-specified “logit adjustment loss” in Equation (9)
- Evidence: Section 3.2, Equation (9): “−∑_i ∑_c γ_i(c) log{ P(Y=c | X=x_i, uniform, θ) + P(Y=c) }”.
- Problem: This loss takes the logarithm of a sum of probabilities, which is not a valid cross-entropy form (the argument to log should be a properly normalized predicted probability for class c, not “probability + prior”). It is also inconsistent with the Bayes-based label-shift formula in Equation (3), where adjustment is multiplicative on likelihoods/logits (Menon et al., 2020 style adds log priors to logits; it does not add probabilities inside the log).
- Impact: This undermines the claimed connection to logit adjustment and risks invalid training objectives in Section 3.2. It also conflicts conceptually with the stated goal of adapting to a uniform test distribution (Section 2, Equation (3)).

2) Incorrect claim that P(Y|A) can be recovered from P(A|Y) and known P(A) alone
- Evidence: Section 3.2: “we can recover the class distribution P(Y|A) from the missingness mechanism P(A|Y) and, because P(A) is known, they are learned equivalently.”
- Problem: The identity is P(Y|A=a) = P(A=a|Y) P(Y) / P(A=a). Thus, recovering P(Y|A) from P(A|Y) requires knowledge of P(Y), not just P(A). The text omits dependence on P(Y), which is later estimated via OR/IPW/DR (Section 3.3), but the claim of “equivalent learning” is mathematically false as stated.
- Impact: Misstates identifiability and could mislead readers about what components must be estimated to obtain P(Y|A).

3) Theoretical guarantees hinge on assumptions not evidenced in experiments (sample splitting)
- Evidence: Appendix A, Assumption A.1.3: requires P(Y|X, θ) and P(A|Y, θ) to be estimated on auxiliary samples independent of the samples used for the sample averaging (i.e., sample splitting or cross-fitting).
- Evidence: Appendix C (Training and hyperparameter settings) describes implementation but does not mention sample splitting/cross-fitting.
- Problem: The asymptotic normality and efficiency result in Theorem 3.2 (Section 3.3.1; proof in Appendix A) relies on independence of nuisance estimators from the evaluation samples. No direct evidence found in the manuscript that sample splitting or cross-fitting was used in any experiments.
- Impact: The strong theoretical guarantees claimed for Ψ_dr (Theorem 3.2) may not apply to the reported empirical pipeline as implemented, weakening the validity of the theoretical claims in practice.

4) Conclusion contradicts experimental evidence for CIFAR-10
- Evidence: Section 5 (Conclusion): “even inaccurate class-label distributions do not lead to degraded accuracy in CIFAR-10.”
- Evidence: Table 3 (Section 4.2): SimPro vs SimPro+ shows degradation in at least one CIFAR-10 setting (e.g., reversed, γ_l=150, γ_u=1/150: SimPro 83.8 ± 0.80 vs SimPro+ 83.3 ± 0.38; uniform, γ_l=150, γ_u=1: BOAT 93.9 ± 0.03 vs BOAT+ 93.7 ± 0.23).
- Problem: The conclusion statement is contradicted by Table 3 where accuracy is lower for the plug-in in some settings.
- Impact: Overstates robustness of the approach; the contradiction reduces trustworthiness of the summary claims.

5) Missing or incomplete evidence for reported improvements
- Evidence: Section 4.2: “Table 5 demonstrates improvements for 2/2 class imbalance ratios in STL-10.”
- Problem: No Table 5 appears in the manuscript. No direct evidence found in the manuscript to substantiate the STL-10 claim.
- Additional evidence gap: Table 2 (CIFAR-100-LT, Section 4.1) appears truncated (e.g., “MLE OR 0.065 ± 0.002 | 0.061...”), impeding verification of full results and conclusions.
- Impact: Missing/incomplete tables prevent independent assessment of key empirical claims.

6) Unlabeled likelihood term miswritten as equality instead of proportionality
- Evidence: Section 4.1 (MLE description): “write the unlabeled term as P(A=0, X) = ∑_c P(Y=c | X) P(A=0 | Y=c)”.
- Problem: Correct factorization is P(A=0, X) = P(X) ∑_c P(Y=c | X) P(A=0 | Y=c); since P(X) is not modeled, the equality should be “∝” rather than “=”.
- Impact: This is a technical misstatement in the likelihood decomposition. While likely minor in implementation (since P(X) is constant w.r.t θ), the equality as written is mathematically incorrect.

7) Ambiguity/inconsistency around use of P(Y) in logit adjustment
- Evidence: Section 3.2, Equation (9), and Appendix C: “we still keep a running estimate of the class distribution P(Y) in the logit adjustment loss Equation (9).”
- Problem: Adjusting to a uniform test distribution (Equation (3)) should be implemented via logit shifts by log(P(Y_target)/P(Y_source)). The manuscript’s use of a “running P(Y)” added inside a log (Equation (9)) is both mathematically suspect (see Issue 1) and conceptually mismatched with Equation (3). It is also unclear whether they adjust from labeled to uniform or from combined to uniform.
- Impact: Creates confusion about the correctness of the training objective and could materially affect method behavior.

Other observations (lower impact)
- Variable naming inconsistency: Tables use “M_l” while Section 2 uses “N, N_l, D_u” and Datasets section uses “m_1”. No direct impact, but inconsistent notation (Section 4.1 tables vs Section 2) can hinder reproducibility.
- Assumption A.1.2 requires P(A=1|Y) ≥ ε and suggests clipping; no direct evidence found in the manuscript that clipping was implemented in experiments, while instability from large weights is noted elsewhere (Section 4.3, Appendix B).

Conclusion
The manuscript contains several high-impact internal inconsistencies and missing evidentiary elements:
- A mis-specified core loss (Equation (9)) that conflicts with the earlier label-shift formulation and standard logit adjustment practices.
- A mathematically incorrect identifiability claim for P(Y|A) from P(A|Y) alone.
- Theoretical guarantees predicated on sample splitting not evidenced in experiments.
- A conclusion statement contradicted by reported CIFAR-10 results.
- Missing/incomplete tables impede verification of key claims.

Addressing these issues—especially correcting Equation (9), clarifying identifiability and training objectives, documenting whether sample splitting was used, revising the conclusion to match Table 3, and supplying all referenced tables—would substantially improve the paper’s correctness and integrity.