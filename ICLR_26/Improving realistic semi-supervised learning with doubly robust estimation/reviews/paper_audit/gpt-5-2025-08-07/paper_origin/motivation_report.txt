# Innovation & Motivation Report

## 1. The Authors' Claimed Contribution
- Core Problem: Realistic long-tailed semi-supervised learning (RTSSL) where the unlabeled class distribution P(Y|A=0) is unknown and differs from the labeled distribution P(Y|A=1), leading standard pseudo-labeling to be biased and perform poorly on unlabeled data.
- Claimed Gap: â€œExisting methods typically assume that the unlabeled class distribution is either known a priori, which is unrealistic in most situations, or estimate it on-the-fly using the pseudo-labels themselves.â€ (Abstract). The Introduction further motivates that â€œSimPro (Du et al., 2024) overestimates head classes in 4/5 unlabeled distribution settings (Figure 1). The proposed doubly robust estimator is more accurate.â€
- Proposed Solution: A two-stage method. Stage 1 uses a label-shift EM framework to estimate P(Y|X) and the missingness mechanism P(A|Y), then applies a doubly robust (DR) estimator to accurately estimate the combined class distribution P(Y) and recover P(Y|A=0). Stage 2 incorporates this estimated unlabeled class distribution into pseudo-labeling approaches (e.g., SimPro, BOAT) via logit adjustment/EM. Theoretical guarantees are provided: â€œUnder Assumption 3.1â€¦ âˆšN(Î¨_dr(Î¸)(c) âˆ’ P(Y=c)) â‡’ ğ’©(0, ğ”¼[Ï†(O)(c)^2]).â€ (Theorem 3.2). The approach explicitly models non-ignorable missingness: â€œAdapt a maximum likelihood framework with non-ignorable missingness via EM, encoding P(A|Y). This generalizes FixMatch and reparameterizes SimPro.â€ (Introduction; Section 3.2)

## 2. Comparative Scrutiny (The "Trial")
Here, we analyze how the paper stands against the identified similar works.

### vs. Learning to Impute: A General Framework for Semi-supervised Learning
- Identified Overlap: Both aim to improve SSL by producing better imputed labels/signals for unlabeled data and plugging them into standard training. The manuscriptâ€™s Stage 1 EM responsibilities Ï‰^t(x,c) and DR estimate of class priors act as learned imputation signals.
- Manuscriptâ€™s Defense: The manuscript specializes the imputation to label-shift RTSSL with explicit prior estimation and theory: â€œWe propose to explicitly estimate the unlabeled class distributionâ€¦ using a doubly robust estimator with a strong theoretical guarantee; this estimate can then be integrated into existing methodsâ€¦â€ (Abstract). It further formalizes identifiability under label shift: â€œAssumes label shift P(X|Y, A)=P(X|Y).â€ (Explicit caveats; Preliminaries Eq. (2))
- Reviewerâ€™s Assessment: The distinction is substantive. Prior â€œlearning to imputeâ€ provides a general plug-in idea; here, the authors deliver a statistically grounded, efficient DR estimator targeted at class-prior shift under non-ignorable missingness, with a concrete EM factorization. This narrows the scope but deepens rigor. The manuscript does not appear to cite this specific work in the provided text.

### vs. InterLUDE: Labeledâ€“Unlabeled Interaction for SSL
- Identified Overlap: Both emphasize interaction between labeled and unlabeled pools to correct biases; the manuscriptâ€™s EM lower bound blends labeled counts with unlabeled posteriors, and Stage 2 aligns predictions via prior-aware logit adjustment.
- Manuscriptâ€™s Defense: The manuscript claims a principled label-shift EM view with explicit modeling of P(A|Y): â€œAdapt a maximum likelihood framework with non-ignorable missingness via EM, encoding P(A|Y). This generalizes FixMatch and reparameterizes SimPro (details in Section 3.2).â€ (Introduction) It further provides a DR estimator with efficiency (Theorem 3.2).
- Reviewerâ€™s Assessment: Methodological overlap exists at a high level (labeledâ€“unlabeled coupling), but the manuscriptâ€™s focus on estimating and correcting unlabeled class priors under label shift is a concrete and theoretically anchored contribution beyond InterLUDEâ€™s embedding fusion/consistency heuristics. The manuscript does not appear to cite InterLUDE in the provided text.

### vs. Bayesian Pseudo Labels: EM for Semi-Supervised Segmentation
- Identified Overlap: Both recast pseudo-labeling as EM with responsibilities; the manuscript also views FixMatch as an EM instance and reparameterizes SimPro accordingly.
- Manuscriptâ€™s Defense: It differentiates via label-shift modeling and explicit estimation of P(A|Y) and P(Y|A=0): â€œNon-ignorable missingness: A can depend on both X and Y; with label shift assumptionâ€¦ the true data distribution is identifiable.â€ (Preliminaries) â€œLabel-shift EMâ€¦ Ï‰^t(x,c) âˆ P(Y|X)Â·P(A=0|Y).â€ (Section 3.1, Eq. (7)) and then â€œapply a meta doubly robust estimator to improve P(Y|A=0).â€ (Introduction; Section 3.3)
- Reviewerâ€™s Assessment: The EM framing is shared, but the manuscriptâ€™s label-shift identifiability, explicit missingness mechanism P(A|Y), and semiparametric DR estimation of class priors represent a significant technical extension beyond prior EM-as-pseudo-labeling works. The segmentation domain and dynamic thresholds differ in scope. The manuscript does not appear to cite this specific work in the provided text.

### vs. FreeMatch: Self-adaptive Thresholding for SSL
- Identified Overlap: Common pseudo-labeling backbone (FixMatch/consistency) and concern with imbalanced SSL.
- Manuscriptâ€™s Defense: The manuscript explicitly targets class-prior correction rather than thresholding: â€œLabel shift and logit adjustmentâ€¦ P(Y|X,uniform) âˆ P(Y|X,A=1) P(Y|uniform)/P(Y|A=1).â€ (Preliminaries Eq. (3)) and â€œUseâ€¦ estimated unlabeled distribution to train final classifier.â€ (Method; Section 3.3; Section 3.2 Eq. (9))
- Reviewerâ€™s Assessment: While both adapt pseudo-labeling to imbalance, the manuscriptâ€™s core novelty is class-prior estimation via EM+DR under label shift with efficiency guarantees. FreeMatchâ€™s adaptive thresholds are orthogonal. The difference is meaningful. The manuscript adheres to FixMatch/SimPro connections but does not appear to cite FreeMatch in the provided text.

### vs. Keep It on a Leash (CPG): Controllable Pseudo-label Generation
- Identified Overlap: Both aim to mitigate pseudo-label bias under unknown unlabeled distributions and employ logit adjustment informed by class priors.
- Manuscriptâ€™s Defense: It proposes explicit prior estimation as a finite-dimensional parameter with theoretical guarantees: â€œExplicitly estimate the unlabeled class distributionâ€¦ using a doubly robust estimator with strong theoretical guarantees; integrate into pseudo-labeling to improve training.â€ (Abstract) and provides a label-shift EM factorization including P(A|Y) (Section 3.1â€“3.2).
- Reviewerâ€™s Assessment: CPG enforces a known distribution via controllable filtering; the manuscript estimates it via an efficient DR estimator within an EM model of missingness. The approaches are close in spirit; however, the manuscript advances a principled estimation-and-proof route that CPG does not. The manuscript does not appear to cite CPG in the provided text.

### vs. Class-Distribution-Aware Pseudo Labeling (CAP) for Multi-Label Learning
- Identified Overlap: Both estimate the class distribution and feed it back into pseudo-labeling to align with true priors.
- Manuscriptâ€™s Defense: The manuscript focuses on single-label, label-shift SSL with identifiability and DR efficiency: â€œAssumes label shift P(X|Y, A)=P(X|Y).â€ (Preliminaries; Explicit caveats) and â€œÎ¨_drâ€¦ unbiased if either P(Y|X) or P(A|Y) is correct; asymptotically normal and efficient.â€ (Section 3.3; Theorem 3.2)
- Reviewerâ€™s Assessment: Conceptual overlap (distribution-aware pseudo-labeling) is evident, but the setting (single-label under label shift) and the semiparametric efficiency claims are new in this context. The manuscript does not appear to cite CAP in the provided text.

### vs. â€œImproving realistic semi-supervised learning with doubly robust estimationâ€ (same title/authors)
- Identified Overlap: The Similar Works list includes a paper with identical title and authors and an abstract that matches the manuscriptâ€™s Abstract.
- Manuscriptâ€™s Defense: Not applicable; this appears to be the same work. The Abstract text in the Similar Work matches the manuscriptâ€™s Abstract: â€œWe propose to explicitly estimate the unlabeled class distributionâ€¦ using a doubly robust estimatorâ€¦ integrate into existing methodsâ€¦â€
- Reviewerâ€™s Assessment: This is not independent prior art but likely the same manuscript or its preprint. It does not weaken motivation or novelty but indicates redundancy within the Similar Works list.

## 3. Novelty Verdict
- Innovation Type: Substantive
- Assessment:
  The manuscript identifies a concrete gap in RTSSLâ€”unknown and long-tailed unlabeled class priors bias pseudo-labelingâ€”and defends a principled remedy: estimate the unlabeled class distribution via a doubly robust estimator embedded in a label-shift EM framework with explicit modeling of non-ignorable missingness P(A|Y). This delivers asymptotic efficiency under fourth-root-n nuisance rates and sample splitting (Theorem 3.2), and then plugs the estimate into existing methods (SimPro, BOAT) to improve training. Compared to similar works that either heuristically adjust thresholds, enforce controlled priors via filtering, or recast pseudo-labeling as EM without label-shift identifiability, the manuscriptâ€™s contribution is a statistically grounded, target-parameterâ€“centric approach with theory and empirical validation.
  - Strength:
    - Clear, well-articulated gap: â€œExisting methodsâ€¦ assumeâ€¦ known unlabeled distribution or estimate it on-the-fly via pseudo-labels; can be biased.â€ (Abstract)
    - Principled modeling: label-shift identifiability (P(X|Y, A)=P(X|Y)) and non-ignorable missingness via EM (Section 3.1â€“3.2).
    - Theoretical guarantees: doubly robust estimator Î¨_dr is asymptotically normal and efficient under Assumption 3.1; influence-function derivation and efficiency in Appendix A (Equations (16)â€“(27)).
    - Empirical support: Lower TVD estimates for P(Y|A=0) in CIFAR-10/ImageNet-127, and consistent accuracy improvements when plugging into SimPro/BOAT across multiple settings (Section 4.1â€“4.2).
    - Clarifies connections: shows FixMatch as EM and reparameterizes SimPro (Section 3.2), strengthening conceptual coherence.
  - Weakness:
    - Reliance on assumptions: â€œAssumes label shift P(X|Y, A)=P(X|Y) and uniform test distribution.â€ (Explicit caveats), boundedness of P(A=1|Y) â‰¥ Îµ and sample splitting (Appendix A).
    - Practical instability: â€œDR-risk training can be unstable due to inverse weighting; small P(A|Y) for tail classes causes training issues.â€ (Explicit caveats; Section 4.3), and the DR-loss ablation underperforms (Section 4.3).
    - Estimation quality varies: â€œFor CIFAR-100 stage 1 estimates may be poor, yet accuracy generally does not degrade.â€ (Explicit caveats), suggesting limited robustness in high-class-count regimes.
    - Coverage of related work: Several closely related distribution-aware pseudo-labeling works (e.g., FreeMatch, CPG, CAP) are not explicitly cited in the provided text, leaving some overlap unaddressed in the manuscriptâ€™s narrative.

## 4. Key Evidence Anchors
- Abstract: â€œExisting methods typically assume that the unlabeled class distribution is either known a prioriâ€¦ or estimate it on-the-flyâ€¦ We propose to explicitly estimate the unlabeled class distributionâ€¦ using a doubly robust estimatorâ€¦ integrate into existing methodsâ€¦â€
- Introduction: â€œSimProâ€¦ overestimates head classesâ€¦ The proposed doubly robust estimator is more accurate.â€ and â€œAdapt a maximum likelihood framework with non-ignorable missingness via EM, encoding P(A|Y). This generalizes FixMatch and reparameterizes SimPro.â€
- Preliminaries:
  - Label-shift assumption: â€œP(X|Y,A)=P(X|Y)â€ (Equation (2)).
  - Bayes correction: â€œP(Y|X,uniform) âˆ P(Y|X,A=1)Â·P(Y|uniform)/P(Y|A=1)â€ (Equation (3)).
- Method:
  - EM lower bound and responsibilities: Q(Î¸|Î¸^t) decomposition (Equations (5)â€“(7)).
  - SimPro EM/logit adjustment link: â€œLoss â€¦ with P(Y) maintained as a running estimate.â€ (Equation (9); Section 3.2).
  - Estimators: OR/IPW/DR definitions for P(Y) (Equations (10), (12), (13)); DR unbiasedness if either P(Y|X) or P(A|Y) is correct.
- Theory:
  - Assumption 3.1 (fourth-root-n rates) (Equation (14)).
  - Theorem 3.2: asymptotic normality and efficiency of Î¨_dr (Equation (15)); proof and influence function in Appendix A (Equations (16)â€“(27)).
- Experiments:
  - Distribution estimation (TVD): CIFAR-10/Table 1, ImageNet-127/Table 7 (e.g., SimPro DR TVD â€œ0.017 Â± 0.004â€ in CIFAR-10 consistent; â€œ0.017 Â± 0.000â€ on ImageNet-127 32Ã—32).
  - Accuracy improvements: CIFAR-10/Table 3 (e.g., SimPro â€œ74.4 Â± 0.71â€ â†’ â€œ77.8 Â± 1.50â€), ImageNet-127/Table 6 (e.g., SimPro â€œ63.7â€ â†’ â€œ64.2â€ at 64Ã—64).
  - Ablations: DR-risk instability and batch-update DR underperformance (Section 4.3; Table 8).