1) Summary
This paper introduces Thanos, a post-training, data-aware weight pruning algorithm for large language models (LLMs). The method operates in a block-wise manner, pruning and updating multiple weights within a block simultaneously by solving a small system of linear equations. This approach is designed to better account for the cumulative impact of removing multiple weights compared to iterative one-shot methods. The authors extend Thanos to structured and semi-structured (n:m) sparsity, introducing a novel technique to identify and preserve "outlier rows" to maintain performance. Experimental results on OPT and LLaMA model families show that Thanos is competitive with existing methods like SparseGPT and Wanda in unstructured pruning and achieves strong results in structured pruning across various model sizes and sparsity levels.2) Strengths
*   **Novel and Sound Technical Approach**
    *   The core contribution of updating multiple weights simultaneously within a block (Section 4.1) is a technically sound and novel extension of the Optimal Brain Surgeon (OBS) framework used by methods like SparseGPT. Instead of pruning weights one by one, Thanos formulates the update as a single optimization problem with multiple constraints (Equation 6), which is solved to find the optimal update for a group of weights (Equation 10).
    *   This block-wise update allows for "in-block communication" between weights being pruned (Figure 7, Appendix G.2), which is a more powerful approximation of the pruning loss than the one-at-a-time approach that cannot model interactions between pruned weights within the same update step.
    *   The mathematical derivations for the general multi-weight update are provided in detail, showing a clear theoretical grounding for the proposed method (Appendix G.1).*   **Significant Innovation in Structured Pruning**
    *   The paper introduces a novel and effective technique for structured pruning that identifies and preserves "outlier rows" (Section 4.7.1). This is controlled by a hyperparameter α, which specifies the fraction of rows to exempt from pruning based on their contribution to the layer's output norm (Equation 14).
    *   This technique yields substantial performance improvements according to the reported results. For instance, in Table 2, for LLaMA-3 8B with 30% structured sparsity, `Thanos (α = 0.1)` achieves a perplexity of 36.61, a dramatic improvement over both the baseline `Thanos (α = 0)` (64.43) and strong competitors like SparseGPT (82.19).
    *   The overall pipeline for structured pruning, involving row and column permutations to isolate outliers and columns-to-prune, is well-conceived and clearly illustrated (Figure 3, Algorithm 2).*   **Comprehensive Experimental Evaluation**
    *   The method is evaluated on a wide and relevant set of models, including the OPT and LLaMA families (LLaMA-2, LLaMA-3, TinyLlama) with sizes ranging from 125M to 70B parameters (Section 5.1).
    *   Evaluation is performed on multiple metrics, including perplexity on WikiText-2 (Table 2) and average zero-shot accuracy across seven diverse downstream tasks (Table 3), providing a holistic view of the model's capabilities post-pruning.
    *   The experiments cover various sparsity patterns: unstructured, structured (column pruning), and semi-structured (2:4, 4:8), demonstrating the versatility of the proposed framework (Tables 2, 3, and Appendix D). The paper attempts fair comparisons by using the same calibration data for all data-aware methods (Section 5.1).*   **Strong Reported Empirical Results, Especially for Structured Sparsity**
    *   Thanos demonstrates state-of-the-art performance in structured pruning by a large margin across all tested models and sparsity levels in the provided tables. The perplexity and zero-shot results in Tables 2 and 3 consistently show Thanos outperforming SparseGPT and Wanda.
    *   For example, on LLaMA-2 70B with 2:4 sparsity, Thanos achieves a perplexity of 4.98, compared to 5.69 for SparseGPT and 5.48 for Wanda (Table 2).
    *   The performance gains are clearly visualized in the perplexity vs. sparsity plots, where Thanos consistently provides a better trade-off, especially with outlier detection enabled (Figure 1b).
    *   The method remains competitive in unstructured pruning, often matching or slightly exceeding the performance of SparseGPT and Wanda (Table 2, Figure 1a).3) Weaknesses
*   **Unconventional and Confusing Manuscript Organization**
    *   The paper's structure deviates significantly from the standard scientific format, which severely hinders readability. The "Experiments" section (Section 5) is presented immediately after the "Introduction" (Section 1), before the "Method" (Sections 2-4) has been described. This forces the reader to assess results without understanding how they were generated.
    *   The "Preliminaries" and "Related Work" sections are combined and placed after the problem formulation (Section 3), interrupting the flow of the proposed method.
    *   The "Conclusion and Limitations" are relegated to Appendix A, but this is a critical section that should be in the main paper. This unconventional layout makes the paper difficult to navigate and comprehend.*   **Inconsistent and Potentially Incorrect Mathematical Formulation**
    *   The core update rule for structured pruning is presented in three different and conflicting forms across the manuscript, undermining the technical soundness of this key contribution.
    *   In the main text, Algorithm 2 and Equation 13 present a formula `W_{:,1:s} - W_{:,1:s} (H_{1:s,1:s}^{-1})^{-1} H_{1:s,:}^{-1}` which appears mathematically unusual due to the double inverse.
    *   In the appendix, Algorithm 7 presents a different formula for the same step: `W_{:,1:s} - W_{:,1:s} (H_{1:s,1:s}^{-1}) H_{1:s,:}`.
    *   A third, more plausible formula for the update `− W_{:,1:s} (H_{1:s,1:s})^{-1} H_{1:s,:}` is given in Appendix G.4.2 (Eq. 72), but this contradicts the other two versions presented in the algorithms. This lack of a single, correct formulation is a major flaw.*   **Significant Discrepancies in Reported Experimental Results**
    *   There is a major numerical mismatch between the results presented in Figure 1(b) and Table 2 for the same experiment: structured pruning on the LLaMA-3 8B model.
    *   For example, at 30% sparsity, Table 2 reports a perplexity of 82.19 for SparseGPT, while the plot in Figure 1(b) shows a value around 52.
    *   Similar large discrepancies exist for `Thanos (α=0)` (64.43 in table vs. approx. 45 in figure). Such inconsistencies raise serious concerns about the reliability and correctness of the experimental data.*   **Methodologically Flawed Comparison in Semi-Structured Pruning**
    *   The experimental comparison for semi-structured n:m sparsity with outlier handling is unfair. The paper explicitly states in Section 5.1 that for `Thanos (α=0.1)`, the effective sparsity is reduced from 50% to 45%.
    *   However, in Tables 2 and 3, this version of Thanos is directly compared against baselines (SparseGPT, Wanda) that are evaluated at the full 50% sparsity.
    *   This invalidates the claims of superior performance in these settings, as the improved results for `Thanos (α=0.1)` are likely attributable, at least in part, to it pruning 10% fewer weights than the methods it is compared against.*   **Insufficient Analysis of Computational Complexity and Efficiency**
    *   The theoretical complexity of Thanos for unstructured pruning is higher than its competitors (Table 1), but the trade-off between this increased cost and the resulting accuracy improvement is not explicitly discussed or visualized.
    *   The paper makes several claims about efficiency (Appendix H.1, H.3) but does not provide a clear, direct comparison of the accuracy-efficiency trade-off. For example, while Figure 9 shows pruning time, it is not directly linked to the accuracy results in Tables 2 and 3, making it hard to judge if the extra computational cost of Thanos is justified.
    *   The paper mentions that GPU memory limitations require further subdivision of pruning blocks (Appendix H.2), which suggests practical scalability challenges. A more thorough analysis of the wall-clock time and memory usage versus model size and accuracy would be beneficial.*   **Limited Ablation and Hyperparameter Sensitivity Analysis**
    *   The method introduces two important hyperparameters: the block size `B` and the outlier row fraction `α`. The sensitivity to these hyperparameters is not sufficiently explored.
    *   For `B`, an ablation is provided in Appendix C (Table 5), but only for a single model (TinyLlama-1.1B). The results for unstructured sparsity show perplexity is "relatively stable across different block sizes," which raises the question of how critical the block-wise formulation is if the block size has minimal impact. The justification for choosing `B=128` for unstructured and `B=512` for structured/semi-structured sparsity (Section 5.1) could be strengthened with analysis on more models.
    *   For `α`, results are presented for `α=0` and `α=0.1` (Tables 2, 3), demonstrating its effectiveness. However, there is no analysis of how performance varies for other values of `α` (e.g., 0.05, 0.15, 0.2). This makes it difficult to assess the robustness of `α=0.1` as a default setting.4) Suggestions for Improvement
*   **Reorganize the Manuscript for Clarity**
    *   The paper should be restructured to follow a standard, logical flow. A suggested order is: 1. Introduction, 2. Preliminaries and Related Work, 3. Method (Thanos), 4. Experiments, 5. Conclusion.
    *   The problem formulation (currently Section 2) should be part of the Method section.
    *   The Conclusion and Limitations (currently Appendix A) should be moved to the main body of the paper, providing a proper summary of the work and its context.*   **Unify and Correct the Mathematical Formulation**
    *   Please provide a single, correct, and consistently used mathematical formula for the structured pruning weight update.
    *   Clarify the derivation for this update rule and ensure it is correctly reflected in all algorithms (Algorithm 2, Algorithm 7) and equations (Eq. 13, Eq. 72) throughout the manuscript and appendix.*   **Reconcile and Verify Experimental Results**
    *   The authors must resolve the numerical discrepancy between Figure 1(b) and Table 2.
    *   Please verify all reported numbers and ensure that figures and tables are consistent. If there was an error, it should be corrected and explained.*   **Ensure Fair Experimental Comparisons**
    *   To ensure a fair comparison in the semi-structured n:m experiments, the baselines should also be evaluated at the same 45% effective sparsity level as `Thanos (α=0.1)`.
    *   Alternatively, the Thanos method with `α=0.1` could be adjusted to achieve a final effective sparsity of 50% to match the baselines. The results in Tables 2 and 3 should be updated accordingly.*   **Provide a Clearer Analysis of the Efficiency Trade-off**
    *   The authors should add a dedicated analysis of the accuracy-efficiency trade-off. This could be a plot of perplexity/accuracy versus pruning time for Thanos and the baselines on a few representative models.
    *   Please clarify the efficiency claims made in Appendix H.1 and H.3 relative to the data in Figure 9, particularly for unstructured and semi-structured pruning where Thanos is slower on larger models.
    *   It would be valuable to include memory usage statistics during pruning to give a more complete picture of the practical costs associated with the method, especially in light of the issues mentioned in Appendix H.2.*   **Conduct More Thorough Ablation Studies**
    *   To strengthen the claims about hyperparameter choices, the ablation study for block size `B` (Table 5) should be expanded to include at least one larger model to confirm if the observed stability holds at scale.
    *   A sensitivity analysis for the outlier fraction `α` is crucial. Please include a plot showing how a key metric (e.g., perplexity on LLaMA-3 8B) changes as `α` is varied (e.g., from 0 to 0.3). This would demonstrate the robustness of the method and help practitioners choose an appropriate value.5) Score
*   Overall (10): 5 — The paper introduces promising ideas, especially for structured pruning, but is undermined by major flaws including inconsistent mathematical formulations, conflicting experimental reports, and unfair baseline comparisons.
*   Novelty (10): 8 — The block-wise simultaneous weight update (Eq. 10) and the outlier-aware structured pruning approach (Sec. 4.7.1) are strong and novel contributions to the field of post-training pruning.
*   Technical Quality (10): 5 — The core idea is interesting, but the technical execution is flawed due to inconsistent mathematical formulas (Alg. 2 vs Alg. 7 vs Eq. 72), unfair experimental comparisons (Sec. 5.1), and major discrepancies in reported results (Fig. 1b vs Table 2).
*   Clarity (10): 4 — The unconventional manuscript organization (e.g., Experiments before Method) makes the paper very difficult to follow, and this is compounded by inconsistent mathematical formulas and conflicting results between figures and tables.
*   Confidence (5): 5 — I have carefully reviewed the main paper and the appendices and am confident in my assessment of its strengths and weaknesses.