**1) Summary**This paper introduces Thanos, a post-training, data-aware weight pruning algorithm for large language models (LLMs). The method operates in a block-wise manner, pruning and updating multiple weights within a block simultaneously by solving a small system of linear equations. This approach is designed to better account for the cumulative impact of removing multiple weights compared to iterative one-shot methods. The authors extend Thanos to structured and semi-structured (n:m) sparsity, introducing a novel technique to identify and preserve "outlier rows" to maintain performance. Experimental results on OPT and LLaMA model families show that Thanos is competitive with existing methods like SparseGPT and Wanda in unstructured pruning and achieves state-of-the-art results in structured pruning across various model sizes and sparsity levels.**2) Strengths***   **Novel and Sound Technical Approach**
    *   The core contribution of updating multiple weights simultaneously within a block (Section 4.1) is a technically sound and novel extension of the Optimal Brain Surgeon (OBS) framework used by methods like SparseGPT. Instead of pruning weights one by one, Thanos formulates the update as a single optimization problem with multiple constraints (Equation 6), which is solved to find the optimal update for a group of weights (Equation 10).
    *   This block-wise update allows for "in-block communication" between weights being pruned (Figure 7, Appendix G.2), which is a more powerful approximation of the pruning loss than the one-at-a-time approach that cannot model interactions between pruned weights within the same update step.
    *   The mathematical derivations for the multi-weight update are provided in detail, showing a clear theoretical grounding for the proposed method (Appendix G.1).*   **Significant Innovation in Structured Pruning**
    *   The paper introduces a novel and effective technique for structured pruning that identifies and preserves "outlier rows" (Section 4.7.1). This is controlled by a hyperparameter α, which specifies the fraction of rows to exempt from pruning based on their contribution to the layer's output norm (Equation 14).
    *   This technique yields substantial performance improvements. For instance, in Table 2, for LLaMA-3 8B with 30% structured sparsity, `Thanos (α = 0.1)` achieves a perplexity of 36.61, a dramatic improvement over both the baseline `Thanos (α = 0)` (64.43) and strong competitors like SparseGPT (82.19).
    *   The overall pipeline for structured pruning, involving row and column permutations to isolate outliers and columns-to-prune, is well-conceived and clearly illustrated (Figure 3, Algorithm 2).*   **Comprehensive and Rigorous Experimental Evaluation**
    *   The method is evaluated on a wide and relevant set of models, including the OPT and LLaMA families (LLaMA-2, LLaMA-3, TinyLlama) with sizes ranging from 125M to 70B parameters (Section 5.1).
    *   Evaluation is performed on multiple metrics, including perplexity on WikiText-2 (Table 2) and average zero-shot accuracy across seven diverse downstream tasks (Table 3), providing a holistic view of the model's capabilities post-pruning.
    *   The experiments cover various sparsity patterns: unstructured, structured (column pruning), and semi-structured (2:4, 4:8), demonstrating the versatility of the proposed framework (Tables 2, 3, and Appendix D). The comparisons are fair, using the same calibration data for all data-aware methods (Section 5.1).*   **Strong Empirical Results, Especially for Structured Sparsity**
    *   Thanos demonstrates state-of-the-art performance in structured pruning by a large margin across all tested models and sparsity levels. The perplexity and zero-shot results in Tables 2 and 3 consistently show Thanos outperforming SparseGPT and Wanda. For example, on LLaMA-2 70B with 2:4 sparsity, Thanos achieves a perplexity of 4.98, compared to 5.69 for SparseGPT and 5.48 for Wanda (Table 2).
    *   The performance gains are clearly visualized in the perplexity vs. sparsity plots, where Thanos consistently provides a better trade-off, especially with outlier detection enabled (Figure 1b).
    *   The method remains competitive in unstructured pruning, often matching or slightly exceeding the performance of SparseGPT and Wanda (Table 2, Figure 1a).**3) Weaknesses***   **Unconventional and Confusing Manuscript Organization**
    *   The paper's structure deviates significantly from the standard scientific format, which severely hinders readability. The "Experiments" section (Section 5) is presented immediately after the "Introduction" (Section 1), before the "Method" (Section 2-4) has been described. This forces the reader to assess results without understanding how they were generated.
    *   The "Preliminaries" and "Related Work" sections are combined and placed after the problem formulation (Section 3), interrupting the flow of the proposed method.
    *   The "Conclusion and Limitations" are relegated to Appendix A (Section 6), which is a critical section that should be in the main paper. This unconventional layout makes the paper difficult to navigate and comprehend.*   **Insufficient Analysis of Computational Complexity and Efficiency**
    *   The theoretical complexity of Thanos for unstructured pruning is higher than its competitors (Table 1), with a term of `O(c^4/B)`. While the paper provides pruning time plots (Figure 9), the trade-off between this increased cost and the resulting accuracy improvement is not explicitly discussed.
    *   There appear to be contradictory claims regarding efficiency. Appendix H.3 states that for models smaller than 1B parameters, "Thanos demonstrates greater speed compared to SparseGPT". However, Figure 9a shows that for the OPT-1.3B model, SparseGPT is faster than Thanos for unstructured pruning. This inconsistency needs to be resolved.
    *   The paper mentions that GPU memory limitations require further subdivision of pruning blocks (Appendix H.2), which suggests practical scalability challenges. A more thorough analysis of the wall-clock time and memory usage versus model size and accuracy would be beneficial.*   **Limited Ablation and Hyperparameter Sensitivity Analysis**
    *   The method introduces two important hyperparameters: the block size `B` and the outlier row fraction `α`. The sensitivity to these hyperparameters is not sufficiently explored.
    *   For `B`, an ablation is provided in Appendix C (Table 5), but only for a single model (TinyLlama-1.1B). The results for unstructured sparsity show perplexity is "relatively stable across different block sizes," which raises the question of how critical the block-wise formulation is if the block size has minimal impact. The justification for choosing `B=128` for unstructured and `B=512` for structured/semi-structured sparsity (Section 5.1) could be strengthened with analysis on more models.
    *   For `α`, results are presented for `α=0` and `α=0.1` (Tables 2, 3), demonstrating its effectiveness. However, there is no analysis of how performance varies for other values of `α` (e.g., 0.05, 0.15, 0.2). This makes it difficult to assess the robustness of `α=0.1` as a default setting.**4) Suggestions for Improvement***   **Reorganize the Manuscript for Clarity**
    *   The paper should be restructured to follow a standard, logical flow. A suggested order is: 1. Introduction, 2. Preliminaries and Related Work, 3. Method (Thanos), 4. Experiments, 5. Conclusion.
    *   The problem formulation (currently Section 2) should be part of the Method section.
    *   The Conclusion and Limitations (currently Appendix A) should be moved to the main body of the paper as Section 6, providing a proper summary of the work and its context.*   **Provide a Clearer Analysis of the Efficiency Trade-off**
    *   The authors should add a dedicated analysis of the accuracy-efficiency trade-off. This could be a plot of perplexity/accuracy versus pruning time for Thanos and the baselines on a few representative models.
    *   Please clarify the discrepancy between the text in Appendix H.3 and the results in Figure 9a regarding the relative speed of Thanos and SparseGPT on smaller models.
    *   It would be valuable to include memory usage statistics during pruning to give a more complete picture of the practical costs associated with the method, especially in light of the issues mentioned in Appendix H.2.*   **Conduct More Thorough Ablation Studies**
    *   To strengthen the claims about hyperparameter choices, the ablation study for block size `B` (Table 5) should be expanded to include at least one larger model to confirm if the observed stability holds at scale.
    *   A sensitivity analysis for the outlier fraction `α` is crucial. Please include a plot showing how a key metric (e.g., perplexity on LLaMA-3 8B) changes as `α` is varied (e.g., from 0 to 0.3). This would demonstrate the robustness of the method and help practitioners choose an appropriate value.**5) Score***   Overall (10): 7 — The paper presents a novel and effective method for structured pruning with strong results, but its impact is diminished by significant organizational issues and a lack of deep analysis on complexity and hyperparameters.
*   Novelty (10): 8 — The block-wise simultaneous weight update (Eq. 10) and the outlier-aware structured pruning approach (Sec. 4.7.1) are strong and novel contributions to the field of post-training pruning.
*   Technical Quality (10): 7 — The method is technically sound and the experimental setup is rigorous (Tables 2, 3), but the limited ablation studies and unresolved inconsistencies in the efficiency analysis are weaknesses.
*   Clarity (10): 5 — While individual sections are mostly clear, the overall manuscript structure is highly unconventional and confusing (e.g., Experiments before Method, Conclusion in Appendix), making the paper very difficult to follow.
*   Confidence (5): 5 — I have carefully reviewed the main paper and the appendices and am confident in my assessment of its strengths and weaknesses.