Academic integrity and consistency risk report

Summary of high-impact issues identified, with explicit anchors to the manuscript

1) Structured update formula inconsistency (likely material to correctness)
- Main text Eq. (13) in Section 4.7 writes the structured update as
  “hatΔ_{k:} = −W_{:,1:s} (H_{1:s,1:s}^{−1})^{−1} H_{1:s,:}^{−1}.”
- Appendix G.4.2 (Eq. 72) gives a different expression:
  “Δ̂_{k:} = − W_{:,1:s} (H_{1:s,1:s})^{−1} H_{1:s,:}.”
- Algorithm 7 (Appendix G.4.5), step 10, implements yet another variant:
  “W_{:,1:s} ← W_{:,1:s} − W_{:,1:s} (H_{1:s,1:s}^{−1}) H_{1:s,:}.”
These are not equivalent. Using “(H_{1:s,1:s}^{−1})^{−1}” (i.e., H_{1:s,1:s}) together with “H_{1:s,:}^{−1}” (a slice of H^{-1}) in Eq. (13) mixes blocks of H and H^{-1) and is inconsistent with the derivation in Appendix G.1/G.4.2. This discrepancy can change the update direction and magnitude, directly affecting pruning correctness. Anchors: Section 4.7 Eq. (13); Appendix G.4.2 Eq. (72); Appendix G.4.5 Algorithm 7 step 10.

2) Dimensional inconsistency of the unit vector e^q (affects constraint formulation)
- Section 2.2 defines e^q ∈ ℝ^{1×b} and uses the constraint “Δ_{k:} e^q + W_{kq} = 0.” With Δ_{k:} ∈ ℝ^{1×b}, this multiplication is not well-defined unless e^q is a column vector.
- Appendix E.4 corrects this and explicitly sets e^q ∈ ℝ^{b×1} (Block 70), making “Δ_{k:} e^q + W_{kq} = 0” valid.
This internal inconsistency may confuse implementation and derivations of Lagrangian conditions. Anchors: Section 2.2 (Block 14); Appendix E.4 (Block 70).

3) Misreferenced equations (“(3.2)”) for pruning metric
- Section 3.4 (Block 19) and Section 4.1/4.2 (Blocks 22–23) refer to “metric (3.2)” while no Equation 3.2 exists in the manuscript. The correct references appear to be Eq. (5) in the main text or Eq. (46) in Appendix F.2/F.4 for the OBD/Wanda metric.
These misreferences obstruct verification of the metric used to create masks. Anchors: Blocks 19, 22–23; correct candidates: Eq. (5) main; Eq. (46) appendix.

4) Algorithmic reference mismatch for structured update
- Section 4.7 Algorithm 2, step 10, labels the structured pruning update with “xleftarrow{(10)}” (Eq. 10), which is the general multi-weight update for unstructured setting. The structured case has its own derived form (Eq. 13 / Appendix Eq. 72). Using (10) here is not consistent with the structured derivation. Anchors: Section 4.7 Algorithm 2 step 10; Eq. (10); Eq. (13); Appendix Eq. (72).

5) Semi-structured comparisons with reduced effective sparsity (non-equivalent evaluation)
- Section 5.1 explicitly states: “In semi-structured sparsity with α = 0.1, the total sparsity p decreases from p = 0.5 to p = 0.45.” (Block 35)
- Despite this, Tables 2–3 report Thanos (α = 0.1) results alongside other methods under “4:8” and “2:4” sparsity, without indicating that Thanos uses lower effective sparsity than the baselines in those rows. This yields non-apples-to-apples comparisons and can inflate perceived advantages of Thanos at α = 0.1 in semi-structured settings. Anchors: Section 5.1 (Block 35); Table 2 rows “4:8” and “2:4” for “Thanos (α = 0.1)”; Table 3 rows “4:8” and “2:4” for “Thanos (α = 0.1)”.

6) Overstated/unsubstantiated claims about unstructured performance
- Section 5.2 claims: “Thanos outperforms existing methods in pruning TinyLlama 1.3B and all LLaMA-3 models ranging from 3B to 70B…” (Block 36).
  • For LLaMA-3 70B, Table 2 shows Thanos = 5.78 and SparseGPT = 5.78 (tie, not “outperforms”).
  • For TinyLlama, no comparative unstructured perplexity versus other methods is presented. The only TinyLlama table (Appendix C, Table 5) reports Thanos-only results across block sizes; no baselines. No direct evidence found in the manuscript supporting the TinyLlama “outperforms” claim.
Anchors: Section 5.2 (Block 36); Table 2 (LLaMA-3 70B unstructured entries); Appendix C Table 5.

7) Model labeling inconsistency in results tables
- Section 5.1 lists evaluated models: OPT family; TinyLlama 1.3B; LLaMA-2 (7B/13B/70B); LLaMA-3 (1B/3B/8B/70B). (Block 35)
- Table 2 and Table 3 include a column “LLaMA-2 1.1B,” which is not in the stated evaluation set and is not a standard LLaMA-2 variant. Additionally, Appendix C uses “TinyLlama-1.1B” (Table 5), while the main text names “TinyLlama 1.3B.”
These mismatches create ambiguity about which model the 1.1B column corresponds to and whether the reported numbers align with the described evaluation suite. Anchors: Section 5.1 (Block 35); Table 2/3 “LLaMA-2 1.1B”; Appendix C Table 5 (“TinyLlama-1.1B”).

8) Ceil omission in formula next to Figure 3
- Section 5.2/5.3 page shows “s = pb/(1−α)” adjacent to Figure 3 (Block 37), while structured pruning elsewhere uses s = ⌈pb/(1−α)⌉ (Section 4.7.1 Eq. (14) and Algorithm 2 step 2). This inconsistency can lead to different column counts pruned. Anchors: Block 37 next to Figure 3; Section 4.7.1 (Block 31); Algorithm 2 step 2.

9) Use of H^{-1} without specifying computation in Thanos pseudocode
- Algorithm 1 (Section 4.2) and Algorithm 9 (Appendix H.1) use H_{q:}^{−1} and H_{1:s,:}^{−1} but never state how these rows of the inverse are obtained (e.g., via solving Hx=e_q or a factorization). SparseGPT’s Appendix (F.3) discusses Cholesky-based efficiencies, but the Thanos algorithms, as written, omit the necessary step to procure H^{-1} or its rows, leaving the algorithm incomplete for implementation. Anchors: Algorithm 1 lines 12–15 (Block 23); Algorithm 9 lines 12–15 (Block 121); compare with Appendix F.3 (Blocks 86–88).

10) Equation and notation inconsistencies that can affect reproducibility
- Notation Table B defines e^j ∈ ℝ^{b×1} (Block 50), conflicting with Section 2.2 where e^q ∈ ℝ^{1×b} (Block 14).
- In Algorithm 2 step 10, the annotation “xleftarrow{(10)}” does not match the structured-case derivation (see Issue 4).
These inconsistencies hinder precise reimplementation and verification. Anchors: Section 2.2; Table 4 (Appendix B).

Assessment

The above issues are substantive and, in several cases, directly impact the algorithmic correctness (structured update formula), fairness of experimental comparisons (semi-structured α=0.1 at reduced sparsity p), and the verifiability of claimed performance (TinyLlama superiority lacks in-paper evidence; “outperforms” claim for LLaMA-3 70B is contradicted by a tie).

Recommendations to address integrity risks

- Correct the structured update derivation and ensure Eq. (13), Appendix Eq. (72), and Algorithm 7 step 10 are mathematically consistent and dimensionally valid. Align Algorithm 2’s step 10 reference to the corrected structured formula.
- Fix the dimensional definition of e^q consistently (use column vector) across the manuscript and update constraints accordingly.
- Replace all “(3.2)” references with the correct equation numbers for the pruning metric (e.g., Eq. (5) or Eq. (46)), and verify all equation cross-references.
- Clarify and standardize model naming (e.g., TinyLlama 1.1B vs 1.3B; remove or correct “LLaMA-2 1.1B” if mislabeled).
- In semi-structured comparisons, either keep p constant across methods (e.g., adjust s or mask to preserve n:m sparsity per row including outlier handling) or explicitly report effective sparsity and compare at matched p. Avoid mixing α=0.1 Thanos (p≈0.45) against baselines at p=0.5 without disclosure within the tables.
- Modify Section 5.2 claims to match evidence: indicate ties where applicable (LLaMA-3 70B unstructured) and remove or support the TinyLlama claim with comparative tables/figures.
- Add explicit details on how H^{-1} (or needed rows/blocks) are computed in Thanos (factorization, solves), consistent with the provided pseudocode.

If these are corrected and clarifications are provided, many of the integrity risks would be mitigated.

If no such corrections are made, the current manuscript contains clear internal inconsistencies (equations and notation), non-equivalent comparisons in semi-structured experiments, and unsupported claims regarding TinyLlama, which collectively affect scientific validity and trustworthiness.