### Summary

This submission introduces **ITD (Inherent Temporal Dependencies)**, a **tracklet-based benchmark** for test-time adaptation (TTA) intended to better reflect **realistic temporal correlations** found in streaming/video settings, where consecutive frames often depict the same object. Built by extracting object-centric crops from an object-tracking dataset (e.g., TrackingNet) and applying controlled shifts such as **class skew**, **clean-to-corrupt transitions**, and **synthetic corruptions**, ITD is positioned as a more realistic alternative to standard i.i.d.-style corruption benchmarks. On top of this benchmark, the paper proposes **ADVMEM**, an **adversarial memory initialization** strategy aimed at improving **memory-based TTA** methods, and reports performance improvements and increased stability under both i.i.d. and non-i.i.d. evaluation protocols.

Across reviewers, the main consensus is that **the benchmark motivation is valid and timely**, and the dataset construction is a reasonable step toward evaluating TTA under temporal dependence. However, reviewers are largely **unconvinced about novelty and rigor**, arguing that the dataset may be a repackaging/simplification of existing video or continual adaptation benchmarks and that ADVMEM appears to be a relatively straightforward use of adversarial sample generation without deeper insight. Several reviewers also highlight **insufficient baselines (especially post-2023 TTA methods), limited model coverage, weak reproducibility details, and substantial writing/presentation issues**. Overall sentiment trends negative, with multiple reviewers recommending rejection unless the work is significantly strengthened.

### Strengths

* **Addresses a real gap in common TTA evaluation:** Reviewers agree that many TTA benchmarks implicitly assume i.i.d. samples and fail to capture **temporal correlations** typical of real deployments (streaming, mobile cameras, driving).
* **Practical benchmark construction via tracklets:** Building an evaluation stream from **object tracklets** is considered a sensible and implementable way to induce temporal dependence, and the inclusion of both **static and dynamic corruption severities** is viewed as useful for probing robustness.
* **Modular shift design enables more diagnostic evaluation:** The benchmark’s controlled factors (e.g., class skew, transitions, corruption patterns) can support **fine-grained ablations** beyond what ImageNet-C/CIFAR-C-style benchmarks enable.
* **Method is simple and easy to follow:** ADVMEM’s procedure is straightforward, and the reported empirical gains suggest that memory initialization can matter in temporally correlated TTA.

### Weaknesses

* **Novelty of the benchmark is questioned relative to existing datasets and setups:** Multiple reviewers argue ITD may not be meaningfully new compared to **video-based / non-i.i.d. / continual** TTA settings already explored (e.g., ImageNet-Vid-style streams, RoTTA/TRIBE-like setups, and temporally correlated benchmarks in detection/segmentation such as ACDC/Cityscapes-C/KITTI-C). The benchmark is sometimes characterized as a **simplification** (single object per frame) rather than a fundamentally new evaluation regime.
* **ADVMEM is viewed as incremental and under-analyzed:** Reviewers describe ADVMEM as a **straightforward adversarial initialization trick** rather than a new TTA mechanism. The paper largely reports empirical gains but provides limited **theoretical grounding** or **mechanistic analysis** (e.g., how adversarial initialization changes representations, memory dynamics, or forgetting behavior).
* **Insufficient and outdated baselines for “thorough analysis” claims:** A major criticism is that comparisons appear incomplete, particularly missing **many recent (2024–2025) online/continual/memory-based TTA methods**. Reviewers argue that without stronger, modern baselines, it is hard to conclude ITD exposes genuinely new failure modes or that ADVMEM is competitive.
* **Benchmark realism and coverage concerns:**

  * Cropping/resizing boxes to a fixed size may remove **natural scale variation**, potentially harming realism for applications like driving.
  * Tracklets may exhibit only mild appearance change and limited occlusion/motion, reducing the ability to test methods that depend on stronger temporal dynamics.
  * Only **~21 classes** are included, which may limit relevance for long-tailed/open-world conditions.
  * Heavy use of **synthetic corruptions** is argued to reduce ecological validity for real sensor/scene shifts.
  * The benchmark is **vision-only**, while current TTA usage often involves **multimodal VLMs**.
* **Concerns about base model quality and evaluation protocol:** One reviewer flags that the finetuned base models (e.g., ResNet18/ViT-B trained with limited budget) may be too weak or mismatched, making it difficult to fairly differentiate TTA methods (e.g., strong methods not outperforming simple AdaBN in some tables). Broader model coverage (ConvNeXt, CLIP, ViT variants) is requested.
* **Reproducibility and dataset documentation issues:** Reviewers note missing or insufficient detail about dataset splits, release plans, reproducibility, and ethics considerations.
* **Writing and presentation problems:** Several reviewers mention the manuscript is long and repetitive, formatting is non-standard, and figures/tables/captions are not well integrated—leading to an “oversold” impression relative to the technical depth.
