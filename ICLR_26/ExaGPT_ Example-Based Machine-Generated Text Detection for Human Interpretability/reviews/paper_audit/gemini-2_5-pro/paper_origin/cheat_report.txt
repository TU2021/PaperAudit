**Integrity and Consistency Review Report**

**Manuscript Title:** ExaGPT: Example-Based Machine-Generated Text Detection for Human Interpretability

**Overall Assessment:**
This review has identified several major internal inconsistencies between the claims made in the text and the data presented in the tables and figures. These issues are not minor and fundamentally undermine the paper's primary conclusions regarding its performance superiority and the analysis of its own methodology.

---

**Major Issues Identified:**

**1. Inconsistency in Baseline Performance Reporting Undermines Core Performance Claims**

The central claim that "ExaGPT massively outperforms prior powerful detectors by up to +40.9 points of accuracy at a false positive rate of 1%" (Abstract, Block #2) appears to be based on questionable baseline results presented in Table 2.

*   **Evidence:** In Table 2 (Block #19), the RoBERTa baseline is reported to have an AUROC of 100.0 in multiple settings (e.g., ChatGPT/Wikipedia, ChatGPT/Reddit, Dolly-v2/Reddit). An AUROC of 100.0 indicates perfect separability between the two classes, meaning a threshold exists that achieves 100% True Positive Rate (TPR) at 0% False Positive Rate (FPR).
*   **Contradiction:** Despite this perfect AUROC, the same RoBERTa model is reported to have an accuracy of 50.0% at 1% FPR in those same settings. On a balanced binary classification task, an accuracy of 50.0% is equivalent to random guessing. It is logically inconsistent for a model with perfect classification capability (AUROC=100.0) to perform at chance level when constrained to a 1% FPR. With perfect separability, the accuracy at 1% FPR should be close to 100% (specifically, 99.5% on a balanced test set of 1000 samples).
*   **Impact:** The paper's headline claim of outperformance relies on these anomalous baseline scores. For instance, the largest performance gap supporting the "+40.9 points" claim seems to come from comparing ExaGPT's 90.8% accuracy to RoBERTa's 50.0% on the Dolly-v2/Reddit setting (a +40.8 point difference). Since the RoBERTa baseline result is not credible, the claim of massive outperformance is unsupported by the provided evidence. This suggests a potential flaw in the baseline evaluation methodology.

**2. Direct Contradiction Between Textual Analysis and Plotted Results for Hyperparameter α**

Section 4.2, "Impact of α," contains claims that are directly contradicted by the corresponding figures.

*   **Evidence:** The text in Section 4.2 (Block #22) explicitly states: "...we observe that the higher the α, the higher the detection performance." This claim is intended to be supported by Figure 5 (Block #27) for the ChatGPT generator.
*   **Contradiction:** Figure 5 clearly shows the opposite trend. For all four domains (Wikipedia, Reddit, WikiHow, arXiv), both the AUROC (left plot) and the Accuracy at 1% FPR (right plot) *decrease* as `α` increases from 0.0 towards 1.0. The best performance is consistently achieved at or near `α = 0.0`. The same contradictory pattern holds for GPT-4 and Dolly-v2, as shown in Appendix Figure 10 (Block #47).
*   **Impact:** This is a significant logical failure in the analysis section. The authors' interpretation of their own results is incorrect, which calls into question the paper's understanding and explanation of how its own method works. The text further misinterprets the role of `α`, stating that higher performance is linked to "taking the reliability score more into account," which corresponds to a *low* `α`, not a high one, according to Equation 5.

**Conclusion:**

The manuscript contains critical internal inconsistencies that affect its core scientific claims. The reported performance of a key baseline (RoBERTa) is logically inconsistent with its AUROC score, invalidating the primary claim of state-of-the-art performance. Furthermore, the analysis of a key hyperparameter is directly contradicted by the data presented in the paper's own figures. These issues must be fully resolved and corrected before the manuscript can be considered for publication.