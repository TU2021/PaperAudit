# Innovation & Motivation Report

## 1. The Authors' Claimed Contribution
- **Core Problem**: Automated hateful meme detection systems often provide only binary labels, which are insufficient for real-world content moderation that requires context and explanations.
- **Claimed Gap**: The authors explicitly state that prior "Explain-then-Detect" approaches have failed to be practical. The abstract claims: *"Recent Explain-then-Detect approaches, using Chain-of-Thought prompting or LMM agents, perform worse than simple SFT baselines, and even advanced post-training methods such as GRPO fail to close the gap."* They diagnose this failure as stemming from two issues: (1) models do not reason about policy-relevant cues, and (2) the binary reward signal is too weak to guide the generation of high-quality reasoning.
- **Proposed Solution**: The manuscript introduces ExPO-HM, a framework inspired by human moderator training. It consists of three main components: (1) Supervised Fine-Tuning on structured Policy Manuals (SFT-PM) to instill domain knowledge; (2) Group-Relative Policy Optimization with Curriculum Learning (GRPO-CL) to transition from fine-grained to binary tasks; and (3) a novel Conditional Decision Entropy (CDE) metric used as a reward signal to encourage decisive and correct reasoning.

## 2. Comparative Scrutiny (The "Trial")
*Here, we analyze how the paper stands against the identified similar works.*

### vs. [IntMeme: Demystifying Hateful Content...] & [Multimodal Learning for Hateful Memes Detection]
- **Identified Overlap**: These works establish the architectural precedent for an "Interpret/Generate-then-Detect" pipeline. `IntMeme` proposes generating an "interpretive analysis" before classification, and the work by Zhou et al. incorporates an "image captioning process" before detection. Both share the core idea of using an intermediate text generation step to aid classification.
- **Manuscript's Defense**: The manuscript does not cite these specific papers but addresses this entire class of methods in its introduction and related work. It argues that such approaches historically underperform direct detection baselines. The entire premise of ExPO-HM is not to invent the "Explain-then-Detect" idea, but to be the *first to make it work effectively*. The defense is implicit in its contribution: proposing a specific training methodology (SFT-PM, GRPO-CL, CDE) designed to overcome the exact performance limitations observed in these earlier paradigms.
- **Reviewer's Assessment**: The difference is significant. While the high-level architectural concept is not de novo, the manuscript's primary contribution lies in diagnosing the failure of prior implementations and proposing a novel, multi-faceted training strategy to solve it. The shift from a simple caption or interpretation to a policy-grounded explanation, optimized with a sophisticated reward, is a substantive advance.

### vs. [Robust Adaptation of Large Multimodal Models for Retrieval Augmented Hateful Meme Detection (RA-HMD)]
- **Identified Overlap**: RA-HMD is identified as the state-of-the-art direct detection model. It represents the performance ceiling that the manuscript's "Explain-then-Detect" approach must surpass to prove its viability.
- **Manuscript's Defense**: The manuscript explicitly cites RA-HMD in its Related Work and includes it as a key SOTA baseline in its experimental results (Table 1). The defense is empirical: ExPO-HM reports a binary F1 score of 81.1 on the HatefulMemes dataset, outperforming RA-HMD's reported 80.2. The authors argue their method is superior not only in performance but also in providing necessary explanations, thus addressing the core limitation of the direct detection paradigm that RA-HMD represents.
- **Reviewer's Assessment**: The manuscript successfully defends its contribution. By directly comparing against and outperforming the established state-of-the-art in the alternative paradigm, it validates its central claim that an explanation-driven process can be more accurate, not just more interpretable. This is a strong point in favor of the paper's significance.

### vs. [Modularized Networks for Few-shot Hateful Meme Detection]
- **Identified Overlap**: Both this paper and the manuscript are built on the insight that monolithic, end-to-end training is suboptimal for the complex reasoning required in hateful meme detection. Both decompose the problem into learning foundational sub-skills. This paper does so architecturally by composing specialized LoRA modules, while the manuscript does so temporally via a training curriculum.
- **Manuscript's Defense**: The manuscript does not cite this work, but its methodology presents a distinct alternative to the same underlying problem. Its defense lies in the novelty of its approach: using a sequential curriculum within a reinforcement learning framework (SFT-PM -> GRPO-CL) rather than a static, modular composition. The effectiveness of this temporal approach is demonstrated through extensive ablations (Table 2), which show that each stage of the curriculum contributes significantly to the final performance.
- **Reviewer's Assessment**: This comparison highlights that "problem decomposition" is an emerging idea in the field, but the manuscript's implementation is novel. The choice of a temporal curriculum over an architectural one is a distinct and well-justified methodological contribution, particularly its integration with RL and the CDE reward. The novelty is substantive.

## 3. Novelty Verdict
- **Innovation Type**: Substantive
- **Assessment**:
  The manuscript successfully defends its claims of novelty and significance. The existence of prior work on "Interpret-then-Detect" architectures does not weaken the submission; rather, it strengthens its motivation by establishing a known, unsolved problem: these architectures consistently failed to outperform simpler, direct-detection models. The manuscript's core contribution is a specific and novel training framework (SFT-PM, GRPO-CL, and the CDE reward) that, for the first time, overcomes this performance gap.
  - **Strength**: The primary strength is the proposal of a complete, well-motivated training recipe that solves a documented failure mode of a promising research direction. The introduction of the Conditional Decision Entropy (CDE) as both a metric and a reward signal for reasoning quality is a particularly novel and impactful contribution. The strong empirical results, including outperforming the SOTA direct detection model RA-HMD, provide compelling evidence of the method's effectiveness.
  - **Weakness**: The highest-level concept of generating text before making a decision is not new. However, the paper correctly frames this not as a weakness, but as the central problem it is solving.

## 4. Key Evidence Anchors
- **Method Section**: The detailed description of the three-stage ExPO-HM framework, particularly the formulation of the Conditional Decision Entropy (CDE) reward function (`r_CDE`).
- **Table 1 (Main Results)**: Provides the key empirical evidence, showing ExPO-HM outperforming the SOTA direct detection model (RA-HMD) and standard RL baselines (GRPO, DPO) on binary, fine-grained, and reasoning tasks.
- **Table 2 (Ablation Study)**: Crucially demonstrates that each proposed component (SFT-PM, GRPO-CL, CDE reward) provides a significant performance contribution, validating the design of the full framework.
- **Introduction/Related Work**: The clear articulation of the "gap" where prior "Explain-then-Detect" systems underperform direct SFT baselines, which establishes the motivation for the entire work.