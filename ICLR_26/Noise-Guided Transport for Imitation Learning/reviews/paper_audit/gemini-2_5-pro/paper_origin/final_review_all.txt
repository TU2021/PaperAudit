1) Summary
This paper introduces Noise-Guided Transport (NGT), a lightweight, off-policy imitation learning method designed for the low-data regime. NGT formulates reward learning as an optimal transport problem solved through an adversarial training scheme. The core mechanism involves training a predictor network to match the outputs of a frozen, randomly initialized prior network on expert data, while simultaneously maximizing the mismatch on agent-generated data. The authors show this objective is equivalent to maximizing the Earth Mover's Distance between the expert and agent distributions. The method leverages distributional losses to successfully tackle high-dimensional continuous control tasks like Humanoid locomotion from as few as 20 expert transitions. Experimental results demonstrate that NGT outperforms a range of baselines in sample-efficiency and performance, particularly in challenging, data-scarce scenarios.2) Strengths
*   **Novel and Theoretically Grounded Method**
    *   The core idea of learning a reward function by adversarially predicting the outputs of a frozen random network is a novel formulation for imitation learning (Section 4.1). This approach elegantly sidesteps the typical binary classification setup of GAIL-style methods.
    *   The paper provides a strong theoretical connection between the proposed adversarial objective and optimal transport, showing that minimizing the objective is equivalent to maximizing the Earth Mover's Distance (EMD) between the agent and expert distributions (Section 4.2, Equation 3).
    *   The theoretical analysis is thorough, including a concentration bound for the empirical loss objective (Appendix F, Theorem F.2) and a detailed analysis of the Lipschitz properties of the potential function and its components (Section 4.3, Theorem 4.1, Theorem 4.2).
    *   The application and analysis of distributional losses (`ℓ_HLG`) for reward learning in this context is a novel contribution that proves critical for solving complex tasks (Section 4.3.2).*   **Exceptional Empirical Performance in Low-Data Regimes**
    *   NGT demonstrates state-of-the-art performance across a suite of continuous control tasks, consistently outperforming strong baselines in the low-data setting (Figure 1, Figure 2).
    *   The method's success on the high-dimensional Humanoid-v4 task with extremely limited data (e.g., 1 demonstration, corresponding to 50 transitions) is particularly impressive, as most baselines fail or perform poorly in this setting (Figure 2, Humanoid column).
    *   NGT shows stable and graceful scaling with the amount of expert data, from as few as 20 transitions (Figure 3, `dems01` with `subr50`) up to several hundred. This highlights its robustness to data scarcity.
    *   The method's strong performance extends to more challenging DeepMind Control Suite environments, which feature greater initial state stochasticity, further validating its generalization capabilities (Appendix O, Figure 9).*   **Comprehensive and Rigorous Experimental Evaluation**
    *   The paper compares NGT against a wide and relevant set of baselines, including classic methods (BC), OT-based methods (PWIL, W-DAC/SAM), GAIL variants (DAC/SAM), and recent diffusion-based approaches (DiffAIL) (Section 5).
    *   The authors provide extensive ablation studies that convincingly justify key design choices. These studies demonstrate the necessity of the distributional loss for Humanoid (Appendix N, Figure 4), the importance of spectral normalization (Appendix N, Figure 7), the benefit of orthogonal initialization (Appendix N, Figure 6), and the impact of embedding dimensionality (Appendix N, Figure 8).
    *   The experimental setup is well-controlled, with all methods built on a shared SAC backbone to ensure fair comparison (Section 5). The evaluation protocol is sound, using multiple random seeds and a robust evaluation scheme to prevent memorization.*   **Practicality and Efficiency**
    *   NGT is presented as a lightweight method that does not require large-scale pretraining or specialized architectures (Abstract).
    *   A significant practical advantage is that NGT achieves stability using only spectral normalization, avoiding the need for a computationally expensive gradient penalty, which is required by other adversarial IL methods (Section 4.3.1, Appendix N Figure 7).
    *   The method demonstrates competitive computational speed, performing on par with or faster than several key baselines on high-dimensional tasks (Appendix P, Table 3).3) Weaknesses
*   **Discrepancy Between Theory and Practice for Key Result**
    *   The paper's central theoretical claim—that the method optimizes the Earth Mover's Distance—is predicated on the potential function `h_ξ` being 1-Lipschitz (Section 4.2, Equation 3).
    *   However, for the flagship Humanoid results, the method relies on the `ℓ_HLG` loss (Appendix N, Figure 4) with hyperparameters (Appendix N, Table 1) that, according to the paper's own analysis (Theorem 4.2), result in a Lipschitz constant significantly greater than 1.
    *   This creates a disconnect between the theoretical justification and the practical implementation. It is unclear if the method is truly optimizing an EMD in the setting where it achieves its most impressive results, which undermines the technical soundness of this core claim.*   **Reliance on a Complex Loss for Challenging Tasks**
    *   The paper's strongest results on the Humanoid task are critically dependent on the use of a distributional histogram loss (`ℓ_HLG`) (Section 4.3.2). Standard losses like MSE fail completely on this task (Appendix N, Figure 4).
    *   The `ℓ_HLG` loss introduces several new, potentially sensitive hyperparameters: the support interval `[a, b]`, the number of bins `N`, and the Gaussian spread `σ` (Section 4.3.2). This complexity seems to contradict the claim that the method is "easy to implement and tune" (Abstract).
    *   The paper notes that these hyperparameters must be adapted to the environment to achieve optimal results on non-Humanoid tasks (Appendix N, Figure 5), suggesting a non-trivial tuning effort may be required in practice.*   **Lack of Clarity on Experimental Protocol and Details**
    *   The main text does not explicitly state which loss function (e.g., Huber or `ℓ_HLG`) was used for the non-Humanoid results presented in Figure 2, leaving the reader to infer this from the appendix (Appendix N, Section "For the Humanoid...").
    *   The training duration for the Humanoid experiments (3x10^6 steps, per Figure 2) is inconsistent with the stated default and the duration for all other tasks (10^7 steps, per Appendix N, Table 1 and other plots in Figure 2), with no justification provided.
    *   The "20 transitions" claim (Abstract, Figure 3) relies on subsampling rates (`subr`) that are not defined or explained in the main experimental setup (Section 5), hindering reproducibility.
    *   The aggregated performance plot in the introduction (Figure 1) does not specify which tasks were included, making it difficult to assess whether it is a representative summary of performance.*   **Limited Exploration of the Prior Network Design**
    *   The frozen prior network `f_ξ^†` is a cornerstone of the method, as it generates the target "noise" for the predictor (Section 4.1). However, the design space for this network is not explored in depth.
    *   The paper justifies the use of Orthogonal Initialization (Section 4.3.1) and ablates against Kaiming initialization (Appendix N, Figure 6), but other architectural choices (e.g., network depth/width, activation functions, or alternative random initializations) are not discussed.
    *   The quality and structure of the random mapping provided by the prior network seem fundamental to the learning signal, but the paper does not provide intuition or analysis on what constitutes a "good" prior.*   **Key Ablation Results are Relegated to the Appendix**
    *   The ablation studies in Appendix N provide critical evidence supporting the method's design, but they are not mentioned or summarized in the main paper.
    *   The finding that `ℓ_HLG` is essential for Humanoid (Appendix N, Figure 4) and that spectral normalization is critical for stability (Appendix N, Figure 7) are fundamental to understanding why NGT works.
    *   Placing these crucial results entirely in the appendix weakens the self-containedness of the main paper and may cause readers to miss the full justification for the method's components.4) Suggestions for Improvement
*   **Clarify and Reconcile the Theory-Practice Gap**
    *   Explicitly acknowledge in the main text (e.g., Section 4.3 or 5) that the hyperparameters used for `ℓ_HLG` on the Humanoid task do not satisfy the 1-Lipschitz condition.
    *   Discuss the implications of this violation. Does the method still approximate an OT distance, or does the objective function optimize something else in this regime? Provide intuition for why the method works well despite the violation.
    *   To fully resolve the issue, it would be ideal to show that strong performance can be achieved on Humanoid with hyperparameters that *do* satisfy the 1-Lipschitz constraint, or with a different 1-Lipschitz loss.*   **Acknowledge and Discuss the Role of the Distributional Loss**
    *   In the main text (e.g., Section 5), explicitly state that the `ℓ_HLG` loss was essential for the Humanoid results and discuss the trade-off between its performance benefits and the introduction of new hyperparameters.
    *   Briefly discuss the role of the `ℓ_HLG` hyperparameters (`N`, `σ`, etc.) and provide intuition for their tuning, perhaps linking them to task complexity as suggested in Appendix N.
    *   To strengthen the "easy to tune" claim, it would be beneficial to show that a reasonable default setting for `ℓ_HLG` works well across a range of tasks, or provide a simple heuristic for setting its parameters.*   **Improve Transparency and Consistency of the Experimental Protocol**
    *   In the main experimental section (Section 5), clarify which loss was used for each family of environments (e.g., "We used the Huber loss for all tasks except Humanoid-v4...").
    *   Justify the shorter training duration for the Humanoid experiments in the main text or align it with the protocol for other experiments.
    *   Clearly define the subsampling rates (`subr10`, `subr20`, `subr50`) in Section 5 to properly contextualize the results in Figure 3 and the "20 transitions" claim.
    *   Specify in the caption of Figure 1 which tasks were included in the aggregation to ensure the plot is representative and verifiable from Figure 2.*   **Expand on the Prior Network's Role**
    *   Add a short discussion in Section 4.1 or 4.3 about the design of the prior network `f_ξ^†`.
    *   Acknowledge that the architecture and initialization of the prior are important design choices and briefly motivate the current approach beyond the ablation results.
    *   Suggesting that the exploration of more structured or learned priors could be an avenue for future work would add valuable context.*   **Integrate Key Ablation Findings into the Main Paper**
    *   Incorporate a concise summary of the most critical ablation results into the main experimental section (Section 5).
    *   For example, a brief paragraph discussing the findings from Appendix N, Figures 4 and 7 would significantly strengthen the paper's narrative by immediately justifying the use of `ℓ_HLG` and spectral normalization.
    *   Alternatively, a small, well-chosen figure in the main text could summarize 2-3 key ablations (e.g., `ℓ_HLG` vs. MSE on Humanoid, with vs. without SN) to make the paper more self-contained.5) Score
- Overall (10): 7 — The paper presents a novel and empirically powerful method, but its technical claims are weakened by a theory-practice gap and several clarity issues in the experimental reporting.
- Novelty (10): 9 — The formulation of adversarial reward learning as predicting random priors within an optimal transport framework is highly novel and insightful (Section 4.1, 4.2).
- Technical Quality (10): 7 — The theoretical analysis is undermined by a violation of its core 1-Lipschitz assumption in the implementation for the paper's best result (Theorem 4.2, Appendix N Table 1).
- Clarity (10): 6 — The paper is generally well-written, but is hampered by inconsistent experimental details and the relegation of critical results and justifications to the appendix (Figure 2, Appendix N).
- Confidence (5): 5 — I am highly confident in my assessment, as the paper provides detailed methodology, theory, and extensive empirical evidence that I have carefully checked.