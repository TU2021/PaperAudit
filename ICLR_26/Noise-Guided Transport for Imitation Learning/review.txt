### Summary

This paper introduces **Noise-Guided Transport (NGT)**, a novel off-policy imitation learning method designed for low-data regimes. NGT frames imitation as an **optimal transport problem** and solves it via adversarial training. It does not require pretraining or specialized architectures and incorporates uncertainty estimation by design. The method is **lightweight** and efficient, achieving strong performance on continuous control tasks, such as **Humanoid** and **HalfCheetah**, using as few as **20 transitions**. The key innovation lies in its ability to enforce the **Lipschitz condition** and measure distributional distance under the **Wasserstein-1 metric** without relying on gradient penalties.

---

### Strengths

1. **Novel Approach**:

   * NGT offers a unique solution to imitation learning in low-data scenarios by treating imitation as an optimal transport problem.
   * The method avoids the traditional **gradient penalties** required to enforce the Lipschitz condition, offering a more **computationally efficient** alternative.

2. **Strong Empirical Results**:

   * NGT performs well on several **continuous control tasks** in the **MuJoCo Gymnasium** and **DeepMind Control Suite**, demonstrating strong **sample efficiency** with minimal expert data.
   * The paper provides comprehensive **ablation studies** that demonstrate the effectiveness of different components of the method.

3. **Efficiency**:

   * The method shows **high data and sample efficiency** in **low-data regimes**, outperforming existing adversarial imitation learning (AIL) approaches.
   * **No pretraining** or specialized architectures are required, making it easier to implement and tune.

4. **Theoretical Justification**:

   * NGT is grounded in **optimal transport theory**, and the paper offers **theoretical results** supporting its approach, including the use of a **frozen random prior network** that regularizes the training process.

5. **Practical Relevance**:

   * The simplicity and effectiveness of NGT make it highly relevant for real-world applications where **data** is limited and computational resources are constrained.

---

### Weaknesses

1. **Presentation Issues**:

   * The manuscript is difficult to follow in some areas, particularly in sections that could be more **concise**. There are some **unnecessary bolded words** and **missing hyperlinks** in the appendices, which affect the overall readability.
   * The **motivation for the chosen method** (NGT) is not clearly aligned with its name and is introduced later in the paper. This could be made clearer at the beginning to help guide the reader.

2. **Computational Efficiency**:

   * While the authors claim that NGT is more **computationally efficient** by avoiding gradient penalties, **Table 3** does not show a clear advantage in computation time compared to existing methods.
   * The authors need to **better justify the computational efficiency** claim, especially by highlighting the trade-off between time and reward performance.

3. **Methodology**:

   * The use of **random priors** in the reward-learning mechanism is introduced without sufficient background or motivation in some parts of the paper. The authors should offer more clarification on how **random priors** are utilized and how they impact performance.
   * There are also **vague or incorrect statements** about the **Lipschitz constant** and its impact on performance. For example, certain statements regarding the properties of **ReLU functions** and **vanishing gradients** are not fully explained and need clarification.

4. **Connection to Prior Work**:

   * The paper touches on concepts related to **adversarial imitation learning** and **optimal transport**, but there is insufficient explanation of how NGT differs from or improves upon **previous work**, such as **WGAN-based IL** or **Adversarial Motion Priors (AMP)**.
   * More reference to prior works, such as **Xiao et al. (2019)** and **Peng et al. (2021)**, would help position NGT within the context of existing research.

5. **Experiment Design**:

   * The experiments are run with **only 4 random seeds** per task, which is **insufficient** for reliable statistical results, especially in **low-data regimes** where variability is expected.
   * The authors should increase the number of **random seeds** (at least 10) to ensure that the reported results are not due to random fluctuations or chance.
   * The hyperparameter tuning process for different methods needs to be clarified, particularly the decision to apply the same hyperparameters across tasks with different dynamics.