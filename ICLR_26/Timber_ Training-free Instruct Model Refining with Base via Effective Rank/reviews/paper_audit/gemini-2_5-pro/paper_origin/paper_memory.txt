# Global Summary
This paper investigates the "superficiality" of post-training in Large Language Models (LLMs), where a pretrained Base model is fine-tuned into an Instruct model. The authors provide novel quantitative evidence for this hypothesis by showing that the effective rank (eRank) of weight matrices remains almost unchanged between paired Base and Instruct models. They argue that this superficiality leads to a trade-off, improving the model's exploitation capabilities (e.g., Pass@1) at the cost of its exploration capabilities (e.g., Pass@k).

To address this limitation, the paper proposes Timber, a simple, training-free method to enhance an Instruct model's exploration while preserving its exploitation. The core idea is to partially revert the Instruct model's weights towards its paired Base model. This is achieved by calculating the weight delta between the two models, performing SVD on the delta, and then using the eRank as a threshold to either remove (Timber-L) or attenuate (Timber) the tail-end singular values.

Experiments on Llama and Qwen series models (0.6B to 30B) across various benchmarks (e.g., MATH, GPQA-D, HumanEval) show that Timber consistently improves performance over vanilla Instruct models. For instance, Timber improves the average score of Llama-3.1-8B by +1.71. The method is particularly effective at improving Pass@k scores, supporting the claim that it enhances exploration.

# Abstract
The paper first reinforces the hypothesis that post-training is superficial by providing quantitative evidence that the effective rank (eRank) of weights changes negligibly between Base and Instruct models. This superficiality creates a trade-off, improving exploitation at the cost of exploration. The paper proposes Timber, a training-free method to enhance the Instruct model's exploration while preserving exploitation. Timber works by partially reverting the Instruct model towards its paired Base model through a targeted refinement of the weight deltas. Experiments on Llama and Qwen models show that Timber consistently improves performance, especially on Pass@k metrics.

# Introduction
- The paper investigates the superficial nature of the post-training stage (SFT and RL) that converts a Base LLM to an Instruct LLM.
- It introduces a novel weight-level perspective using effective rank (eRank), which quantifies the effective dimensionality of a weight matrix.
- The analysis shows that eRanks of corresponding linear layers in Base and Instruct models are nearly identical, providing new evidence for the superficiality of post-training.
- A key problem arising from this superficiality is a trade-off between exploitation (improved Pass@1) and exploration (limited Pass@k for large k).
- To address this, the paper proposes Timber, a training-free method that enhances an Instruct model by partially reverting it towards its Base model.
- Timber's mechanism involves decomposing the weight delta between the models via SVD and using eRank to identify and then remove or attenuate the tail components of the singular values.
- The contributions are: 1) a new analysis of post-training superficiality via eRank, 2) the Timber method, and 3) experimental validation of Timber's effectiveness on various LLMs.

# Preliminaries
- LLM training is a two-stage process: pre-training a Base model on vast data, followed by post-training (SFT, RL) to create an Instruct model. A table lists the paired Base and Instruct models used, including Llama and Qwen3 series.
- The paper reviews the "Superficial Alignment Hypothesis," which posits that capabilities are learned during pre-training, and alignment only teaches the model which format to use.
- Effective Rank (eRank) is defined as the exponential of the Shannon entropy of the normalized singular value distribution of a matrix. It measures the effective dimensionality. The paper sets the scale factor γ=1.
- The core analysis shows that eRanks for corresponding linear layers in paired Base and Instruct models are nearly identical across Llama and Qwen models. For example, in Qwen3-14B's Layer 4, the k_proj matrix has an eRank of 935 for both Base and Instruct versions.
- This finding suggests that post-training preserves the singular subspaces of the weights and reinforces the superficiality hypothesis.
- The eRank-to-Rank ratio is shown to be highly concentrated around a mean of 0.85 for all evaluated models, with an interquartile range between 0.75 and 0.95.

# Method
- The method section is divided into Motivation and the description of Timber.
- **Motivation**: Post-training sharpens exploitation (focusing on effective reasoning paths) at the cost of exploration (diverse solutions), leading to high Pass@1 but low Pass@k scores. The paper aims to enhance exploration without extra training or inference overhead. The proposed solution is to partially revert the Instruct model towards its Base state by refining the weight deltas.
- **Timber**: A training-free method to refine the weight delta `W_Δ = W_I - W_B`.
- The process involves:
    1. Decomposing `W_Δ` using SVD: `SVD(W_Δ) -> UΣV^T`.
    2. Setting a threshold `K` based on the ceiling of the eRank of the delta: `K := ceil(eRank(W_Δ))`.
    3. Refining the singular values in `Σ`. Two strategies are proposed:
        - **Timber-L**: A low-rank approach that discards tail singular values by setting `σ_i = 0` for `i > K`.
        - **Timber**: A full-rank approach that attenuates tail singular values: `σ_i` becomes `λ * σ_i` for `i > K`, where `0 < λ < 1`.
    4. Reconstructing the refined Instruct model weights: `W_I^+ = W_B + U * refine(Σ) * V^T`.
- This refinement is applied only to the weights of linear layers, not biases or normalization layers.

# Motivation
- This section, presented as 3.1 in the manuscript, outlines the core challenge and rationale for the proposed method.
- **Challenge**: Post-training creates a trade-off where Instruct models excel at exploitation (high Pass@1) but suffer in exploration (low Pass@k for large k).
- **Goal**: To enhance exploration without compromising exploitation in a training-free manner, avoiding the computational overhead of other methods.
- **Proposed Solution**: Given that post-training is superficial, the paper proposes to enhance the Instruct model by leveraging the weights of the Base model. The strategy is to partially revert the Instruct model to its Base state by refining the weight deltas between them.

# Experiments
- **Setup**:
    - Models: Llama 3 and Qwen3 series, from 0.6B to 30B, including the MoE model Qwen3-30B-A3B.
    - Benchmarks: IFEval, MATH, MATH-500, GPQA-D, HellaSwag. For Qwen3's "Thinking mode," AIME'24 and HumanEval are also used.
    - Metrics: Mean@k and Pass@k, with Pass@k calculated using an unbiased estimator.
    - Hyperparameters: The attenuation factor λ for Timber is searched in {0.2, 0.5, 0.8} based on AIME'24 performance.
    - Repetitions: 4 runs for Llama-3.2-1B, 3 runs for other models.
- **Main Results**:
    - Table 2 shows that both Timber-L and Timber consistently outperform the vanilla Instruct models across all settings. For Llama-3.1-8B, Timber achieves an average score of 55.23, a +1.71 improvement.
    - The attenuation strategy (Timber) is generally superior to the dropping strategy (Timber-L) in 6 out of 7 cases.
    - The method is robust across different model families (Llama, Qwen), sizes, and architectures (dense, MoE).
- **Thinking Mode and Pass@k Analysis**:
    - On AIME'24 and HumanEval with Qwen3 models in Thinking mode, Timber consistently outperforms the vanilla Instruct model. For Qwen3-30B-A3B on HumanEval, Timber scores 96.14, a +2.44 improvement over the baseline's 93.7.
    - Pass@k results on Qwen3-0.6B (Figure 5) show that Timber and Timber-L achieve significantly higher scores than the vanilla model on AIME'24 and GPQA-Diamond.
    - The performance gap widens as `k` increases, providing strong evidence for enhanced exploration.

# Discussion
- **Comparison with Truncated SVD**:
    - Timber-L is framed as a special case of SVD applied to weight deltas, with the truncation point determined by eRank.
    - Baselines `Truncate-R` (rank ratio) and `Truncate-E` (energy ratio) are compared on Qwen3-8B.
    - Timber achieves the highest average score (74.84), outperforming all SVD variants. The SVD baselines show unstable performance sensitive to the threshold, whereas Timber is more robust.
- **Comparison with Model Merge**:
    - A simple model merge (`W_merge = μ*W_I + (1-μ)*W_B`) is a uniform scaling of the weight delta.
    - On Llama-3.2-1B, this simple merge only provides a slight improvement at `μ=0.95` and performance degrades sharply otherwise.
    - Timber's fine-grained, eRank-based refinement provides a more significant and robust performance gain.
- **Ablation on Modules**:
    - An ablation on Llama-3.1-8B studies applying Timber-L to only attention (Attn) or FFN layers.
    - Applying to both modules yields the best overall performance.
    - Applying only to Attn layers benefits IFEval (instruction following).
    - Applying only to FFN layers benefits MATH and GPQA-D (knowledge-intensive tasks), consistent with prior findings that FFNs store factual knowledge.
- **Case Study**:
    - A case study on Qwen3-14B (detailed in Appendix A.5) shows that Timber generates more comprehensive thinking trajectories compared to the vanilla Instruct model.

# Conclusion
- The paper reinforces the hypothesis of superficial post-training using effective rank (eRank) analysis.
- It proposes Timber, a simple and effective training-free method to address the limited exploration capability of Instruct models by refining the weight delta towards the Base model.
- The method uses eRank as a threshold to either remove or attenuate tail singular values of the weight delta.
- Extensive experiments demonstrate that Timber enhances exploration without compromising exploitation.
- Future work could explore more strategies for enhancing weight deltas.

# References
This section lists the academic papers and resources cited throughout the manuscript.

# Appendix
- **A.1 LLM Usage**: States that an LLM was used for proofreading and language refinement.
- **A.2 More Related Work**: Provides additional context on the use of eRank in LLM analysis and on the weight-level similarity between Base and Instruct models, noting that weight differences can be less than 5%.
- **A.3 Evaluation Details**:
    - Specifies the evaluation framework (OpenCompass) and provides details on each benchmark, including shot settings (e.g., 0-shot for IFEval, 4-shot for MATH).
    - Table 4 lists generation hyperparameters (temperature, top_p, etc.) for each model family.
- **A.4 Performance with different λ**:
    - Table 5 shows the average benchmark scores for Timber with λ values of 0.0, 0.2, 0.5, and 0.8.
    - The results demonstrate robustness, with consistent improvements over the vanilla baseline.
    - The paper recommends λ = 0.2 as a "sweet point" for new models.
- **A.5 Detailed Cases**:
    - Presents qualitative examples from the GPQA-Diamond benchmark on Qwen3-14B.
    - The examples aim to show that Timber's responses have more comprehensive thinking trajectories, exhibit more extensive domain knowledge, and use mathematical formulas where the vanilla Instruct model fails to do so.