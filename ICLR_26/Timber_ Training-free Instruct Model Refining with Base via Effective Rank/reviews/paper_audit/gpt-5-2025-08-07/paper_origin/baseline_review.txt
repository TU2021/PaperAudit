Summary
- The paper studies the relationship between Base and Instruct LLMs through effective rank (eRank) of weight matrices and reports that eRank is nearly unchanged after post‑training, suggesting superficial changes (Section 2.2; Figures 1, 8–10). Building on this, the authors propose Timber, a training‑free weight‑space refinement that partially reverts an Instruct model toward its Base by modifying the SVD spectrum of the weight delta WΔ with an eRank‑based head/tail split and either discarding (Timber‑L) or attenuating (Timber) the tail (Equations 2–7; Section 3.2). Experiments across Llama and Qwen families (0.6B–30B) show consistent average accuracy improvements and enlarged Pass@k, especially at larger k (Table 2; Figures 4–5; Appendix Table 5). Timber also outperforms truncated‑SVD and simple model‑merge baselines (Section 5.1 Table 3; Section 5.2). Ablations suggest benefits from applying Timber to both attention and FFN modules (Section 5.3, Figure 7).Strengths
- Bold weight-level perspective on post-training superficiality
  • The paper provides weight-level eRank comparisons across Base/Instruct pairs and layers, finding near-identity of eRank (Section 2.2; Figures 1, 8–10), strengthening the “superficial” post-training hypothesis. This is important for novelty and interpretability.
  • The distribution of eRank-to-rank ratios shows eRank is a high fraction of full rank across models (Figure 2), clarifying representational capacity and supporting the claim that post-training does not expand the intrinsic dimensionality; this matters for technical soundness.
  • Clear definition and discussion of eRank and its invariances (Equation 1; Section 2.1), improving clarity and reproducibility of the analysis.- Simple, training-free method with concrete formulation
  • Timber is precisely specified via SVD of WΔ, eRank-based threshold K, and two refinement strategies (Equations 2–7; Section 3.2), enabling replication and highlighting a lightweight intervention (clarity and practical impact).
  • The motivation ties exploration/exploitation to sampling diversity and Pass@k (Section 3.1; Equation 8), situating Timber within a clear problem framing (clarity and relevance).
  • Implementation choice to modify only linear weights and leave biases/norm layers untouched (Section 3.2) reduces risk of destabilization and preserves alignment behavior (technical prudence).- Consistent empirical gains across diverse models and tasks
  • Across Llama 3 and Qwen3 models (0.6B–30B), Timber improves the averaged score on standard benchmarks without training (Table 2), indicating robustness and practical utility (impact).
  • Pass@k increases with k, and Timber/Timber‑L substantially outperform Instruct on AIME’24 and GPQA‑Diamond (Figure 5; Section 4.2), directly evidencing enhanced exploration (experimental rigor).
  • Robustness to λ is documented for Thinking mode on AIME’24 and HumanEval, with consistent gains across λ values (Figure 4; Appendix Table 5), strengthening claims about stability (technical soundness).- Comparative analyses to relevant baselines
  • Timber outperforms truncated‑SVD variants Truncate‑R and Truncate‑E under comparable energy preservation (Section 5.1; Table 3), supporting the effectiveness of attenuation over truncation (experimental rigor).
  • Weighted model merge (uniform scaling of WΔ) is less robust and often degrades with smaller μ, whereas Timber remains effective (Section 5.2; Figure 6 text), validating the fine‑grained eRank‑guided approach (novelty and soundness).
  • Module-wise ablation indicates applying Timber to both attention and FFN yields the best overall performance; attention-only helps IFEval and FFN-only helps math tasks (Section 5.3; Figure 7), providing interpretability and design guidance (clarity and impact).- Clear evaluation setup and estimator choice
  • The paper uses the unbiased Pass@k estimator (Equation 8), multiple rollouts, and repeats (Section 4.1), improving reliability and methodological rigor (experimental soundness).
  • Benchmarks and inference hyperparameters are enumerated (Section 4.1; Appendix A.3.1 and A.3.2; Table 4), aiding reproducibility (clarity).
  • The GitHub link is provided (Abstract), facilitating verification and adoption (impact).Weaknesses
- Limited and potentially incomplete evidence for eRank invariance and “superficiality”
  • Only three layers per model are shown for Base vs. Instruct comparisons (Section 2.2; Figures 1, 8–10), which may not capture full-network behavior; broader statistical comparisons are absent, weakening generality (experimental rigor).
  • The analysis reports ceilings of eRank (Section 2.2), but does not quantify differences (e.g., deltas or distributions across all layers); no hypothesis tests or aggregated metrics are given, limiting strength of evidence (technical soundness).
  • γ is fixed to 1 (Section 2.1) and the claim that results are invariant to log bases is stated, but sensitivity to γ or alternative spectral measures is not explored; No direct evidence found in the manuscript for γ sensitivity (experimental completeness).- Clarity issues and numeric inconsistencies in Figure 1
  • Figure 1 lists eRank values like “q_proj: 26292630,” which appear implausible given typical matrix ranks (Section 2.2, Figure 1 table), risking misinterpretation of the central evidence (clarity).
  • The text claims k_proj is relatively small due to GQA (Section 2.2), yet the figure presents extremely large eRank values for some projections without unit explanation, confusing readers (clarity).
  • The mismatch between bar charts (Figures 8–10) and tabular numbers in Figure 1 suggests a formatting or calculation issue; No direct reconciliation evidence found in the manuscript (technical accuracy).- Use of eRank on weight deltas is not sufficiently justified
  • The eRank-to-rank ratio distribution (Figure 2) is reported for “all linear layers in various LLMs,” but not for WΔ; yet Timber sets K from eRank(WΔ) (Section 3.2), leaving a gap in justification (technical soundness).
  • The statement “As shown in Figure 2, the eRanks are around the 85th percentile of full rank” is used to motivate Timber‑L (Section 3.2) but Figure 2 does not explicitly analyze deltas; No direct evidence found in the manuscript connecting WΔ spectra to this percentile (clarity and rigor).
  • No analysis of when WΔ is not full rank or has atypical spectra (Section 3.2 claims WΔ is “typically full-rank”), limiting understanding of edge cases; No direct evidence found in the manuscript (technical completeness).- Baseline coverage is narrow relative to cited literature
  • The paper cites training-based and tool-assisted approaches (Section 1; Section 3.1), but does not include them in empirical comparison (Section 4.2), narrowing the context of improvement (impact).
  • Weight-space baselines focus on truncation or uniform scaling (Section 5.1 Table 3; Section 5.2), but other training‑free strategies referenced in the paper’s bibliography are not compared; No direct evidence found in the manuscript for broader baselines (experimental breadth).
  • Absence of comparison on Pass@k with alternative sampling/diversity‑focused methods cited (e.g., test‑time scaling variants) limits the exploration claim’s scope (impact).- Computational cost and scalability are asserted but not quantified
  • Timber requires SVD of WΔ for all linear layers across billions of parameters (Section 3.2), but runtime/memory costs, hardware, and wall‑clock times are not reported (Section 4.1), hindering practical assessment (reproducibility).
  • The search over λ is described as “minimal” (Section 4.1; Appendix A.4) but no compute accounting is provided; No direct evidence found in the manuscript (technical completeness).
  • No discussion of how MoE routing or large sequence lengths affect the SVD pipeline (Table 1; Section 4.1), limiting claims of scalability (impact).- Statistical significance and variance reporting are limited
  • Table 2 reports average improvements often ≤1 point; repeats are mentioned (Section 4.1) but confidence intervals or statistical tests are absent, making it hard to judge robustness under sampling variance (experimental rigor).
  • Pass@k curves (Figure 5) show gains, but variance bands or bootstrap CIs are not shown; No direct evidence found in the manuscript (technical rigor).
  • Sensitivity to prompt randomness and seed control is not documented (Appendix A.3.2 lists generation hyperparameters but not seeds), affecting reproducibility (clarity).- Alignment/safety impacts are not evaluated
  • Timber partially reverts Instruct toward Base (Section 3.2), which could affect alignment; IFEval is included (Table 2), but safety/harms are not measured (impact).
  • No human or automated safety eval is reported for exploration‑heavy regimes (Figures 4–5), leaving uncertainty on trade‑offs (technical completeness).
  • No qualitative analysis of harmful outputs or instruction-following degradation beyond IFEval (Appendix A.3.1), limiting responsible deployment assessment (impact).- Mechanistic evidence for exploration is limited
  • The claim that Timber expands sampling space is supported via Pass@k (Figure 5), but diversity metrics (e.g., distinct‑n, entropy, disagreement among samples) are not analyzed (experimental completeness).
  • No probe of hidden‑state diversity, activation rank, or entropy changes is provided, although the paper motivates rank‑level analysis (Section 2.1–2.2) (technical depth).
  • Case studies (Appendix A.5) are illustrative, but do not quantify exploration beyond correctness and trajectory detail (Section 5.4), limiting mechanistic understanding (impact).- Sensitivity analyses are partial
  • λ is studied on a few tasks/models (Figure 4; Appendix Table 5), but the choice of K=⌈eRank(WΔ)⌉ and γ=1 are not varied (Section 3.2), leaving threshold sensitivity unclear (technical rigor).
  • No comparison of eRank thresholds computed on W_B or W_I vs. on WΔ (Section 3.2), limiting understanding of alternative formulations (novelty and completeness).
  • Rounding effects and ordering assumptions (Σ in “non-decreasing order,” Section 3.2) are not examined; typical SVD orders are non‑increasing, suggesting a potential typo or convention mismatch (clarity).Suggestions for Improvement
- Broaden and deepen the eRank evidence for superficiality
  • Report network‑wide Base–Instruct eRank differences across all linear layers (means, medians, distributions) and include statistical tests (Section 2.2; Figures 1, 8–10) to solidify the invariance claim.
  • Provide aggregated metrics beyond ceilings (e.g., average absolute difference in eRank per layer; correlation across layers) and quantify effect sizes (Section 2.2).
  • Add sensitivity to γ (e.g., γ=2) and to alternative spectral measures (e.g., participation ratio) to confirm robustness of conclusions (Section 2.1).- Fix figure numeric inconsistencies and improve clarity
  • Correct or explain the large eRank numbers in Figure 1 (e.g., units, scaling), and ensure consistency with bar plots in Figures 8–10 (Section 2.2).
  • Explicitly annotate axes and units for all eRank plots, and clarify GQA-related dimensionalities to avoid confusion (Section 2.2; Figures 1, 8–10).
  • Include a reconciliation note or supplemental table aligning per‑layer numeric eRanks across figures to eliminate ambiguity (No direct reconciliation currently present).- Justify eRank(WΔ) as the threshold more thoroughly
  • Provide distributions and statistics of eRank(WΔ) across layers/models, and compare them to eRank(W_B) and eRank(W_I) to motivate K (Section 3.2; Figure 2 currently does not analyze deltas).
  • Validate “~85%” percentile using WΔ empirically (Section 3.2) and add ablations where K is set by other criteria (e.g., energy, fixed ratio) to show why eRank(WΔ) is preferable.
  • Analyze edge cases (e.g., low‑rank or highly skewed WΔ) and discuss Timber’s behavior under such spectra, including failure modes (Section 3.2).- Expand baseline comparisons in line with cited literature
  • Include at least one training‑based method and one tool‑assisted method cited in the paper (Section 1; Section 3.1) to contextualize Timber’s gains under comparable compute.
  • Compare against additional training‑free diversity/sampling strategies referenced (e.g., test‑time scaling variants) on Pass@k to isolate weight‑space benefits (Section 4.2).
  • When baselines are infeasible (compute or licensing), document constraints and provide qualitative or small‑scale comparisons to maintain fairness (No direct evidence currently provided).- Quantify computational cost and scalability
  • Report wall‑clock time, memory footprint, and hardware requirements for Timber on each model size, including MoE (Section 3.2; Table 1; Section 4.1).
  • Provide λ search cost and total inference cost for Pass@k runs (Section 4.1; Appendix A.4), and compare to truncated SVD/merge baselines for practical assessment.
  • Discuss implementation details (batched SVD, precision, device placement) and provide profiling logs to support “minimal cost” claims (No direct evidence currently presented).- Add statistical significance and variance analyses
  • Include confidence intervals or standard deviations for Table 2 averages and per‑benchmark scores, and perform significance tests where improvements are small (Section 4.1–4.2).
  • Add variance bands to Pass@k curves (Figure 5) and report seeds and prompt randomness controls (Appendix A.3.2).
  • Document reproducibility details (e.g., seed management, deterministic settings) to strengthen claims of robustness (No direct evidence currently provided).- Evaluate alignment and safety impacts
  • Complement IFEval with standardized safety/harms evaluations and report any changes introduced by Timber (Table 2; Section 4.2).
  • Perform human spot checks in exploration‑heavy regimes (Figures 4–5) to ensure Timber does not degrade alignment when sampling more diverse trajectories.
  • Provide qualitative examples of instruction following and safety behavior pre‑ and post‑Timber (Appendix A.5 could be expanded to include safety‑oriented prompts).- Strengthen mechanistic evidence for exploration
  • Measure sample diversity directly (e.g., distinct‑n on rationales, inter‑sample disagreement, entropy of logits) alongside Pass@k (Figure 5) to tie gains to exploration.
  • Probe hidden‑state representational changes (e.g., activation eRank, attention entropy) to connect the weight‑space intervention with downstream diversity (Sections 2.1–2.2).
  • Extend case studies (Appendix A.5) with quantitative trajectory metrics (e.g., number of unique solution paths) to substantiate exploration claims.- Extend sensitivity analyses of Timber’s hyperparameters and design choices
  • Vary K (e.g., K±δ, energy‑based K) and report performance to demonstrate robustness of the eRank threshold (Section 3.2).
  • Explore γ choices (γ=2) and compare using eRank computed on W_B/W_I vs. WΔ to assess alternative formulations (Section 3.2).
  • Clarify ordering convention for singular values and examine rounding effects of K=⌈eRank⌉; correct “non‑decreasing” if it is a typo (Section 3.2).Score
- Overall (10): 7 — Solid training-free idea with clear formulation (Equations 2–7; Section 3.2) and consistent empirical gains (Table 2; Figures 4–5), but evidence for eRank invariance is limited (Section 2.2; Figures 1, 8–10) and clarity issues remain (Figure 1).
- Novelty (10): 7 — eRank-based refinement of weight deltas and exploration-focused Pass@k improvements are distinctive (Section 3.2; Figure 5; Table 3), though related merging/compression ideas exist (Section 5.1–5.2).
- Technical Quality (10): 6 — Method is soundly specified (Equations 2–7) and evaluated (Table 2; Figure 5), but lacks comprehensive statistical tests, compute metrics, and full justification of eRank(WΔ) threshold (Section 3.2; Section 4.1–4.2).
- Clarity (10): 6 — Generally clear exposition (Equation 1; Equation 8; Appendix A.3.1–A.3.2), but numeric inconsistencies in Figure 1 and missing details on costs/threshold sensitivity reduce clarity (Section 2.2; Section 3.2).
- Confidence (5): 4 — High confidence in reading and interpretation based on detailed anchors (Equations 1–8; Figures 1–5; Tables 1–3, 4, 5), but some figure inconsistencies and missing metrics limit certainty.