### Summary

The paper titled **"Machine Text Detectors are Membership Inference Attacks"** explores the connection between **membership inference attacks (MIAs)** and **machine-generated text detection (MGT detection)**. It provides a theoretical and empirical investigation into how methods developed for one task can be applied to the other, demonstrating a strong correlation in performance across both tasks. The key contribution is proving that **MIAs and MGT detectors** share the same **optimal decision function**¡ªthe likelihood ratio between the target language model and the true human-text distribution¡ªand that many existing methods can be viewed as approximations of this optimal function. This result is supported by extensive experiments comparing **7 MIA methods** and **5 MGT detectors** across 13 domains and 10 generators, showing **strong transferability** between tasks. The paper also introduces **Mint**, a unified evaluation suite for both MIA and machine-generated text detection.

---

### Strengths

1. **Theoretical Contribution**:

   * The paper proves the **equivalence** between the decision functions used in MIAs and machine text detection. This theoretical insight is a strong foundation for understanding how these tasks relate and informs the development of future methods.

2. **Empirical Validation**:

   * The extensive experiments provide **strong evidence** of the transferability between MIA methods and machine-generated text detectors, including the surprising finding that **Binoculars**, designed for text detection, outperforms MIA methods on MIA tasks.

3. **Unified Evaluation Framework**:

   * The introduction of **Mint**, a unified evaluation suite, is a significant step toward facilitating fair cross-task comparisons and enabling future research to build on these findings.

4. **Clear Writing**:

   * The paper is **well-written**, making complex ideas accessible, even for readers not deeply familiar with membership inference attacks or machine-generated text detection.

---

### Weaknesses

1. **Limited Analysis of Generation Methods**:

   * The **choice of MGT detectors** seems incomplete. Almost all detectors rely on similar strategies, particularly based on **log-likelihood**. The paper could benefit from including methods that take fundamentally different approaches, such as those analyzing fluctuations in log-likelihood or intrinsic dimension techniques.

2. **Rank Correlation**:

   * While the theoretical results focus on the **optimal statistic**, the empirical analysis is based on **rank correlation** rather than absolute performance. This weakens the conclusions as **rank correlation** may not fully capture meaningful differences in method performance, particularly in saturated settings.

3. **Saturated Performance in Experiments**:

   * The experiments show that many detectors perform well, but it¡¯s difficult to determine whether the observed small differences are meaningful. This is especially evident in Figure 3, where performance gaps are minimal, making it challenging to conclude that certain methods are significantly better than others.

4. **Discrepancies in Performance Across Studies**:

   * The paper highlights **performance discrepancies** in different studies, such as **Lastde++** being the worst performer in this paper, yet performing well in prior work. The paper does not sufficiently address how different **generation strategies** or **hyperparameters** may influence the results.

5. **Lack of Human Verification**:

   * The transferability of methods is intriguing, but **human verification** of these results would provide more **credibility** and deeper insights, particularly in a task involving subjective qualities like detecting human-like text.
