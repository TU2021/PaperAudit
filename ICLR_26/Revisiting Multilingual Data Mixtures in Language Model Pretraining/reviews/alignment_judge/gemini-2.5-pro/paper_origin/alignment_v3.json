{
  "paper": "Revisiting Multilingual Data Mixtures in Language Model Pretraining",
  "runs": [
    {
      "config": {
        "judge_model": "gemini-2.5-pro",
        "review_agent": "deepreviewer",
        "ai_model": "gpt-5-2025-08-07",
        "ai_review_file": "deep_review_all.txt",
        "temperature": 0.0,
        "max_tokens": 20000,
        "timeout_s": 180,
        "metric": "coverage_v1"
      },
      "config_key": "55f39c3e353412551a5ae68e81fc4acc489b4edd",
      "inputs": {
        "human_review": "review_origin.txt",
        "ai_review": "reviews/deepreviewer/gpt-5-2025-08-07/paper_origin/deep_review_all.txt"
      },
      "multi_review": {
        "detected": false,
        "num_reviews": 1,
        "summarize_used": false
      },
      "ai_review_consolidated": null,
      "alignment": {
        "strength_coverage_recall": 0.83,
        "weakness_coverage_recall": 0.4,
        "ai_extra_major_points_rate": 0.71,
        "symmetric_coverage_similarity": 0.39,
        "note": "The AI review shows high alignment on strengths but low alignment on weaknesses. The AI misses several key human concerns, such as the novelty of findings relative to prior work and the need for experiments on even larger models. Conversely, the AI raises many unique technical points, including reproducibility gaps (LR schedule), low evaluation sensitivity, and a specific taxonomy error in the pivot experiments."
      },
      "generated_at": "2025-12-27T23:46:17"
    },
    {
      "config": {
        "judge_model": "gemini-2.5-pro",
        "review_agent": "paper_audit",
        "ai_model": "gpt-5-2025-08-07",
        "ai_review_file": "baseline_review.txt",
        "temperature": 0.0,
        "max_tokens": 20000,
        "timeout_s": 180,
        "metric": "coverage_v1"
      },
      "config_key": "b3137abdd5dd456ecfb029f7bed4151251d086e2",
      "inputs": {
        "human_review": "review_origin.txt",
        "ai_review": "reviews/paper_audit/gpt-5-2025-08-07/paper_origin/baseline_review.txt"
      },
      "multi_review": {
        "detected": false,
        "num_reviews": 1,
        "summarize_used": false
      },
      "ai_review_consolidated": null,
      "alignment": {
        "strength_coverage_recall": 1.0,
        "weakness_coverage_recall": 0.44,
        "ai_extra_major_points_rate": 0.6,
        "symmetric_coverage_similarity": 0.35,
        "note": "The AI review fully covers the human reviewers' praise for the paper's experimental scope and design. However, it misses about half of the human-raised weaknesses, such as concerns about novelty and ungrounded assumptions. Conversely, the AI introduces numerous extra, specific methodological critiques, including confounding factors in the experiments and reporting inconsistencies, leading to a low overall symmetric coverage."
      },
      "generated_at": "2025-12-27T23:51:57"
    },
    {
      "config": {
        "judge_model": "gemini-2.5-pro",
        "review_agent": "paper_audit",
        "ai_model": "gpt-5-2025-08-07",
        "ai_review_file": "final_review_all.txt",
        "temperature": 0.0,
        "max_tokens": 20000,
        "timeout_s": 180,
        "metric": "coverage_v1"
      },
      "config_key": "0a71ca7d783136ba33fb6b5ec9aad08ece2f0c09",
      "inputs": {
        "human_review": "review_origin.txt",
        "ai_review": "reviews/paper_audit/gpt-5-2025-08-07/paper_origin/final_review_all.txt"
      },
      "multi_review": {
        "detected": false,
        "num_reviews": 1,
        "summarize_used": false
      },
      "ai_review_consolidated": null,
      "alignment": {
        "strength_coverage_recall": 1.0,
        "weakness_coverage_recall": 0.5,
        "ai_extra_major_points_rate": 0.57,
        "symmetric_coverage_similarity": 0.37,
        "note": "Review B captures all key strengths raised by humans (scale, coverage, experimental design). However, the reviews diverge significantly on weaknesses: humans focus on external validity (relevance to SOTA, lack of novelty vs. XLM-R, repeated tokens), while the AI focuses on internal validity (confounding variables in pivot/curriculum design, reporting inconsistencies, and lack of data quality metrics)."
      },
      "generated_at": "2025-12-28T00:01:41"
    },
    {
      "config": {
        "judge_model": "gemini-2.5-pro",
        "review_agent": "deepreviewer",
        "ai_model": "gpt-5-2025-08-07",
        "ai_review_file": "deep_review_merge.txt",
        "temperature": 0.0,
        "max_tokens": 20000,
        "timeout_s": 180,
        "metric": "coverage_v1"
      },
      "config_key": "752f27bc09e656c7d041a880d0c174422eea6ca4",
      "inputs": {
        "human_review": "review_origin.txt",
        "ai_review": "reviews/deepreviewer/gpt-5-2025-08-07/paper_origin/deep_review_merge.txt"
      },
      "multi_review": {
        "detected": false,
        "num_reviews": 1,
        "summarize_used": false
      },
      "ai_review_consolidated": null,
      "alignment": {
        "strength_coverage_recall": 0.86,
        "weakness_coverage_recall": 0.27,
        "ai_extra_major_points_rate": 0.63,
        "symmetric_coverage_similarity": 0.38,
        "note": "The AI review shows high alignment on strengths but very low alignment on weaknesses. The AI misses major human concerns about the paper's novelty and its positioning relative to prior work, while raising several distinct methodological issues not mentioned by humans, such as reproducibility gaps and low evaluation sensitivity."
      },
      "generated_at": "2025-12-28T00:17:23"
    }
  ]
}