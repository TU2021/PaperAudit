#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json, time
from pathlib import Path
from typing import List, Dict, Any
import requests
from tqdm import tqdm
import openreview

# ======== å›ºå®šå‚æ•° ========

CONFERENCE = "ACL"
YEAR = 2025
TYPE = "oral"
USERNAME = "tusongjun2023@ia.ac.cn"
PASSWORD = "Tu2000112125"
OUT_DIR = "./downloads"
SLEEP = 0.35
SKIP_EXISTING = True

# ==========================

BASEURL = "https://api2.openreview.net" # V2 API
PDF_URL = "https://openreview.net/pdf?id={forum}"
REVIEW_HINTS = ("/Official_Review", "/Review", "/Meta_Review", "/Decision", "/Comment")
ATTACHMENT_FIELDS = ("pdf", "submission", "paper", "file", "source")

def login():
    return openreview.api.OpenReviewClient(baseurl=BASEURL, username=USERNAME, password=PASSWORD)

def extract_value(x):
    """OpenReview å­—æ®µç»Ÿä¸€å–å€¼ï¼šdict({'value': ...}) -> strï¼›str -> åŸæ ·ï¼›å…¶å®ƒ -> ''"""
    if isinstance(x, dict):
        return x.get("value", "")
    if isinstance(x, str):
        return x
    return ""

def normalize_content(d):
    """æŠŠ note.content é‡Œå¸¸è§çš„ value åŒ…ä¸€å±‚çš„å­—æ®µæ‹å¹³ï¼š{'decision': {'value':'Accept'}} -> {'decision':'Accept'}"""
    if not isinstance(d, dict):
        return d
    out = {}
    for k, v in d.items():
        if isinstance(v, dict) and "value" in v and len(v) <= 2:
            out[k] = extract_value(v)
        else:
            out[k] = v
    return out

def safe_title(s: str) -> str:
    s = extract_value(s)
    s = (s or "").strip()
    s = "".join(ch if ch.isalnum() or ch in "-_. " else "_" for ch in s)
    return (s.replace(" ", "_") or "no_title")[:160]

def get_all_notes(client, **kwargs):
    out, offset, limit = [], 0, 1000
    while True:
        notes = client.get_notes(offset=offset, limit=limit, **kwargs)
        if not notes: break
        out.extend(notes); offset += len(notes)
    return out

def filter_by_type(notes: List[Any], conf_type: str):
    t_norm = conf_type.lower()
    t_title = t_norm.capitalize()
    kept = []
    for n in notes:
        c = getattr(n, "content", {}) or {}
        venue = c.get("venue") or c.get("Venue") or ""
        venue = extract_value(venue)

        ok = False
        if isinstance(venue, str) and (f"({t_title})" in venue or f"({t_norm})" in venue or t_title in venue or t_norm in venue):
            ok = True
        if ok:
            kept.append(n)

    return kept

def exists_nonempty(p: Path) -> bool:
    try:
        return p.exists() and p.is_file() and p.stat().st_size > 0
    except Exception:
        return False
    
def download_pdf(client, note, pdir: Path) -> bool:
    """ä¸‹è½½ PDFï¼›è‹¥å·²æœ‰éç©ºæ–‡ä»¶åˆ™ç›´æ¥è¿”å› Trueã€‚"""
    pdf_path = pdir / "paper.pdf"
    if SKIP_EXISTING and exists_nonempty(pdf_path):
        return True

    # ä¼˜å…ˆå°è¯• attachmentï¼ˆæˆåŠŸç‡æ›´é«˜ï¼‰
    for f in ATTACHMENT_FIELDS:
        try:
            data = client.get_attachment(note.id, f)
            if data:
                pdf_path.write_bytes(data)
                return True
        except Exception:
            pass

    # å›é€€åˆ°å…¬å¼€ pdf åœ°å€
    forum = getattr(note, "forum", None) or note.id
    try:
        r = requests.get(PDF_URL.format(forum=forum), timeout=30)
        if r.status_code == 200 and r.headers.get("content-type","").lower().startswith("application/pdf"):
            pdf_path.write_bytes(r.content)
            return True
    except Exception:
        pass
    return False

def _clean_invitation_from(r):
    """
    ä» r.invitations ä¸­æŒ‘ä¸€ä¸ªâ€œéç³»ç»Ÿâ€çš„é‚€è¯·åï¼Œå¹¶åªè¿”å›æœ€åä¸€æ®µæ ‡è¯†ï¼š
    ä¾‹å¦‚ '.../-/Official_Review' -> 'Official_Review'
    è‡ªåŠ¨å¿½ç•¥ Edit/Withdraw/Revision ç­‰ã€‚
    """
    bad = ("/-Edit", "/-Withdraw", "/-Revision", "/-Desk_Rejected", "/-Withdrawn")
    inv_list = getattr(r, "invitations", []) or []
    for inv in inv_list:
        if not any(b in inv for b in bad):
            return inv.split("/")[-1]
    return ""

def collect_reviews_metadata(client, forum_id: str):
    replies = client.get_all_notes(forum=forum_id)

    # 1) ç´¢å¼•æ‰€æœ‰èŠ‚ç‚¹ï¼ˆæ‹å¹³ contentã€æ¸…æ´— invitationï¼‰
    nodes = {}
    for r in replies:
        node = {
            "id": getattr(r, "id", None),
            "forum": getattr(r, "forum", None),
            "replyto": getattr(r, "replyto", None),
            "invitation": _clean_invitation_from(r),  # åªä¿ç•™ 'Official_Review' è¿™ç§çŸ­å
            "cdate": getattr(r, "cdate", None),
            "mdate": getattr(r, "mdate", None),
            "content": normalize_content(getattr(r, "content", {}) or {}),
            "children": []
        }
        nodes[node["id"]] = node

    # 2) æ‰¾ submission æ ¹ï¼ˆé€šå¸¸ id == forumï¼‰
    submission = nodes.get(forum_id)
    if submission is None and replies:
        # å…œåº•ï¼šæœ€æ—©çš„ä¸€æ¡å½“ä½œ submission
        root = min(replies, key=lambda x: getattr(x, "cdate", 0))
        submission = nodes.get(getattr(root, "id", None))

    # 3) å»ºç«‹å­é“¾
    for node in nodes.values():
        pid = node["replyto"]
        if pid and pid in nodes:
            nodes[pid]["children"].append(node)

    # 4) åˆ†ç±»ï¼ˆæ³¨æ„ invitation å·²å˜æˆæœ«æ®µçŸ­åï¼‰
    decisions, meta_reviews = [], []
    for node in nodes.values():
        inv = node["invitation"]
        if inv == "Decision" or inv.endswith("Decision"):
            decisions.append(node)
        elif inv == "Meta_Review" or inv.endswith("Meta_Review"):
            meta_reviews.append(node)

    # 5) åªå–â€œç›´æ¥æŒ‚åœ¨ submission ä¸Šâ€çš„æ ¹ï¼Œä½œä¸ºæ¯æ¡è¯„å®¡çº¿ç¨‹çš„èµ·ç‚¹
    if submission:
        thread_roots = list(submission["children"])
    else:
        # æ²¡è¯†åˆ«åˆ° submission æ—¶ï¼Œé€€åŒ–ä¸º replyto==forum çš„ä¸€å±‚
        thread_roots = [n for n in nodes.values() if n["replyto"] == forum_id]

    # 6) æ’åºï¼šæ¯æ£µæ ‘è‡ªé¡¶å‘ä¸‹æŒ‰æ—¶é—´ä»æ—©åˆ°æ™š
    def sort_rec(n):
        n["children"].sort(key=lambda x: (x.get("cdate") or 0))
        for ch in n["children"]:
            sort_rec(ch)

    for tr in thread_roots:
        sort_rec(tr)
    thread_roots.sort(key=lambda x: (x.get("cdate") or 0))

    # 7) è´´ä¸Šå‹å¥½ç±»å‹æ ‡ç­¾ï¼ˆåŸºäºçŸ­åï¼‰
    def label_kind(inv):
        if inv == "Official_Review" or inv.endswith("Review") and not inv.endswith("Meta_Review"):
            return "review"
        if inv.endswith("Meta_Review"):
            return "meta_review"
        if inv.endswith("Decision"):
            return "decision"
        if inv.endswith("Comment") or inv.endswith("Public_Comment"):
            return "comment"
        return "other"

    for node in nodes.values():
        node["kind"] = label_kind(node["invitation"])

    # 8) è¾“å‡ºï¼ˆä¸å†åŒ…å« submissionï¼Œä»¥å…é‡å¤ï¼›submission çš„ä¿¡æ¯æ”¾ metadata.jsonï¼‰
    review_dict = {
        "forum": forum_id,
        "threads": thread_roots,
        "meta_reviews": meta_reviews,
        "decisions": decisions
    }

    # æ„é€  submission çš„ç²¾ç®€å‰¯æœ¬ï¼šç§»é™¤ children å­—æ®µï¼Œä¿ç•™å…¶ä½™ä¿¡æ¯
    submission_dict = {k: v for k, v in submission.items() if k != "children"}



    return review_dict, submission_dict

def main():
    venue_id = f"{CONFERENCE}/{YEAR}/Conference"
    out_root = Path(OUT_DIR).expanduser() / f"{CONFERENCE.split('.')[0]}_{YEAR}_{TYPE}"
    out_root.mkdir(parents=True, exist_ok=True)

    client = login()
    print(f"ğŸ“¥ æ‹‰å– {venue_id} å…¨é‡æŠ•ç¨¿ä¸­â€¦")
    all_notes = get_all_notes(client, content={"venueid": venue_id})
    print(f"âœ… å…¨é‡æŠ•ç¨¿æ•°ï¼š{len(all_notes)} ç¯‡")

    # æŒ‰ç±»å‹è¿‡æ»¤
    subset = filter_by_type(all_notes, TYPE)
    print(f"ğŸ¯ åŒ¹é…ç±»å‹ ({TYPE})ï¼š{len(subset)} ç¯‡")

    summary = []
    for n in tqdm(subset, desc="Downloading"):
        c = getattr(n, "content", {}) or {}
        title = c.get("title") or c.get("Title") or "<no-title>"
        forum = getattr(n, "forum", None) or getattr(n, "id", None)
        number = getattr(n, "number", None)
        sub_id = str(number) if number else (forum[:8] if forum else "unknown")

        base = f"{sub_id}-{safe_title(title)}"
        pdir = out_root / base
        pdir.mkdir(parents=True, exist_ok=True)

        pdf_path = pdir / "paper.pdf"
        reviews_path = pdir / "reviews.json"
        metadata_path = pdir / "metadata.json"

        # 1) PDF
        pdf_ok = False
        if SKIP_EXISTING and exists_nonempty(pdf_path):
            pdf_ok = True
        else:
            pdf_ok = download_pdf(client, n, pdir)

        # 2) Reviews / Metadata
        # å¦‚æœä¸¤ä¸ªæ–‡ä»¶éƒ½å·²å­˜åœ¨ä¸”éç©ºï¼Œå°±ç›´æ¥è·³è¿‡æŠ“å–
        if SKIP_EXISTING and exists_nonempty(reviews_path) and exists_nonempty(metadata_path):
            with reviews_path.open("r", encoding="utf-8") as f:
                reviews_loaded = json.load(f)
            reviews_cnt = len(reviews_loaded.get("threads", []))
        else:
            reviews, metadata = collect_reviews_metadata(client, forum)
            reviews_path.write_text(json.dumps(reviews, indent=2, ensure_ascii=False), encoding="utf-8")
            metadata_path.write_text(json.dumps(metadata, indent=2, ensure_ascii=False), encoding="utf-8")
            reviews_cnt = len(reviews.get("threads", []))

        summary.append({"title": extract_value(title), "forum": forum, "pdf": pdf_ok, "reviews_count": reviews_cnt})
        time.sleep(SLEEP)

    (out_root / "summary.json").write_text(json.dumps(summary, indent=2, ensure_ascii=False), encoding="utf-8")
    print(f"\nâœ… ä¸‹è½½å®Œæˆï¼š{len(summary)} ç¯‡ï¼Œç»“æœä¿å­˜åœ¨ï¼š{out_root.resolve()}")
    for s in summary[:3]:
        print(f"  - {s['title'][:80]} (pdf={s['pdf']}, reviews={s['reviews_count']})")

if __name__ == "__main__":
    main()
